Already on 'yangexp2'
wandb: Currently logged in as: stevenzhou0816100. Use `wandb login --relogin` to force relogin
Traceback (most recent call last):
  File "/private/home/beidic/.conda/envs/griffin/bin/huggingface-cli", line 8, in <module>
    sys.exit(main())
             ^^^^^^
  File "/private/home/beidic/.conda/envs/griffin/lib/python3.12/site-packages/huggingface_hub/commands/huggingface_cli.py", line 51, in main
    service.run()
  File "/private/home/beidic/.conda/envs/griffin/lib/python3.12/site-packages/huggingface_hub/commands/user.py", line 98, in run
    login(token=self.args.token, add_to_git_credential=self.args.add_to_git_credential)
  File "/private/home/beidic/.conda/envs/griffin/lib/python3.12/site-packages/huggingface_hub/_login.py", line 111, in login
    _login(token, add_to_git_credential=add_to_git_credential, write_permission=write_permission)
  File "/private/home/beidic/.conda/envs/griffin/lib/python3.12/site-packages/huggingface_hub/_login.py", line 307, in _login
    raise ValueError("Invalid token passed!")
ValueError: Invalid token passed!
The following values were not passed to `accelerate launch` and had defaults used instead:
		More than one GPU was found, enabling multi-GPU training.
		If this was unintended please pass in `--num_processes=1`.
	`--mixed_precision` was set to a value of `'no'`
	`--dynamo_backend` was set to a value of `'no'`
To avoid this warning pass in values for each of the problematic parameters or run `accelerate config`.
2024-06-03:11:12:36,406 INFO     [main.py:288] Verbosity set to INFO
2024-06-03:11:12:36,407 INFO     [main.py:288] Verbosity set to INFO
2024-06-03:11:12:36,407 INFO     [main.py:288] Verbosity set to INFO
2024-06-03:11:12:36,816 INFO     [main.py:288] Verbosity set to INFO
2024-06-03:11:12:38,565 INFO     [main.py:288] Verbosity set to INFO
2024-06-03:11:12:38,854 INFO     [main.py:288] Verbosity set to INFO
2024-06-03:11:12:40,196 INFO     [main.py:288] Verbosity set to INFO
2024-06-03:11:12:40,198 INFO     [main.py:288] Verbosity set to INFO
2024-06-03:11:12:42,931 INFO     [main.py:378] Selected Tasks: ['gsm8k']
2024-06-03:11:12:42,931 INFO     [main.py:378] Selected Tasks: ['gsm8k']
2024-06-03:11:12:42,936 INFO     [main.py:378] Selected Tasks: ['gsm8k']
2024-06-03:11:12:42,941 INFO     [xevaluator.py:137] Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234
2024-06-03:11:12:42,941 INFO     [xevaluator.py:137] Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234
2024-06-03:11:12:42,941 INFO     [xevaluator.py:184] Initializing xhf model, with arguments: {'pretrained': 'meta-llama/Meta-Llama-3-8B-Instruct', 'griffin': True, 'check': False}
2024-06-03:11:12:42,941 INFO     [xevaluator.py:184] Initializing xhf model, with arguments: {'pretrained': 'meta-llama/Meta-Llama-3-8B-Instruct', 'griffin': True, 'check': False}
2024-06-03:11:12:42,941 INFO     [xevaluator.py:137] Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234
2024-06-03:11:12:42,941 INFO     [xevaluator.py:184] Initializing xhf model, with arguments: {'pretrained': 'meta-llama/Meta-Llama-3-8B-Instruct', 'griffin': True, 'check': False}
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]2024-06-03:11:12:46,007 INFO     [main.py:378] Selected Tasks: ['gsm8k']
2024-06-03:11:12:46,013 INFO     [xevaluator.py:137] Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234
2024-06-03:11:12:46,014 INFO     [xevaluator.py:184] Initializing xhf model, with arguments: {'pretrained': 'meta-llama/Meta-Llama-3-8B-Instruct', 'griffin': True, 'check': False}
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]2024-06-03:11:12:48,637 INFO     [main.py:378] Selected Tasks: ['gsm8k']
2024-06-03:11:12:48,645 INFO     [xevaluator.py:137] Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234
2024-06-03:11:12:48,645 INFO     [xevaluator.py:184] Initializing xhf model, with arguments: {'pretrained': 'meta-llama/Meta-Llama-3-8B-Instruct', 'griffin': True, 'check': False}
2024-06-03:11:12:48,678 INFO     [main.py:378] Selected Tasks: ['gsm8k']
2024-06-03:11:12:48,686 INFO     [xevaluator.py:137] Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234
2024-06-03:11:12:48,686 INFO     [xevaluator.py:184] Initializing xhf model, with arguments: {'pretrained': 'meta-llama/Meta-Llama-3-8B-Instruct', 'griffin': True, 'check': False}
2024-06-03:11:12:49,083 INFO     [main.py:378] Selected Tasks: ['gsm8k']
2024-06-03:11:12:49,090 INFO     [xevaluator.py:137] Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234
2024-06-03:11:12:49,090 INFO     [xevaluator.py:184] Initializing xhf model, with arguments: {'pretrained': 'meta-llama/Meta-Llama-3-8B-Instruct', 'griffin': True, 'check': False}
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]2024-06-03:11:12:51,949 INFO     [main.py:378] Selected Tasks: ['gsm8k']
2024-06-03:11:12:51,955 INFO     [xevaluator.py:137] Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234
2024-06-03:11:12:51,955 INFO     [xevaluator.py:184] Initializing xhf model, with arguments: {'pretrained': 'meta-llama/Meta-Llama-3-8B-Instruct', 'griffin': True, 'check': False}
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:  25%|██▌       | 1/4 [00:20<01:01, 20.63s/it]Loading checkpoint shards:  25%|██▌       | 1/4 [00:28<01:24, 28.16s/it]Loading checkpoint shards:  25%|██▌       | 1/4 [00:30<01:31, 30.62s/it]Loading checkpoint shards:  25%|██▌       | 1/4 [00:30<01:32, 30.82s/it]Loading checkpoint shards:  25%|██▌       | 1/4 [00:30<01:31, 30.66s/it]Loading checkpoint shards:  25%|██▌       | 1/4 [00:25<01:15, 25.17s/it]Loading checkpoint shards:  25%|██▌       | 1/4 [00:25<01:15, 25.02s/it]Loading checkpoint shards:  25%|██▌       | 1/4 [00:25<01:16, 25.63s/it]Loading checkpoint shards:  50%|█████     | 2/4 [00:54<00:55, 27.90s/it]Loading checkpoint shards:  50%|█████     | 2/4 [01:00<01:00, 30.46s/it]Loading checkpoint shards:  50%|█████     | 2/4 [01:01<01:01, 30.57s/it]Loading checkpoint shards:  50%|█████     | 2/4 [00:52<00:53, 26.99s/it]Loading checkpoint shards:  50%|█████     | 2/4 [01:01<01:01, 30.53s/it]Loading checkpoint shards:  50%|█████     | 2/4 [00:58<00:59, 29.57s/it]Loading checkpoint shards:  50%|█████     | 2/4 [00:55<00:56, 28.23s/it]Loading checkpoint shards:  50%|█████     | 2/4 [00:56<00:57, 28.80s/it]Loading checkpoint shards:  75%|███████▌  | 3/4 [01:24<00:28, 28.53s/it]Loading checkpoint shards:  75%|███████▌  | 3/4 [01:30<00:30, 30.19s/it]Loading checkpoint shards:  75%|███████▌  | 3/4 [01:31<00:30, 30.27s/it]Loading checkpoint shards:  75%|███████▌  | 3/4 [01:30<00:30, 30.22s/it]Loading checkpoint shards:  75%|███████▌  | 3/4 [01:25<00:28, 28.98s/it]Loading checkpoint shards:  75%|███████▌  | 3/4 [01:28<00:29, 29.71s/it]Loading checkpoint shards:  75%|███████▌  | 3/4 [01:25<00:29, 29.12s/it]Loading checkpoint shards:  75%|███████▌  | 3/4 [01:22<00:28, 28.55s/it]Loading checkpoint shards: 100%|██████████| 4/4 [01:33<00:00, 20.04s/it]Loading checkpoint shards: 100%|██████████| 4/4 [01:33<00:00, 23.45s/it]
Loading checkpoint shards: 100%|██████████| 4/4 [01:36<00:00, 20.50s/it]Loading checkpoint shards: 100%|██████████| 4/4 [01:36<00:00, 24.12s/it]
Loading checkpoint shards: 100%|██████████| 4/4 [01:31<00:00, 19.73s/it]Loading checkpoint shards: 100%|██████████| 4/4 [01:31<00:00, 22.85s/it]
Loading checkpoint shards: 100%|██████████| 4/4 [01:31<00:00, 19.79s/it]Loading checkpoint shards: 100%|██████████| 4/4 [01:31<00:00, 22.76s/it]
Loading checkpoint shards: 100%|██████████| 4/4 [01:36<00:00, 20.52s/it]Loading checkpoint shards: 100%|██████████| 4/4 [01:36<00:00, 24.15s/it]
Loading checkpoint shards: 100%|██████████| 4/4 [01:36<00:00, 20.55s/it]Loading checkpoint shards: 100%|██████████| 4/4 [01:36<00:00, 24.20s/it]
Loading checkpoint shards: 100%|██████████| 4/4 [01:27<00:00, 19.31s/it]Loading checkpoint shards: 100%|██████████| 4/4 [01:27<00:00, 21.90s/it]
Loading checkpoint shards: 100%|██████████| 4/4 [01:31<00:00, 20.08s/it]Loading checkpoint shards: 100%|██████████| 4/4 [01:31<00:00, 22.88s/it]
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
Using the latest cached version of the dataset since gsm8k couldn't be found on the Hugging Face Hub
2024-06-03:11:15:14,901 WARNING  [load.py:1631] Using the latest cached version of the dataset since gsm8k couldn't be found on the Hugging Face Hub
Found the latest cached dataset configuration 'main' at /private/home/beidic/.cache/huggingface/datasets/gsm8k/main/0.0.0/e53f048856ff4f594e959d75785d2c2d37b678ee (last modified on Thu May 16 07:01:08 2024).
2024-06-03:11:15:14,905 WARNING  [cache.py:95] Found the latest cached dataset configuration 'main' at /private/home/beidic/.cache/huggingface/datasets/gsm8k/main/0.0.0/e53f048856ff4f594e959d75785d2c2d37b678ee (last modified on Thu May 16 07:01:08 2024).
2024-06-03:11:15:15,367 INFO     [task.py:395] Building contexts for gsm8k on rank 2...
  0%|          | 0/165 [00:00<?, ?it/s]  8%|▊         | 13/165 [00:00<00:01, 121.10it/s] 16%|█▌        | 26/165 [00:00<00:01, 123.68it/s] 24%|██▍       | 40/165 [00:00<00:00, 127.91it/s] 33%|███▎      | 54/165 [00:00<00:00, 130.67it/s] 41%|████      | 68/165 [00:00<00:00, 130.56it/s] 50%|████▉     | 82/165 [00:00<00:00, 128.64it/s] 58%|█████▊    | 95/165 [00:00<00:00, 126.69it/s] 65%|██████▌   | 108/165 [00:00<00:00, 127.52it/s]Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
 74%|███████▍  | 122/165 [00:00<00:00, 128.92it/s] 82%|████████▏ | 136/165 [00:01<00:00, 130.89it/s]Using the latest cached version of the dataset since gsm8k couldn't be found on the Hugging Face Hub
2024-06-03:11:15:16,534 WARNING  [load.py:1631] Using the latest cached version of the dataset since gsm8k couldn't be found on the Hugging Face Hub
Found the latest cached dataset configuration 'main' at /private/home/beidic/.cache/huggingface/datasets/gsm8k/main/0.0.0/e53f048856ff4f594e959d75785d2c2d37b678ee (last modified on Thu May 16 07:01:08 2024).
2024-06-03:11:15:16,536 WARNING  [cache.py:95] Found the latest cached dataset configuration 'main' at /private/home/beidic/.cache/huggingface/datasets/gsm8k/main/0.0.0/e53f048856ff4f594e959d75785d2c2d37b678ee (last modified on Thu May 16 07:01:08 2024).
 91%|█████████ | 150/165 [00:01<00:00, 131.21it/s] 99%|█████████▉| 164/165 [00:01<00:00, 130.89it/s]100%|██████████| 165/165 [00:01<00:00, 129.22it/s]
2024-06-03:11:15:16,708 INFO     [task.py:395] Building contexts for gsm8k on rank 4...
  0%|          | 0/165 [00:00<?, ?it/s] 10%|▉         | 16/165 [00:00<00:00, 157.41it/s] 19%|█▉        | 32/165 [00:00<00:00, 142.54it/s] 28%|██▊       | 47/165 [00:00<00:00, 138.10it/s] 37%|███▋      | 61/165 [00:00<00:00, 136.06it/s] 45%|████▌     | 75/165 [00:00<00:00, 135.07it/s] 54%|█████▍    | 89/165 [00:00<00:00, 134.61it/s] 62%|██████▏   | 103/165 [00:00<00:00, 136.09it/s] 75%|███████▍  | 123/165 [00:00<00:00, 155.77it/s] 87%|████████▋ | 143/165 [00:00<00:00, 168.93it/s] 99%|█████████▉| 163/165 [00:01<00:00, 178.31it/s]100%|██████████| 165/165 [00:01<00:00, 155.50it/s]
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
Using the latest cached version of the dataset since gsm8k couldn't be found on the Hugging Face Hub
2024-06-03:11:15:32,647 WARNING  [load.py:1631] Using the latest cached version of the dataset since gsm8k couldn't be found on the Hugging Face Hub
Found the latest cached dataset configuration 'main' at /private/home/beidic/.cache/huggingface/datasets/gsm8k/main/0.0.0/e53f048856ff4f594e959d75785d2c2d37b678ee (last modified on Thu May 16 07:01:08 2024).
2024-06-03:11:15:32,649 WARNING  [cache.py:95] Found the latest cached dataset configuration 'main' at /private/home/beidic/.cache/huggingface/datasets/gsm8k/main/0.0.0/e53f048856ff4f594e959d75785d2c2d37b678ee (last modified on Thu May 16 07:01:08 2024).
2024-06-03:11:15:32,946 INFO     [task.py:395] Building contexts for gsm8k on rank 5...
  0%|          | 0/165 [00:00<?, ?it/s]  8%|▊         | 13/165 [00:00<00:01, 125.37it/s]Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
 16%|█▋        | 27/165 [00:00<00:01, 129.65it/s] 25%|██▍       | 41/165 [00:00<00:00, 133.42it/s] 33%|███▎      | 55/165 [00:00<00:00, 135.75it/s]Using the latest cached version of the dataset since gsm8k couldn't be found on the Hugging Face Hub
2024-06-03:11:15:33,425 WARNING  [load.py:1631] Using the latest cached version of the dataset since gsm8k couldn't be found on the Hugging Face Hub
Found the latest cached dataset configuration 'main' at /private/home/beidic/.cache/huggingface/datasets/gsm8k/main/0.0.0/e53f048856ff4f594e959d75785d2c2d37b678ee (last modified on Thu May 16 07:01:08 2024).
2024-06-03:11:15:33,427 WARNING  [cache.py:95] Found the latest cached dataset configuration 'main' at /private/home/beidic/.cache/huggingface/datasets/gsm8k/main/0.0.0/e53f048856ff4f594e959d75785d2c2d37b678ee (last modified on Thu May 16 07:01:08 2024).
 42%|████▏     | 69/165 [00:00<00:00, 136.24it/s] 50%|█████     | 83/165 [00:00<00:00, 136.99it/s]2024-06-03:11:15:33,625 INFO     [task.py:395] Building contexts for gsm8k on rank 1...
  0%|          | 0/165 [00:00<?, ?it/s] 63%|██████▎   | 104/165 [00:00<00:00, 159.35it/s] 13%|█▎        | 21/165 [00:00<00:00, 201.80it/s] 76%|███████▌  | 125/165 [00:00<00:00, 174.17it/s] 25%|██▌       | 42/165 [00:00<00:00, 203.21it/s] 88%|████████▊ | 146/165 [00:00<00:00, 184.16it/s] 38%|███▊      | 63/165 [00:00<00:00, 203.51it/s]100%|██████████| 165/165 [00:01<00:00, 162.89it/s]
 51%|█████     | 84/165 [00:00<00:00, 204.67it/s] 64%|██████▎   | 105/165 [00:00<00:00, 205.93it/s] 76%|███████▋  | 126/165 [00:00<00:00, 205.80it/s] 89%|████████▉ | 147/165 [00:00<00:00, 205.73it/s]100%|██████████| 165/165 [00:00<00:00, 205.10it/s]
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
2024-06-03:11:15:46,922 INFO     [xhuggingface.py:314] Using 8 devices with data parallelism
Using the latest cached version of the dataset since gsm8k couldn't be found on the Hugging Face Hub
2024-06-03:11:15:47,163 WARNING  [load.py:1631] Using the latest cached version of the dataset since gsm8k couldn't be found on the Hugging Face Hub
Found the latest cached dataset configuration 'main' at /private/home/beidic/.cache/huggingface/datasets/gsm8k/main/0.0.0/e53f048856ff4f594e959d75785d2c2d37b678ee (last modified on Thu May 16 07:01:08 2024).
2024-06-03:11:15:47,166 WARNING  [cache.py:95] Found the latest cached dataset configuration 'main' at /private/home/beidic/.cache/huggingface/datasets/gsm8k/main/0.0.0/e53f048856ff4f594e959d75785d2c2d37b678ee (last modified on Thu May 16 07:01:08 2024).
2024-06-03:11:15:47,354 INFO     [task.py:395] Building contexts for gsm8k on rank 0...
  0%|          | 0/165 [00:00<?, ?it/s] 13%|█▎        | 21/165 [00:00<00:00, 208.40it/s] 25%|██▌       | 42/165 [00:00<00:00, 209.15it/s] 38%|███▊      | 63/165 [00:00<00:00, 209.30it/s] 52%|█████▏    | 85/165 [00:00<00:00, 209.62it/s] 65%|██████▍   | 107/165 [00:00<00:00, 209.98it/s] 78%|███████▊  | 129/165 [00:00<00:00, 210.32it/s] 92%|█████████▏| 151/165 [00:00<00:00, 210.35it/s]100%|██████████| 165/165 [00:00<00:00, 210.03it/s]
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
Using the latest cached version of the dataset since gsm8k couldn't be found on the Hugging Face Hub
2024-06-03:11:15:52,098 WARNING  [load.py:1631] Using the latest cached version of the dataset since gsm8k couldn't be found on the Hugging Face Hub
Found the latest cached dataset configuration 'main' at /private/home/beidic/.cache/huggingface/datasets/gsm8k/main/0.0.0/e53f048856ff4f594e959d75785d2c2d37b678ee (last modified on Thu May 16 07:01:08 2024).
2024-06-03:11:15:52,100 WARNING  [cache.py:95] Found the latest cached dataset configuration 'main' at /private/home/beidic/.cache/huggingface/datasets/gsm8k/main/0.0.0/e53f048856ff4f594e959d75785d2c2d37b678ee (last modified on Thu May 16 07:01:08 2024).
2024-06-03:11:15:52,493 INFO     [task.py:395] Building contexts for gsm8k on rank 7...
  0%|          | 0/164 [00:00<?, ?it/s]  7%|▋         | 12/164 [00:00<00:01, 119.76it/s] 15%|█▌        | 25/164 [00:00<00:01, 121.37it/s] 23%|██▎       | 38/164 [00:00<00:01, 121.55it/s] 31%|███       | 51/164 [00:00<00:00, 121.18it/s] 39%|███▉      | 64/164 [00:00<00:00, 121.21it/s] 47%|████▋     | 77/164 [00:00<00:00, 121.46it/s] 55%|█████▍    | 90/164 [00:00<00:00, 121.59it/s] 63%|██████▎   | 103/164 [00:00<00:00, 121.62it/s] 71%|███████   | 116/164 [00:00<00:00, 121.86it/s] 79%|███████▊  | 129/164 [00:01<00:00, 121.86it/s] 87%|████████▋ | 142/164 [00:01<00:00, 122.02it/s] 95%|█████████▍| 155/164 [00:01<00:00, 122.03it/s]100%|██████████| 164/164 [00:01<00:00, 121.67it/s]
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
Using the latest cached version of the dataset since gsm8k couldn't be found on the Hugging Face Hub
2024-06-03:11:16:41,631 WARNING  [load.py:1631] Using the latest cached version of the dataset since gsm8k couldn't be found on the Hugging Face Hub
Found the latest cached dataset configuration 'main' at /private/home/beidic/.cache/huggingface/datasets/gsm8k/main/0.0.0/e53f048856ff4f594e959d75785d2c2d37b678ee (last modified on Thu May 16 07:01:08 2024).
2024-06-03:11:16:41,635 WARNING  [cache.py:95] Found the latest cached dataset configuration 'main' at /private/home/beidic/.cache/huggingface/datasets/gsm8k/main/0.0.0/e53f048856ff4f594e959d75785d2c2d37b678ee (last modified on Thu May 16 07:01:08 2024).
2024-06-03:11:16:42,468 INFO     [task.py:395] Building contexts for gsm8k on rank 6...
  0%|          | 0/165 [00:00<?, ?it/s]  4%|▍         | 7/165 [00:00<00:02, 64.46it/s]  8%|▊         | 14/165 [00:00<00:02, 59.73it/s] 13%|█▎        | 21/165 [00:00<00:02, 58.28it/s] 17%|█▋        | 28/165 [00:00<00:02, 60.78it/s] 21%|██        | 35/165 [00:00<00:02, 59.20it/s] 25%|██▌       | 42/165 [00:00<00:02, 60.39it/s] 30%|██▉       | 49/165 [00:00<00:01, 59.13it/s] 34%|███▍      | 56/165 [00:00<00:01, 60.96it/s] 38%|███▊      | 63/165 [00:01<00:01, 59.58it/s] 42%|████▏     | 70/165 [00:01<00:01, 58.66it/s] 47%|████▋     | 77/165 [00:01<00:01, 60.54it/s] 51%|█████     | 84/165 [00:01<00:01, 57.03it/s] 55%|█████▌    | 91/165 [00:01<00:01, 56.86it/s] 59%|█████▉    | 98/165 [00:01<00:01, 59.17it/s] 63%|██████▎   | 104/165 [00:01<00:01, 59.02it/s] 67%|██████▋   | 111/165 [00:01<00:00, 58.20it/s] 72%|███████▏  | 118/165 [00:01<00:00, 60.19it/s] 76%|███████▌  | 125/165 [00:02<00:00, 59.05it/s] 80%|████████  | 132/165 [00:02<00:00, 58.33it/s] 86%|████████▌ | 142/165 [00:02<00:00, 68.12it/s] 93%|█████████▎| 153/165 [00:02<00:00, 77.59it/s] 98%|█████████▊| 161/165 [00:02<00:00, 73.83it/s]100%|██████████| 165/165 [00:02<00:00, 63.03it/s]
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
Using the latest cached version of the dataset since gsm8k couldn't be found on the Hugging Face Hub
2024-06-03:11:16:47,424 WARNING  [load.py:1631] Using the latest cached version of the dataset since gsm8k couldn't be found on the Hugging Face Hub
Found the latest cached dataset configuration 'main' at /private/home/beidic/.cache/huggingface/datasets/gsm8k/main/0.0.0/e53f048856ff4f594e959d75785d2c2d37b678ee (last modified on Thu May 16 07:01:08 2024).
2024-06-03:11:16:47,427 WARNING  [cache.py:95] Found the latest cached dataset configuration 'main' at /private/home/beidic/.cache/huggingface/datasets/gsm8k/main/0.0.0/e53f048856ff4f594e959d75785d2c2d37b678ee (last modified on Thu May 16 07:01:08 2024).
2024-06-03:11:16:48,300 INFO     [task.py:395] Building contexts for gsm8k on rank 3...
  0%|          | 0/165 [00:00<?, ?it/s]  4%|▍         | 7/165 [00:00<00:02, 63.37it/s]  8%|▊         | 14/165 [00:00<00:02, 61.28it/s] 13%|█▎        | 21/165 [00:00<00:02, 60.11it/s] 19%|█▉        | 32/165 [00:00<00:01, 77.12it/s] 24%|██▍       | 40/165 [00:00<00:01, 77.61it/s] 29%|██▉       | 48/165 [00:00<00:01, 77.88it/s] 34%|███▍      | 56/165 [00:00<00:01, 78.19it/s] 39%|███▉      | 64/165 [00:00<00:01, 62.32it/s] 43%|████▎     | 71/165 [00:01<00:01, 48.62it/s] 47%|████▋     | 77/165 [00:01<00:02, 41.41it/s] 50%|████▉     | 82/165 [00:01<00:02, 41.47it/s] 56%|█████▋    | 93/165 [00:01<00:01, 55.81it/s] 62%|██████▏   | 102/165 [00:01<00:01, 61.44it/s] 66%|██████▌   | 109/165 [00:01<00:00, 60.87it/s] 73%|███████▎  | 120/165 [00:01<00:00, 72.97it/s] 78%|███████▊  | 128/165 [00:02<00:00, 67.51it/s] 82%|████████▏ | 136/165 [00:02<00:00, 48.05it/s] 86%|████████▌ | 142/165 [00:02<00:00, 45.06it/s] 90%|████████▉ | 148/165 [00:02<00:00, 41.38it/s] 95%|█████████▌| 157/165 [00:02<00:00, 50.71it/s]100%|██████████| 165/165 [00:02<00:00, 57.34it/s]
2024-06-03:11:17:01,441 INFO     [xevaluator.py:395] Running generate_until requests
2024-06-03:11:17:01,442 INFO     [xevaluator.py:395] Running generate_until requests
2024-06-03:11:17:01,442 INFO     [xevaluator.py:395] Running generate_until requests
2024-06-03:11:17:01,442 INFO     [xevaluator.py:395] Running generate_until requests
2024-06-03:11:17:01,442 INFO     [xevaluator.py:395] Running generate_until requests
2024-06-03:11:17:01,442 INFO     [xevaluator.py:395] Running generate_until requests
2024-06-03:11:17:01,442 INFO     [xevaluator.py:395] Running generate_until requests
2024-06-03:11:17:01,443 INFO     [xevaluator.py:395] Running generate_until requests
Running generate_until requests:   0%|          | 0/165 [00:00<?, ?it/s]Running generate_until requests:   1%|          | 1/165 [00:22<1:01:45, 22.60s/it]Running generate_until requests:   1%|          | 2/165 [00:42<56:20, 20.74s/it]  Running generate_until requests:   2%|▏         | 3/165 [00:57<49:26, 18.31s/it]Running generate_until requests:   2%|▏         | 4/165 [01:09<42:47, 15.95s/it]Running generate_until requests:   3%|▎         | 5/165 [01:19<36:05, 13.54s/it]Running generate_until requests:   4%|▎         | 6/165 [01:29<32:54, 12.42s/it]Running generate_until requests:   4%|▍         | 7/165 [01:35<27:14, 10.34s/it]Running generate_until requests:   5%|▍         | 8/165 [01:46<27:44, 10.60s/it]Running generate_until requests:   5%|▌         | 9/165 [01:57<27:43, 10.66s/it]Running generate_until requests:   6%|▌         | 10/165 [02:08<28:06, 10.88s/it]Running generate_until requests:   7%|▋         | 11/165 [02:16<25:45, 10.03s/it]Running generate_until requests:   7%|▋         | 12/165 [02:26<25:25,  9.97s/it]Running generate_until requests:   8%|▊         | 13/165 [02:37<25:44, 10.16s/it]Running generate_until requests:   8%|▊         | 14/165 [02:46<24:42,  9.82s/it]Running generate_until requests:   9%|▉         | 15/165 [02:57<25:45, 10.30s/it]Running generate_until requests:  10%|▉         | 16/165 [03:06<24:11,  9.74s/it]Running generate_until requests:  10%|█         | 17/165 [03:14<22:57,  9.30s/it]Running generate_until requests:  11%|█         | 18/165 [03:24<23:28,  9.58s/it]Running generate_until requests:  12%|█▏        | 19/165 [03:29<20:14,  8.32s/it]Running generate_until requests:  12%|█▏        | 20/165 [03:35<18:04,  7.48s/it]Running generate_until requests:  13%|█▎        | 21/165 [03:44<19:06,  7.96s/it]Running generate_until requests:  13%|█▎        | 22/165 [03:56<21:34,  9.05s/it]Running generate_until requests:  14%|█▍        | 23/165 [04:01<18:50,  7.96s/it]Running generate_until requests:  15%|█▍        | 24/165 [04:08<18:00,  7.66s/it]Running generate_until requests:  15%|█▌        | 25/165 [04:16<18:03,  7.74s/it]Running generate_until requests:  16%|█▌        | 26/165 [04:23<17:38,  7.62s/it]Running generate_until requests:  16%|█▋        | 27/165 [04:39<23:21, 10.16s/it]Running generate_until requests:  17%|█▋        | 28/165 [04:50<23:24, 10.25s/it]Running generate_until requests:  18%|█▊        | 29/165 [05:01<23:29, 10.36s/it]Running generate_until requests:  18%|█▊        | 30/165 [05:09<22:03,  9.80s/it]Running generate_until requests:  19%|█▉        | 31/165 [05:14<18:44,  8.39s/it]Running generate_until requests:  19%|█▉        | 32/165 [05:21<17:47,  8.02s/it]Running generate_until requests:  20%|██        | 33/165 [05:29<17:45,  8.07s/it]Running generate_until requests:  21%|██        | 34/165 [05:43<21:27,  9.83s/it]Running generate_until requests:  21%|██        | 35/165 [05:56<23:23, 10.80s/it]Running generate_until requests:  22%|██▏       | 36/165 [06:04<21:04,  9.80s/it]Running generate_until requests:  22%|██▏       | 37/165 [06:16<22:07, 10.37s/it]Running generate_until requests:  23%|██▎       | 38/165 [06:24<20:36,  9.73s/it]Running generate_until requests:  24%|██▎       | 39/165 [06:39<23:38, 11.26s/it]Running generate_until requests:  24%|██▍       | 40/165 [06:47<21:38, 10.39s/it]Running generate_until requests:  25%|██▍       | 41/165 [06:54<19:29,  9.43s/it]Running generate_until requests:  25%|██▌       | 42/165 [07:04<19:17,  9.41s/it]Running generate_until requests:  26%|██▌       | 43/165 [07:16<21:07, 10.39s/it]Running generate_until requests:  27%|██▋       | 44/165 [07:24<19:24,  9.62s/it]Running generate_until requests:  27%|██▋       | 45/165 [07:31<17:20,  8.67s/it]Running generate_until requests:  28%|██▊       | 46/165 [07:34<14:10,  7.15s/it]Running generate_until requests:  28%|██▊       | 47/165 [07:39<12:31,  6.36s/it]Running generate_until requests:  29%|██▉       | 48/165 [07:52<16:24,  8.41s/it]Running generate_until requests:  30%|██▉       | 49/165 [08:00<16:12,  8.39s/it]Running generate_until requests:  30%|███       | 50/165 [08:09<16:11,  8.45s/it]Running generate_until requests:  31%|███       | 51/165 [08:16<15:24,  8.11s/it]Running generate_until requests:  32%|███▏      | 52/165 [08:21<13:29,  7.16s/it]Running generate_until requests:  32%|███▏      | 53/165 [08:28<13:29,  7.23s/it]Running generate_until requests:  33%|███▎      | 54/165 [08:35<13:13,  7.15s/it]Running generate_until requests:  33%|███▎      | 55/165 [08:43<13:08,  7.17s/it]Running generate_until requests:  34%|███▍      | 56/165 [08:48<11:57,  6.58s/it]Running generate_until requests:  35%|███▍      | 57/165 [08:59<14:32,  8.08s/it]Running generate_until requests:  35%|███▌      | 58/165 [09:06<13:23,  7.50s/it]Running generate_until requests:  36%|███▌      | 59/165 [09:11<12:14,  6.93s/it]Running generate_until requests:  36%|███▋      | 60/165 [09:16<11:06,  6.34s/it]Running generate_until requests:  37%|███▋      | 61/165 [09:26<12:37,  7.29s/it]Running generate_until requests:  38%|███▊      | 62/165 [09:30<11:07,  6.48s/it]Running generate_until requests:  38%|███▊      | 63/165 [09:36<10:50,  6.37s/it]Running generate_until requests:  39%|███▉      | 64/165 [09:44<11:25,  6.79s/it]Running generate_until requests:  39%|███▉      | 65/165 [09:52<11:36,  6.97s/it]Running generate_until requests:  40%|████      | 66/165 [09:58<11:02,  6.70s/it]Running generate_until requests:  41%|████      | 67/165 [10:05<11:22,  6.96s/it]Running generate_until requests:  41%|████      | 68/165 [10:10<10:03,  6.22s/it]Running generate_until requests:  42%|████▏     | 69/165 [10:21<12:27,  7.79s/it]Running generate_until requests:  42%|████▏     | 70/165 [10:29<12:34,  7.94s/it]Running generate_until requests:  43%|████▎     | 71/165 [10:35<11:05,  7.08s/it]Running generate_until requests:  44%|████▎     | 72/165 [10:49<14:28,  9.34s/it]Running generate_until requests:  44%|████▍     | 73/165 [11:05<17:16, 11.27s/it]Running generate_until requests:  45%|████▍     | 74/165 [11:15<16:38, 10.97s/it]Running generate_until requests:  45%|████▌     | 75/165 [11:21<14:13,  9.48s/it]Running generate_until requests:  46%|████▌     | 76/165 [11:27<12:33,  8.46s/it]Running generate_until requests:  47%|████▋     | 77/165 [11:34<11:45,  8.02s/it]Running generate_until requests:  47%|████▋     | 78/165 [11:41<10:57,  7.56s/it]Running generate_until requests:  48%|████▊     | 79/165 [11:47<10:12,  7.12s/it]Running generate_until requests:  48%|████▊     | 80/165 [11:53<09:33,  6.75s/it]Running generate_until requests:  49%|████▉     | 81/165 [11:59<09:27,  6.75s/it]Running generate_until requests:  50%|████▉     | 82/165 [12:08<10:12,  7.37s/it]Running generate_until requests:  50%|█████     | 83/165 [12:21<12:22,  9.05s/it]Running generate_until requests:  51%|█████     | 84/165 [12:35<14:03, 10.41s/it]Running generate_until requests:  52%|█████▏    | 85/165 [12:39<11:25,  8.57s/it]Running generate_until requests:  52%|█████▏    | 86/165 [12:45<10:20,  7.85s/it]Running generate_until requests:  53%|█████▎    | 87/165 [12:56<11:12,  8.62s/it]Running generate_until requests:  53%|█████▎    | 88/165 [13:02<10:06,  7.88s/it]Running generate_until requests:  54%|█████▍    | 89/165 [13:11<10:19,  8.15s/it]Running generate_until requests:  55%|█████▍    | 90/165 [13:20<10:45,  8.61s/it]Running generate_until requests:  55%|█████▌    | 91/165 [13:24<08:54,  7.22s/it]Running generate_until requests:  56%|█████▌    | 92/165 [13:33<09:15,  7.60s/it]Running generate_until requests:  56%|█████▋    | 93/165 [13:38<08:15,  6.88s/it]Running generate_until requests:  57%|█████▋    | 94/165 [13:43<07:38,  6.46s/it]Running generate_until requests:  58%|█████▊    | 95/165 [13:47<06:27,  5.53s/it]Running generate_until requests:  58%|█████▊    | 96/165 [13:52<06:09,  5.36s/it]Running generate_until requests:  59%|█████▉    | 97/165 [13:59<06:44,  5.96s/it]Running generate_until requests:  59%|█████▉    | 98/165 [14:11<08:41,  7.78s/it]Running generate_until requests:  60%|██████    | 99/165 [14:20<08:50,  8.03s/it]Running generate_until requests:  61%|██████    | 100/165 [14:26<07:59,  7.38s/it]Running generate_until requests:  61%|██████    | 101/165 [14:37<09:13,  8.65s/it]Running generate_until requests:  62%|██████▏   | 102/165 [14:46<09:12,  8.77s/it]Running generate_until requests:  62%|██████▏   | 103/165 [15:00<10:29, 10.15s/it]Running generate_until requests:  63%|██████▎   | 104/165 [15:04<08:37,  8.49s/it]Running generate_until requests:  64%|██████▎   | 105/165 [15:12<08:15,  8.25s/it]Running generate_until requests:  64%|██████▍   | 106/165 [15:19<07:49,  7.95s/it]Running generate_until requests:  65%|██████▍   | 107/165 [15:25<06:56,  7.18s/it]Running generate_until requests:  65%|██████▌   | 108/165 [15:31<06:41,  7.05s/it]Running generate_until requests:  66%|██████▌   | 109/165 [15:41<07:18,  7.83s/it]Running generate_until requests:  67%|██████▋   | 110/165 [15:48<07:04,  7.72s/it]Running generate_until requests:  67%|██████▋   | 111/165 [16:01<08:12,  9.13s/it]Running generate_until requests:  68%|██████▊   | 112/165 [16:07<07:13,  8.18s/it]Running generate_until requests:  68%|██████▊   | 113/165 [16:13<06:39,  7.69s/it]Running generate_until requests:  69%|██████▉   | 114/165 [16:16<05:15,  6.19s/it]Running generate_until requests:  70%|██████▉   | 115/165 [16:24<05:39,  6.80s/it]Running generate_until requests:  70%|███████   | 116/165 [16:32<05:48,  7.12s/it]Running generate_until requests:  71%|███████   | 117/165 [16:38<05:23,  6.73s/it]Running generate_until requests:  72%|███████▏  | 118/165 [16:45<05:16,  6.74s/it]Running generate_until requests:  72%|███████▏  | 119/165 [16:52<05:17,  6.90s/it]Running generate_until requests:  73%|███████▎  | 120/165 [16:58<05:00,  6.68s/it]Running generate_until requests:  73%|███████▎  | 121/165 [17:04<04:46,  6.52s/it]Running generate_until requests:  74%|███████▍  | 122/165 [17:11<04:45,  6.63s/it]Running generate_until requests:  75%|███████▍  | 123/165 [17:17<04:23,  6.27s/it]Running generate_until requests:  75%|███████▌  | 124/165 [17:23<04:19,  6.32s/it]Running generate_until requests:  76%|███████▌  | 125/165 [17:36<05:28,  8.20s/it]Running generate_until requests:  76%|███████▋  | 126/165 [17:46<05:48,  8.93s/it]Running generate_until requests:  77%|███████▋  | 127/165 [17:52<05:05,  8.04s/it]Running generate_until requests:  78%|███████▊  | 128/165 [18:00<04:51,  7.87s/it]Running generate_until requests:  78%|███████▊  | 129/165 [18:06<04:21,  7.27s/it]Running generate_until requests:  79%|███████▉  | 130/165 [18:11<03:56,  6.75s/it]Running generate_until requests:  79%|███████▉  | 131/165 [18:23<04:38,  8.20s/it]Running generate_until requests:  80%|████████  | 132/165 [18:48<07:20, 13.34s/it]Running generate_until requests:  81%|████████  | 133/165 [18:53<05:44, 10.76s/it]Running generate_until requests:  81%|████████  | 134/165 [18:57<04:29,  8.69s/it]Running generate_until requests:  82%|████████▏ | 135/165 [18:59<03:24,  6.82s/it]Running generate_until requests:  82%|████████▏ | 136/165 [19:02<02:45,  5.71s/it]Running generate_until requests:  83%|████████▎ | 137/165 [19:08<02:39,  5.70s/it]Running generate_until requests:  84%|████████▎ | 138/165 [19:19<03:13,  7.18s/it]Running generate_until requests:  84%|████████▍ | 139/165 [19:24<02:51,  6.59s/it]Running generate_until requests:  85%|████████▍ | 140/165 [19:36<03:28,  8.36s/it]Running generate_until requests:  85%|████████▌ | 141/165 [19:41<02:52,  7.19s/it]Running generate_until requests:  86%|████████▌ | 142/165 [19:49<02:55,  7.64s/it]Running generate_until requests:  87%|████████▋ | 143/165 [19:54<02:24,  6.57s/it]Running generate_until requests:  87%|████████▋ | 144/165 [19:58<02:06,  6.01s/it]Running generate_until requests:  88%|████████▊ | 145/165 [20:02<01:48,  5.43s/it]Running generate_until requests:  88%|████████▊ | 146/165 [20:09<01:50,  5.82s/it]Running generate_until requests:  89%|████████▉ | 147/165 [20:14<01:41,  5.64s/it]Running generate_until requests:  90%|████████▉ | 148/165 [20:22<01:47,  6.34s/it]Running generate_until requests:  90%|█████████ | 149/165 [20:29<01:42,  6.43s/it]Running generate_until requests:  91%|█████████ | 150/165 [20:35<01:36,  6.43s/it]Running generate_until requests:  92%|█████████▏| 151/165 [20:44<01:40,  7.17s/it]Running generate_until requests:  92%|█████████▏| 152/165 [20:54<01:44,  8.06s/it]Running generate_until requests:  93%|█████████▎| 153/165 [21:02<01:34,  7.87s/it]Running generate_until requests:  93%|█████████▎| 154/165 [21:06<01:15,  6.88s/it]Running generate_until requests:  94%|█████████▍| 155/165 [21:17<01:20,  8.05s/it]Running generate_until requests:  95%|█████████▍| 156/165 [21:21<01:01,  6.83s/it]Running generate_until requests:  95%|█████████▌| 157/165 [21:25<00:48,  6.10s/it]Running generate_until requests:  96%|█████████▌| 158/165 [21:32<00:43,  6.25s/it]Running generate_until requests:  96%|█████████▋| 159/165 [21:41<00:42,  7.13s/it]Running generate_until requests:  97%|█████████▋| 160/165 [21:45<00:31,  6.23s/it]Running generate_until requests:  98%|█████████▊| 161/165 [21:50<00:23,  5.89s/it]Running generate_until requests:  98%|█████████▊| 162/165 [21:55<00:16,  5.48s/it]Running generate_until requests:  99%|█████████▉| 163/165 [21:58<00:09,  4.80s/it]Running generate_until requests:  99%|█████████▉| 164/165 [22:01<00:04,  4.20s/it]Running generate_until requests: 100%|██████████| 165/165 [22:07<00:00,  4.61s/it]Running generate_until requests: 100%|██████████| 165/165 [22:07<00:00,  8.04s/it]
