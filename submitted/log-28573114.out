M	__pycache__/cache.cpython-312.pyc
M	__pycache__/xevaluator.cpython-312.pyc
M	__pycache__/xhuggingface.cpython-312.pyc
Your branch is up to date with 'origin/yangexp2'.
Already up to date.
/private/home/beidic/.conda/envs/griffin/bin/python
[1m[31mERROR! `huggingface-cli login` uses an outdated login mechanism that is not compatible with the Hugging Face Hub backend anymore. Please use `huggingface-cli login instead.[0m
The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-cli` if you want to set the git credential as well.
Namespace(model='xhf', tasks='gsm8k', model_args='pretrained=meta-llama/Meta-Llama-3-8B-Instruct,cats=True,spr=0.1,,check=True,kernel_size=16,thr=0.1', num_fewshot=None, batch_size='1', max_batch_size=None, device=None, output_path=None, limit=0.5, topp=1.1, topk=64, spr=0.25, sink=8, local=256, use_cache=None, cache_requests=None, check_integrity=False, write_out=False, log_samples=False, show_config=False, include_path=None, gen_kwargs=None, verbosity='INFO', wandb_args='', predict_only=False, seed=[0, 1234, 1234], trust_remote_code=False)
Namespace(model='xhf', tasks='gsm8k', model_args='pretrained=meta-llama/Meta-Llama-3-8B-Instruct,cats=True,spr=0.1,,check=True,kernel_size=16,thr=0.1', num_fewshot=None, batch_size='1', max_batch_size=None, device=None, output_path=None, limit=0.5, topp=1.1, topk=64, spr=0.25, sink=8, local=256, use_cache=None, cache_requests=None, check_integrity=False, write_out=False, log_samples=False, show_config=False, include_path=None, gen_kwargs=None, verbosity='INFO', wandb_args='', predict_only=False, seed=[0, 1234, 1234], trust_remote_code=False)
Namespace(model='xhf', tasks='gsm8k', model_args='pretrained=meta-llama/Meta-Llama-3-8B-Instruct,cats=True,spr=0.1,,check=True,kernel_size=16,thr=0.1', num_fewshot=None, batch_size='1', max_batch_size=None, device=None, output_path=None, limit=0.5, topp=1.1, topk=64, spr=0.25, sink=8, local=256, use_cache=None, cache_requests=None, check_integrity=False, write_out=False, log_samples=False, show_config=False, include_path=None, gen_kwargs=None, verbosity='INFO', wandb_args='', predict_only=False, seed=[0, 1234, 1234], trust_remote_code=False)
Namespace(model='xhf', tasks='gsm8k', model_args='pretrained=meta-llama/Meta-Llama-3-8B-Instruct,cats=True,spr=0.1,,check=True,kernel_size=16,thr=0.1', num_fewshot=None, batch_size='1', max_batch_size=None, device=None, output_path=None, limit=0.5, topp=1.1, topk=64, spr=0.25, sink=8, local=256, use_cache=None, cache_requests=None, check_integrity=False, write_out=False, log_samples=False, show_config=False, include_path=None, gen_kwargs=None, verbosity='INFO', wandb_args='', predict_only=False, seed=[0, 1234, 1234], trust_remote_code=False)
Namespace(model='xhf', tasks='gsm8k', model_args='pretrained=meta-llama/Meta-Llama-3-8B-Instruct,cats=True,spr=0.1,,check=True,kernel_size=16,thr=0.1', num_fewshot=None, batch_size='1', max_batch_size=None, device=None, output_path=None, limit=0.5, topp=1.1, topk=64, spr=0.25, sink=8, local=256, use_cache=None, cache_requests=None, check_integrity=False, write_out=False, log_samples=False, show_config=False, include_path=None, gen_kwargs=None, verbosity='INFO', wandb_args='', predict_only=False, seed=[0, 1234, 1234], trust_remote_code=False)
Namespace(model='xhf', tasks='gsm8k', model_args='pretrained=meta-llama/Meta-Llama-3-8B-Instruct,cats=True,spr=0.1,,check=True,kernel_size=16,thr=0.1', num_fewshot=None, batch_size='1', max_batch_size=None, device=None, output_path=None, limit=0.5, topp=1.1, topk=64, spr=0.25, sink=8, local=256, use_cache=None, cache_requests=None, check_integrity=False, write_out=False, log_samples=False, show_config=False, include_path=None, gen_kwargs=None, verbosity='INFO', wandb_args='', predict_only=False, seed=[0, 1234, 1234], trust_remote_code=False)
Namespace(model='xhf', tasks='gsm8k', model_args='pretrained=meta-llama/Meta-Llama-3-8B-Instruct,cats=True,spr=0.1,,check=True,kernel_size=16,thr=0.1', num_fewshot=None, batch_size='1', max_batch_size=None, device=None, output_path=None, limit=0.5, topp=1.1, topk=64, spr=0.25, sink=8, local=256, use_cache=None, cache_requests=None, check_integrity=False, write_out=False, log_samples=False, show_config=False, include_path=None, gen_kwargs=None, verbosity='INFO', wandb_args='', predict_only=False, seed=[0, 1234, 1234], trust_remote_code=False)
Namespace(model='xhf', tasks='gsm8k', model_args='pretrained=meta-llama/Meta-Llama-3-8B-Instruct,cats=True,spr=0.1,,check=True,kernel_size=16,thr=0.1', num_fewshot=None, batch_size='1', max_batch_size=None, device=None, output_path=None, limit=0.5, topp=1.1, topk=64, spr=0.25, sink=8, local=256, use_cache=None, cache_requests=None, check_integrity=False, write_out=False, log_samples=False, show_config=False, include_path=None, gen_kwargs=None, verbosity='INFO', wandb_args='', predict_only=False, seed=[0, 1234, 1234], trust_remote_code=False)
Namespace(model='xhf', tasks='gsm8k', model_args='pretrained=meta-llama/Meta-Llama-3-8B-Instruct,cats=True,spr=0.2,,check=True,kernel_size=16,thr=0.1', num_fewshot=None, batch_size='1', max_batch_size=None, device=None, output_path=None, limit=0.5, topp=1.1, topk=64, spr=0.25, sink=8, local=256, use_cache=None, cache_requests=None, check_integrity=False, write_out=False, log_samples=False, show_config=False, include_path=None, gen_kwargs=None, verbosity='INFO', wandb_args='', predict_only=False, seed=[0, 1234, 1234], trust_remote_code=False)
Namespace(model='xhf', tasks='gsm8k', model_args='pretrained=meta-llama/Meta-Llama-3-8B-Instruct,cats=True,spr=0.2,,check=True,kernel_size=16,thr=0.1', num_fewshot=None, batch_size='1', max_batch_size=None, device=None, output_path=None, limit=0.5, topp=1.1, topk=64, spr=0.25, sink=8, local=256, use_cache=None, cache_requests=None, check_integrity=False, write_out=False, log_samples=False, show_config=False, include_path=None, gen_kwargs=None, verbosity='INFO', wandb_args='', predict_only=False, seed=[0, 1234, 1234], trust_remote_code=False)
Namespace(model='xhf', tasks='gsm8k', model_args='pretrained=meta-llama/Meta-Llama-3-8B-Instruct,cats=True,spr=0.2,,check=True,kernel_size=16,thr=0.1', num_fewshot=None, batch_size='1', max_batch_size=None, device=None, output_path=None, limit=0.5, topp=1.1, topk=64, spr=0.25, sink=8, local=256, use_cache=None, cache_requests=None, check_integrity=False, write_out=False, log_samples=False, show_config=False, include_path=None, gen_kwargs=None, verbosity='INFO', wandb_args='', predict_only=False, seed=[0, 1234, 1234], trust_remote_code=False)
Namespace(model='xhf', tasks='gsm8k', model_args='pretrained=meta-llama/Meta-Llama-3-8B-Instruct,cats=True,spr=0.2,,check=True,kernel_size=16,thr=0.1', num_fewshot=None, batch_size='1', max_batch_size=None, device=None, output_path=None, limit=0.5, topp=1.1, topk=64, spr=0.25, sink=8, local=256, use_cache=None, cache_requests=None, check_integrity=False, write_out=False, log_samples=False, show_config=False, include_path=None, gen_kwargs=None, verbosity='INFO', wandb_args='', predict_only=False, seed=[0, 1234, 1234], trust_remote_code=False)
Namespace(model='xhf', tasks='gsm8k', model_args='pretrained=meta-llama/Meta-Llama-3-8B-Instruct,cats=True,spr=0.2,,check=True,kernel_size=16,thr=0.1', num_fewshot=None, batch_size='1', max_batch_size=None, device=None, output_path=None, limit=0.5, topp=1.1, topk=64, spr=0.25, sink=8, local=256, use_cache=None, cache_requests=None, check_integrity=False, write_out=False, log_samples=False, show_config=False, include_path=None, gen_kwargs=None, verbosity='INFO', wandb_args='', predict_only=False, seed=[0, 1234, 1234], trust_remote_code=False)
Namespace(model='xhf', tasks='gsm8k', model_args='pretrained=meta-llama/Meta-Llama-3-8B-Instruct,cats=True,spr=0.2,,check=True,kernel_size=16,thr=0.1', num_fewshot=None, batch_size='1', max_batch_size=None, device=None, output_path=None, limit=0.5, topp=1.1, topk=64, spr=0.25, sink=8, local=256, use_cache=None, cache_requests=None, check_integrity=False, write_out=False, log_samples=False, show_config=False, include_path=None, gen_kwargs=None, verbosity='INFO', wandb_args='', predict_only=False, seed=[0, 1234, 1234], trust_remote_code=False)
Namespace(model='xhf', tasks='gsm8k', model_args='pretrained=meta-llama/Meta-Llama-3-8B-Instruct,cats=True,spr=0.2,,check=True,kernel_size=16,thr=0.1', num_fewshot=None, batch_size='1', max_batch_size=None, device=None, output_path=None, limit=0.5, topp=1.1, topk=64, spr=0.25, sink=8, local=256, use_cache=None, cache_requests=None, check_integrity=False, write_out=False, log_samples=False, show_config=False, include_path=None, gen_kwargs=None, verbosity='INFO', wandb_args='', predict_only=False, seed=[0, 1234, 1234], trust_remote_code=False)
Namespace(model='xhf', tasks='gsm8k', model_args='pretrained=meta-llama/Meta-Llama-3-8B-Instruct,cats=True,spr=0.2,,check=True,kernel_size=16,thr=0.1', num_fewshot=None, batch_size='1', max_batch_size=None, device=None, output_path=None, limit=0.5, topp=1.1, topk=64, spr=0.25, sink=8, local=256, use_cache=None, cache_requests=None, check_integrity=False, write_out=False, log_samples=False, show_config=False, include_path=None, gen_kwargs=None, verbosity='INFO', wandb_args='', predict_only=False, seed=[0, 1234, 1234], trust_remote_code=False)
7306 1950 3.7466666666666666
6898 1812 3.806843267108168
6930 1694 4.090909090909091
7710 1967 3.9196746314184034
7416 2011 3.687717553455992
7751 2084 3.7192898272552783
7919 2069 3.8274528757854034
8079 2144 3.768190298507463
xhf (pretrained=meta-llama/Meta-Llama-3-8B-Instruct,cats=True,spr=0.2,,check=True,kernel_size=16,thr=0.1), gen_kwargs: (None), limit: 0.5, num_fewshot: None, batch_size: 1
|Tasks|Version|     Filter     |n-shot|  Metric   |Value |   |Stderr|
|-----|------:|----------------|-----:|-----------|-----:|---|-----:|
|gsm8k|      3|strict-match    |     5|exact_match|0.4121|±  |0.0192|
|     |       |flexible-extract|     5|exact_match|0.6045|±  |0.0190|

Namespace(model='xhf', tasks='gsm8k', model_args='pretrained=meta-llama/Meta-Llama-3-8B-Instruct,cats=True,spr=0.3,,check=True,kernel_size=16,thr=0.1', num_fewshot=None, batch_size='1', max_batch_size=None, device=None, output_path=None, limit=0.5, topp=1.1, topk=64, spr=0.25, sink=8, local=256, use_cache=None, cache_requests=None, check_integrity=False, write_out=False, log_samples=False, show_config=False, include_path=None, gen_kwargs=None, verbosity='INFO', wandb_args='', predict_only=False, seed=[0, 1234, 1234], trust_remote_code=False)
Namespace(model='xhf', tasks='gsm8k', model_args='pretrained=meta-llama/Meta-Llama-3-8B-Instruct,cats=True,spr=0.3,,check=True,kernel_size=16,thr=0.1', num_fewshot=None, batch_size='1', max_batch_size=None, device=None, output_path=None, limit=0.5, topp=1.1, topk=64, spr=0.25, sink=8, local=256, use_cache=None, cache_requests=None, check_integrity=False, write_out=False, log_samples=False, show_config=False, include_path=None, gen_kwargs=None, verbosity='INFO', wandb_args='', predict_only=False, seed=[0, 1234, 1234], trust_remote_code=False)
Namespace(model='xhf', tasks='gsm8k', model_args='pretrained=meta-llama/Meta-Llama-3-8B-Instruct,cats=True,spr=0.3,,check=True,kernel_size=16,thr=0.1', num_fewshot=None, batch_size='1', max_batch_size=None, device=None, output_path=None, limit=0.5, topp=1.1, topk=64, spr=0.25, sink=8, local=256, use_cache=None, cache_requests=None, check_integrity=False, write_out=False, log_samples=False, show_config=False, include_path=None, gen_kwargs=None, verbosity='INFO', wandb_args='', predict_only=False, seed=[0, 1234, 1234], trust_remote_code=False)
Namespace(model='xhf', tasks='gsm8k', model_args='pretrained=meta-llama/Meta-Llama-3-8B-Instruct,cats=True,spr=0.3,,check=True,kernel_size=16,thr=0.1', num_fewshot=None, batch_size='1', max_batch_size=None, device=None, output_path=None, limit=0.5, topp=1.1, topk=64, spr=0.25, sink=8, local=256, use_cache=None, cache_requests=None, check_integrity=False, write_out=False, log_samples=False, show_config=False, include_path=None, gen_kwargs=None, verbosity='INFO', wandb_args='', predict_only=False, seed=[0, 1234, 1234], trust_remote_code=False)
Namespace(model='xhf', tasks='gsm8k', model_args='pretrained=meta-llama/Meta-Llama-3-8B-Instruct,cats=True,spr=0.3,,check=True,kernel_size=16,thr=0.1', num_fewshot=None, batch_size='1', max_batch_size=None, device=None, output_path=None, limit=0.5, topp=1.1, topk=64, spr=0.25, sink=8, local=256, use_cache=None, cache_requests=None, check_integrity=False, write_out=False, log_samples=False, show_config=False, include_path=None, gen_kwargs=None, verbosity='INFO', wandb_args='', predict_only=False, seed=[0, 1234, 1234], trust_remote_code=False)
Namespace(model='xhf', tasks='gsm8k', model_args='pretrained=meta-llama/Meta-Llama-3-8B-Instruct,cats=True,spr=0.3,,check=True,kernel_size=16,thr=0.1', num_fewshot=None, batch_size='1', max_batch_size=None, device=None, output_path=None, limit=0.5, topp=1.1, topk=64, spr=0.25, sink=8, local=256, use_cache=None, cache_requests=None, check_integrity=False, write_out=False, log_samples=False, show_config=False, include_path=None, gen_kwargs=None, verbosity='INFO', wandb_args='', predict_only=False, seed=[0, 1234, 1234], trust_remote_code=False)
Namespace(model='xhf', tasks='gsm8k', model_args='pretrained=meta-llama/Meta-Llama-3-8B-Instruct,cats=True,spr=0.3,,check=True,kernel_size=16,thr=0.1', num_fewshot=None, batch_size='1', max_batch_size=None, device=None, output_path=None, limit=0.5, topp=1.1, topk=64, spr=0.25, sink=8, local=256, use_cache=None, cache_requests=None, check_integrity=False, write_out=False, log_samples=False, show_config=False, include_path=None, gen_kwargs=None, verbosity='INFO', wandb_args='', predict_only=False, seed=[0, 1234, 1234], trust_remote_code=False)
Namespace(model='xhf', tasks='gsm8k', model_args='pretrained=meta-llama/Meta-Llama-3-8B-Instruct,cats=True,spr=0.3,,check=True,kernel_size=16,thr=0.1', num_fewshot=None, batch_size='1', max_batch_size=None, device=None, output_path=None, limit=0.5, topp=1.1, topk=64, spr=0.25, sink=8, local=256, use_cache=None, cache_requests=None, check_integrity=False, write_out=False, log_samples=False, show_config=False, include_path=None, gen_kwargs=None, verbosity='INFO', wandb_args='', predict_only=False, seed=[0, 1234, 1234], trust_remote_code=False)
7476 999 7.483483483483483
7940 1025 7.746341463414634
7203 899 8.012235817575084
8362 1087 7.6927322907083715
7333 941 7.792773645058449
8177 1058 7.728733459357278
7786 1006 7.739562624254473
7724 1009 7.655104063429138
xhf (pretrained=meta-llama/Meta-Llama-3-8B-Instruct,cats=True,spr=0.3,,check=True,kernel_size=16,thr=0.1), gen_kwargs: (None), limit: 0.5, num_fewshot: None, batch_size: 1
|Tasks|Version|     Filter     |n-shot|  Metric   |Value |   |Stderr|
|-----|------:|----------------|-----:|-----------|-----:|---|-----:|
|gsm8k|      3|strict-match    |     5|exact_match|0.5970|±  |0.0191|
|     |       |flexible-extract|     5|exact_match|0.6182|±  |0.0189|

Namespace(model='xhf', tasks='gsm8k', model_args='pretrained=meta-llama/Meta-Llama-3-8B-Instruct,cats=True,spr=0.4,,check=True,kernel_size=16,thr=0.1', num_fewshot=None, batch_size='1', max_batch_size=None, device=None, output_path=None, limit=0.5, topp=1.1, topk=64, spr=0.25, sink=8, local=256, use_cache=None, cache_requests=None, check_integrity=False, write_out=False, log_samples=False, show_config=False, include_path=None, gen_kwargs=None, verbosity='INFO', wandb_args='', predict_only=False, seed=[0, 1234, 1234], trust_remote_code=False)
Namespace(model='xhf', tasks='gsm8k', model_args='pretrained=meta-llama/Meta-Llama-3-8B-Instruct,cats=True,spr=0.4,,check=True,kernel_size=16,thr=0.1', num_fewshot=None, batch_size='1', max_batch_size=None, device=None, output_path=None, limit=0.5, topp=1.1, topk=64, spr=0.25, sink=8, local=256, use_cache=None, cache_requests=None, check_integrity=False, write_out=False, log_samples=False, show_config=False, include_path=None, gen_kwargs=None, verbosity='INFO', wandb_args='', predict_only=False, seed=[0, 1234, 1234], trust_remote_code=False)
Namespace(model='xhf', tasks='gsm8k', model_args='pretrained=meta-llama/Meta-Llama-3-8B-Instruct,cats=True,spr=0.4,,check=True,kernel_size=16,thr=0.1', num_fewshot=None, batch_size='1', max_batch_size=None, device=None, output_path=None, limit=0.5, topp=1.1, topk=64, spr=0.25, sink=8, local=256, use_cache=None, cache_requests=None, check_integrity=False, write_out=False, log_samples=False, show_config=False, include_path=None, gen_kwargs=None, verbosity='INFO', wandb_args='', predict_only=False, seed=[0, 1234, 1234], trust_remote_code=False)
Namespace(model='xhf', tasks='gsm8k', model_args='pretrained=meta-llama/Meta-Llama-3-8B-Instruct,cats=True,spr=0.4,,check=True,kernel_size=16,thr=0.1', num_fewshot=None, batch_size='1', max_batch_size=None, device=None, output_path=None, limit=0.5, topp=1.1, topk=64, spr=0.25, sink=8, local=256, use_cache=None, cache_requests=None, check_integrity=False, write_out=False, log_samples=False, show_config=False, include_path=None, gen_kwargs=None, verbosity='INFO', wandb_args='', predict_only=False, seed=[0, 1234, 1234], trust_remote_code=False)
Namespace(model='xhf', tasks='gsm8k', model_args='pretrained=meta-llama/Meta-Llama-3-8B-Instruct,cats=True,spr=0.4,,check=True,kernel_size=16,thr=0.1', num_fewshot=None, batch_size='1', max_batch_size=None, device=None, output_path=None, limit=0.5, topp=1.1, topk=64, spr=0.25, sink=8, local=256, use_cache=None, cache_requests=None, check_integrity=False, write_out=False, log_samples=False, show_config=False, include_path=None, gen_kwargs=None, verbosity='INFO', wandb_args='', predict_only=False, seed=[0, 1234, 1234], trust_remote_code=False)
Namespace(model='xhf', tasks='gsm8k', model_args='pretrained=meta-llama/Meta-Llama-3-8B-Instruct,cats=True,spr=0.4,,check=True,kernel_size=16,thr=0.1', num_fewshot=None, batch_size='1', max_batch_size=None, device=None, output_path=None, limit=0.5, topp=1.1, topk=64, spr=0.25, sink=8, local=256, use_cache=None, cache_requests=None, check_integrity=False, write_out=False, log_samples=False, show_config=False, include_path=None, gen_kwargs=None, verbosity='INFO', wandb_args='', predict_only=False, seed=[0, 1234, 1234], trust_remote_code=False)
Namespace(model='xhf', tasks='gsm8k', model_args='pretrained=meta-llama/Meta-Llama-3-8B-Instruct,cats=True,spr=0.4,,check=True,kernel_size=16,thr=0.1', num_fewshot=None, batch_size='1', max_batch_size=None, device=None, output_path=None, limit=0.5, topp=1.1, topk=64, spr=0.25, sink=8, local=256, use_cache=None, cache_requests=None, check_integrity=False, write_out=False, log_samples=False, show_config=False, include_path=None, gen_kwargs=None, verbosity='INFO', wandb_args='', predict_only=False, seed=[0, 1234, 1234], trust_remote_code=False)
Namespace(model='xhf', tasks='gsm8k', model_args='pretrained=meta-llama/Meta-Llama-3-8B-Instruct,cats=True,spr=0.4,,check=True,kernel_size=16,thr=0.1', num_fewshot=None, batch_size='1', max_batch_size=None, device=None, output_path=None, limit=0.5, topp=1.1, topk=64, spr=0.25, sink=8, local=256, use_cache=None, cache_requests=None, check_integrity=False, write_out=False, log_samples=False, show_config=False, include_path=None, gen_kwargs=None, verbosity='INFO', wandb_args='', predict_only=False, seed=[0, 1234, 1234], trust_remote_code=False)
6588 527 12.500948766603415
7682 621 12.37037037037037
7117 584 12.186643835616438
7144 583 12.25385934819897
7343 587 12.509369676320272
7823 630 12.417460317460318
8266 691 11.962373371924746
8433 700 12.047142857142857
xhf (pretrained=meta-llama/Meta-Llama-3-8B-Instruct,cats=True,spr=0.4,,check=True,kernel_size=16,thr=0.1), gen_kwargs: (None), limit: 0.5, num_fewshot: None, batch_size: 1
|Tasks|Version|     Filter     |n-shot|  Metric   |Value |   |Stderr|
|-----|------:|----------------|-----:|-----------|-----:|---|-----:|
|gsm8k|      3|strict-match    |     5|exact_match|0.7167|±  |0.0176|
|     |       |flexible-extract|     5|exact_match|0.7197|±  |0.0175|

Namespace(model='xhf', tasks='gsm8k', model_args='pretrained=meta-llama/Meta-Llama-3-8B-Instruct,cats=True,spr=0.5,,check=True,kernel_size=16,thr=0.1', num_fewshot=None, batch_size='1', max_batch_size=None, device=None, output_path=None, limit=0.5, topp=1.1, topk=64, spr=0.25, sink=8, local=256, use_cache=None, cache_requests=None, check_integrity=False, write_out=False, log_samples=False, show_config=False, include_path=None, gen_kwargs=None, verbosity='INFO', wandb_args='', predict_only=False, seed=[0, 1234, 1234], trust_remote_code=False)
Namespace(model='xhf', tasks='gsm8k', model_args='pretrained=meta-llama/Meta-Llama-3-8B-Instruct,cats=True,spr=0.5,,check=True,kernel_size=16,thr=0.1', num_fewshot=None, batch_size='1', max_batch_size=None, device=None, output_path=None, limit=0.5, topp=1.1, topk=64, spr=0.25, sink=8, local=256, use_cache=None, cache_requests=None, check_integrity=False, write_out=False, log_samples=False, show_config=False, include_path=None, gen_kwargs=None, verbosity='INFO', wandb_args='', predict_only=False, seed=[0, 1234, 1234], trust_remote_code=False)
Namespace(model='xhf', tasks='gsm8k', model_args='pretrained=meta-llama/Meta-Llama-3-8B-Instruct,cats=True,spr=0.5,,check=True,kernel_size=16,thr=0.1', num_fewshot=None, batch_size='1', max_batch_size=None, device=None, output_path=None, limit=0.5, topp=1.1, topk=64, spr=0.25, sink=8, local=256, use_cache=None, cache_requests=None, check_integrity=False, write_out=False, log_samples=False, show_config=False, include_path=None, gen_kwargs=None, verbosity='INFO', wandb_args='', predict_only=False, seed=[0, 1234, 1234], trust_remote_code=False)
Namespace(model='xhf', tasks='gsm8k', model_args='pretrained=meta-llama/Meta-Llama-3-8B-Instruct,cats=True,spr=0.5,,check=True,kernel_size=16,thr=0.1', num_fewshot=None, batch_size='1', max_batch_size=None, device=None, output_path=None, limit=0.5, topp=1.1, topk=64, spr=0.25, sink=8, local=256, use_cache=None, cache_requests=None, check_integrity=False, write_out=False, log_samples=False, show_config=False, include_path=None, gen_kwargs=None, verbosity='INFO', wandb_args='', predict_only=False, seed=[0, 1234, 1234], trust_remote_code=False)
Namespace(model='xhf', tasks='gsm8k', model_args='pretrained=meta-llama/Meta-Llama-3-8B-Instruct,cats=True,spr=0.5,,check=True,kernel_size=16,thr=0.1', num_fewshot=None, batch_size='1', max_batch_size=None, device=None, output_path=None, limit=0.5, topp=1.1, topk=64, spr=0.25, sink=8, local=256, use_cache=None, cache_requests=None, check_integrity=False, write_out=False, log_samples=False, show_config=False, include_path=None, gen_kwargs=None, verbosity='INFO', wandb_args='', predict_only=False, seed=[0, 1234, 1234], trust_remote_code=False)
Namespace(model='xhf', tasks='gsm8k', model_args='pretrained=meta-llama/Meta-Llama-3-8B-Instruct,cats=True,spr=0.5,,check=True,kernel_size=16,thr=0.1', num_fewshot=None, batch_size='1', max_batch_size=None, device=None, output_path=None, limit=0.5, topp=1.1, topk=64, spr=0.25, sink=8, local=256, use_cache=None, cache_requests=None, check_integrity=False, write_out=False, log_samples=False, show_config=False, include_path=None, gen_kwargs=None, verbosity='INFO', wandb_args='', predict_only=False, seed=[0, 1234, 1234], trust_remote_code=False)
Namespace(model='xhf', tasks='gsm8k', model_args='pretrained=meta-llama/Meta-Llama-3-8B-Instruct,cats=True,spr=0.5,,check=True,kernel_size=16,thr=0.1', num_fewshot=None, batch_size='1', max_batch_size=None, device=None, output_path=None, limit=0.5, topp=1.1, topk=64, spr=0.25, sink=8, local=256, use_cache=None, cache_requests=None, check_integrity=False, write_out=False, log_samples=False, show_config=False, include_path=None, gen_kwargs=None, verbosity='INFO', wandb_args='', predict_only=False, seed=[0, 1234, 1234], trust_remote_code=False)
Namespace(model='xhf', tasks='gsm8k', model_args='pretrained=meta-llama/Meta-Llama-3-8B-Instruct,cats=True,spr=0.5,,check=True,kernel_size=16,thr=0.1', num_fewshot=None, batch_size='1', max_batch_size=None, device=None, output_path=None, limit=0.5, topp=1.1, topk=64, spr=0.25, sink=8, local=256, use_cache=None, cache_requests=None, check_integrity=False, write_out=False, log_samples=False, show_config=False, include_path=None, gen_kwargs=None, verbosity='INFO', wandb_args='', predict_only=False, seed=[0, 1234, 1234], trust_remote_code=False)
6770 458 14.781659388646288
7792 532 14.646616541353383
7309 489 14.946830265848671
7178 494 14.530364372469636
7916 539 14.686456400742115
7893 533 14.808630393996248
7265 494 14.706477732793521
8049 554 14.528880866425993
xhf (pretrained=meta-llama/Meta-Llama-3-8B-Instruct,cats=True,spr=0.5,,check=True,kernel_size=16,thr=0.1), gen_kwargs: (None), limit: 0.5, num_fewshot: None, batch_size: 1
|Tasks|Version|     Filter     |n-shot|  Metric   |Value |   |Stderr|
|-----|------:|----------------|-----:|-----------|-----:|---|-----:|
|gsm8k|      3|strict-match    |     5|exact_match|0.7152|±  |0.0176|
|     |       |flexible-extract|     5|exact_match|0.7152|±  |0.0176|

Namespace(model='xhf', tasks='gsm8k', model_args='pretrained=meta-llama/Meta-Llama-3-8B-Instruct,cats=True,spr=0.6,,check=True,kernel_size=16,thr=0.1', num_fewshot=None, batch_size='1', max_batch_size=None, device=None, output_path=None, limit=0.5, topp=1.1, topk=64, spr=0.25, sink=8, local=256, use_cache=None, cache_requests=None, check_integrity=False, write_out=False, log_samples=False, show_config=False, include_path=None, gen_kwargs=None, verbosity='INFO', wandb_args='', predict_only=False, seed=[0, 1234, 1234], trust_remote_code=False)
Namespace(model='xhf', tasks='gsm8k', model_args='pretrained=meta-llama/Meta-Llama-3-8B-Instruct,cats=True,spr=0.6,,check=True,kernel_size=16,thr=0.1', num_fewshot=None, batch_size='1', max_batch_size=None, device=None, output_path=None, limit=0.5, topp=1.1, topk=64, spr=0.25, sink=8, local=256, use_cache=None, cache_requests=None, check_integrity=False, write_out=False, log_samples=False, show_config=False, include_path=None, gen_kwargs=None, verbosity='INFO', wandb_args='', predict_only=False, seed=[0, 1234, 1234], trust_remote_code=False)
Namespace(model='xhf', tasks='gsm8k', model_args='pretrained=meta-llama/Meta-Llama-3-8B-Instruct,cats=True,spr=0.6,,check=True,kernel_size=16,thr=0.1', num_fewshot=None, batch_size='1', max_batch_size=None, device=None, output_path=None, limit=0.5, topp=1.1, topk=64, spr=0.25, sink=8, local=256, use_cache=None, cache_requests=None, check_integrity=False, write_out=False, log_samples=False, show_config=False, include_path=None, gen_kwargs=None, verbosity='INFO', wandb_args='', predict_only=False, seed=[0, 1234, 1234], trust_remote_code=False)
Namespace(model='xhf', tasks='gsm8k', model_args='pretrained=meta-llama/Meta-Llama-3-8B-Instruct,cats=True,spr=0.6,,check=True,kernel_size=16,thr=0.1', num_fewshot=None, batch_size='1', max_batch_size=None, device=None, output_path=None, limit=0.5, topp=1.1, topk=64, spr=0.25, sink=8, local=256, use_cache=None, cache_requests=None, check_integrity=False, write_out=False, log_samples=False, show_config=False, include_path=None, gen_kwargs=None, verbosity='INFO', wandb_args='', predict_only=False, seed=[0, 1234, 1234], trust_remote_code=False)
Namespace(model='xhf', tasks='gsm8k', model_args='pretrained=meta-llama/Meta-Llama-3-8B-Instruct,cats=True,spr=0.6,,check=True,kernel_size=16,thr=0.1', num_fewshot=None, batch_size='1', max_batch_size=None, device=None, output_path=None, limit=0.5, topp=1.1, topk=64, spr=0.25, sink=8, local=256, use_cache=None, cache_requests=None, check_integrity=False, write_out=False, log_samples=False, show_config=False, include_path=None, gen_kwargs=None, verbosity='INFO', wandb_args='', predict_only=False, seed=[0, 1234, 1234], trust_remote_code=False)
Namespace(model='xhf', tasks='gsm8k', model_args='pretrained=meta-llama/Meta-Llama-3-8B-Instruct,cats=True,spr=0.6,,check=True,kernel_size=16,thr=0.1', num_fewshot=None, batch_size='1', max_batch_size=None, device=None, output_path=None, limit=0.5, topp=1.1, topk=64, spr=0.25, sink=8, local=256, use_cache=None, cache_requests=None, check_integrity=False, write_out=False, log_samples=False, show_config=False, include_path=None, gen_kwargs=None, verbosity='INFO', wandb_args='', predict_only=False, seed=[0, 1234, 1234], trust_remote_code=False)
Namespace(model='xhf', tasks='gsm8k', model_args='pretrained=meta-llama/Meta-Llama-3-8B-Instruct,cats=True,spr=0.6,,check=True,kernel_size=16,thr=0.1', num_fewshot=None, batch_size='1', max_batch_size=None, device=None, output_path=None, limit=0.5, topp=1.1, topk=64, spr=0.25, sink=8, local=256, use_cache=None, cache_requests=None, check_integrity=False, write_out=False, log_samples=False, show_config=False, include_path=None, gen_kwargs=None, verbosity='INFO', wandb_args='', predict_only=False, seed=[0, 1234, 1234], trust_remote_code=False)
Namespace(model='xhf', tasks='gsm8k', model_args='pretrained=meta-llama/Meta-Llama-3-8B-Instruct,cats=True,spr=0.6,,check=True,kernel_size=16,thr=0.1', num_fewshot=None, batch_size='1', max_batch_size=None, device=None, output_path=None, limit=0.5, topp=1.1, topk=64, spr=0.25, sink=8, local=256, use_cache=None, cache_requests=None, check_integrity=False, write_out=False, log_samples=False, show_config=False, include_path=None, gen_kwargs=None, verbosity='INFO', wandb_args='', predict_only=False, seed=[0, 1234, 1234], trust_remote_code=False)
6835 437 15.640732265446225
7503 483 15.53416149068323
7155 461 15.52060737527115
7923 508 15.596456692913385
7792 502 15.52191235059761
8078 517 15.624758220502901
7295 470 15.52127659574468
7696 492 15.642276422764228
xhf (pretrained=meta-llama/Meta-Llama-3-8B-Instruct,cats=True,spr=0.6,,check=True,kernel_size=16,thr=0.1), gen_kwargs: (None), limit: 0.5, num_fewshot: None, batch_size: 1
|Tasks|Version|     Filter     |n-shot|  Metric   |Value |   |Stderr|
|-----|------:|----------------|-----:|-----------|-----:|---|-----:|
|gsm8k|      3|strict-match    |     5|exact_match|0.7561|±  |0.0167|
|     |       |flexible-extract|     5|exact_match|0.7576|±  |0.0167|

Namespace(model='xhf', tasks='gsm8k', model_args='pretrained=meta-llama/Meta-Llama-3-8B-Instruct,cats=True,spr=0.7,,check=True,kernel_size=16,thr=0.1', num_fewshot=None, batch_size='1', max_batch_size=None, device=None, output_path=None, limit=0.5, topp=1.1, topk=64, spr=0.25, sink=8, local=256, use_cache=None, cache_requests=None, check_integrity=False, write_out=False, log_samples=False, show_config=False, include_path=None, gen_kwargs=None, verbosity='INFO', wandb_args='', predict_only=False, seed=[0, 1234, 1234], trust_remote_code=False)
Namespace(model='xhf', tasks='gsm8k', model_args='pretrained=meta-llama/Meta-Llama-3-8B-Instruct,cats=True,spr=0.7,,check=True,kernel_size=16,thr=0.1', num_fewshot=None, batch_size='1', max_batch_size=None, device=None, output_path=None, limit=0.5, topp=1.1, topk=64, spr=0.25, sink=8, local=256, use_cache=None, cache_requests=None, check_integrity=False, write_out=False, log_samples=False, show_config=False, include_path=None, gen_kwargs=None, verbosity='INFO', wandb_args='', predict_only=False, seed=[0, 1234, 1234], trust_remote_code=False)
Namespace(model='xhf', tasks='gsm8k', model_args='pretrained=meta-llama/Meta-Llama-3-8B-Instruct,cats=True,spr=0.7,,check=True,kernel_size=16,thr=0.1', num_fewshot=None, batch_size='1', max_batch_size=None, device=None, output_path=None, limit=0.5, topp=1.1, topk=64, spr=0.25, sink=8, local=256, use_cache=None, cache_requests=None, check_integrity=False, write_out=False, log_samples=False, show_config=False, include_path=None, gen_kwargs=None, verbosity='INFO', wandb_args='', predict_only=False, seed=[0, 1234, 1234], trust_remote_code=False)
Namespace(model='xhf', tasks='gsm8k', model_args='pretrained=meta-llama/Meta-Llama-3-8B-Instruct,cats=True,spr=0.7,,check=True,kernel_size=16,thr=0.1', num_fewshot=None, batch_size='1', max_batch_size=None, device=None, output_path=None, limit=0.5, topp=1.1, topk=64, spr=0.25, sink=8, local=256, use_cache=None, cache_requests=None, check_integrity=False, write_out=False, log_samples=False, show_config=False, include_path=None, gen_kwargs=None, verbosity='INFO', wandb_args='', predict_only=False, seed=[0, 1234, 1234], trust_remote_code=False)
Namespace(model='xhf', tasks='gsm8k', model_args='pretrained=meta-llama/Meta-Llama-3-8B-Instruct,cats=True,spr=0.7,,check=True,kernel_size=16,thr=0.1', num_fewshot=None, batch_size='1', max_batch_size=None, device=None, output_path=None, limit=0.5, topp=1.1, topk=64, spr=0.25, sink=8, local=256, use_cache=None, cache_requests=None, check_integrity=False, write_out=False, log_samples=False, show_config=False, include_path=None, gen_kwargs=None, verbosity='INFO', wandb_args='', predict_only=False, seed=[0, 1234, 1234], trust_remote_code=False)
Namespace(model='xhf', tasks='gsm8k', model_args='pretrained=meta-llama/Meta-Llama-3-8B-Instruct,cats=True,spr=0.7,,check=True,kernel_size=16,thr=0.1', num_fewshot=None, batch_size='1', max_batch_size=None, device=None, output_path=None, limit=0.5, topp=1.1, topk=64, spr=0.25, sink=8, local=256, use_cache=None, cache_requests=None, check_integrity=False, write_out=False, log_samples=False, show_config=False, include_path=None, gen_kwargs=None, verbosity='INFO', wandb_args='', predict_only=False, seed=[0, 1234, 1234], trust_remote_code=False)
Namespace(model='xhf', tasks='gsm8k', model_args='pretrained=meta-llama/Meta-Llama-3-8B-Instruct,cats=True,spr=0.7,,check=True,kernel_size=16,thr=0.1', num_fewshot=None, batch_size='1', max_batch_size=None, device=None, output_path=None, limit=0.5, topp=1.1, topk=64, spr=0.25, sink=8, local=256, use_cache=None, cache_requests=None, check_integrity=False, write_out=False, log_samples=False, show_config=False, include_path=None, gen_kwargs=None, verbosity='INFO', wandb_args='', predict_only=False, seed=[0, 1234, 1234], trust_remote_code=False)
Namespace(model='xhf', tasks='gsm8k', model_args='pretrained=meta-llama/Meta-Llama-3-8B-Instruct,cats=True,spr=0.7,,check=True,kernel_size=16,thr=0.1', num_fewshot=None, batch_size='1', max_batch_size=None, device=None, output_path=None, limit=0.5, topp=1.1, topk=64, spr=0.25, sink=8, local=256, use_cache=None, cache_requests=None, check_integrity=False, write_out=False, log_samples=False, show_config=False, include_path=None, gen_kwargs=None, verbosity='INFO', wandb_args='', predict_only=False, seed=[0, 1234, 1234], trust_remote_code=False)
7859 495 15.876767676767678
8208 515 15.937864077669904
6558 412 15.91747572815534
7106 445 15.968539325842697
7521 474 15.867088607594937
7861 494 15.912955465587045
7448 468 15.914529914529915
8172 516 15.837209302325581
xhf (pretrained=meta-llama/Meta-Llama-3-8B-Instruct,cats=True,spr=0.7,,check=True,kernel_size=16,thr=0.1), gen_kwargs: (None), limit: 0.5, num_fewshot: None, batch_size: 1
|Tasks|Version|     Filter     |n-shot|  Metric   |Value |   |Stderr|
|-----|------:|----------------|-----:|-----------|-----:|---|-----:|
|gsm8k|      3|strict-match    |     5|exact_match|0.7364|±  |0.0172|
|     |       |flexible-extract|     5|exact_match|0.7424|±  |0.0170|

Namespace(model='xhf', tasks='gsm8k', model_args='pretrained=meta-llama/Meta-Llama-3-8B-Instruct,cats=True,spr=0.8,,check=True,kernel_size=16,thr=0.1', num_fewshot=None, batch_size='1', max_batch_size=None, device=None, output_path=None, limit=0.5, topp=1.1, topk=64, spr=0.25, sink=8, local=256, use_cache=None, cache_requests=None, check_integrity=False, write_out=False, log_samples=False, show_config=False, include_path=None, gen_kwargs=None, verbosity='INFO', wandb_args='', predict_only=False, seed=[0, 1234, 1234], trust_remote_code=False)
Namespace(model='xhf', tasks='gsm8k', model_args='pretrained=meta-llama/Meta-Llama-3-8B-Instruct,cats=True,spr=0.8,,check=True,kernel_size=16,thr=0.1', num_fewshot=None, batch_size='1', max_batch_size=None, device=None, output_path=None, limit=0.5, topp=1.1, topk=64, spr=0.25, sink=8, local=256, use_cache=None, cache_requests=None, check_integrity=False, write_out=False, log_samples=False, show_config=False, include_path=None, gen_kwargs=None, verbosity='INFO', wandb_args='', predict_only=False, seed=[0, 1234, 1234], trust_remote_code=False)
Namespace(model='xhf', tasks='gsm8k', model_args='pretrained=meta-llama/Meta-Llama-3-8B-Instruct,cats=True,spr=0.8,,check=True,kernel_size=16,thr=0.1', num_fewshot=None, batch_size='1', max_batch_size=None, device=None, output_path=None, limit=0.5, topp=1.1, topk=64, spr=0.25, sink=8, local=256, use_cache=None, cache_requests=None, check_integrity=False, write_out=False, log_samples=False, show_config=False, include_path=None, gen_kwargs=None, verbosity='INFO', wandb_args='', predict_only=False, seed=[0, 1234, 1234], trust_remote_code=False)
Namespace(model='xhf', tasks='gsm8k', model_args='pretrained=meta-llama/Meta-Llama-3-8B-Instruct,cats=True,spr=0.8,,check=True,kernel_size=16,thr=0.1', num_fewshot=None, batch_size='1', max_batch_size=None, device=None, output_path=None, limit=0.5, topp=1.1, topk=64, spr=0.25, sink=8, local=256, use_cache=None, cache_requests=None, check_integrity=False, write_out=False, log_samples=False, show_config=False, include_path=None, gen_kwargs=None, verbosity='INFO', wandb_args='', predict_only=False, seed=[0, 1234, 1234], trust_remote_code=False)
Namespace(model='xhf', tasks='gsm8k', model_args='pretrained=meta-llama/Meta-Llama-3-8B-Instruct,cats=True,spr=0.8,,check=True,kernel_size=16,thr=0.1', num_fewshot=None, batch_size='1', max_batch_size=None, device=None, output_path=None, limit=0.5, topp=1.1, topk=64, spr=0.25, sink=8, local=256, use_cache=None, cache_requests=None, check_integrity=False, write_out=False, log_samples=False, show_config=False, include_path=None, gen_kwargs=None, verbosity='INFO', wandb_args='', predict_only=False, seed=[0, 1234, 1234], trust_remote_code=False)
Namespace(model='xhf', tasks='gsm8k', model_args='pretrained=meta-llama/Meta-Llama-3-8B-Instruct,cats=True,spr=0.8,,check=True,kernel_size=16,thr=0.1', num_fewshot=None, batch_size='1', max_batch_size=None, device=None, output_path=None, limit=0.5, topp=1.1, topk=64, spr=0.25, sink=8, local=256, use_cache=None, cache_requests=None, check_integrity=False, write_out=False, log_samples=False, show_config=False, include_path=None, gen_kwargs=None, verbosity='INFO', wandb_args='', predict_only=False, seed=[0, 1234, 1234], trust_remote_code=False)
Namespace(model='xhf', tasks='gsm8k', model_args='pretrained=meta-llama/Meta-Llama-3-8B-Instruct,cats=True,spr=0.8,,check=True,kernel_size=16,thr=0.1', num_fewshot=None, batch_size='1', max_batch_size=None, device=None, output_path=None, limit=0.5, topp=1.1, topk=64, spr=0.25, sink=8, local=256, use_cache=None, cache_requests=None, check_integrity=False, write_out=False, log_samples=False, show_config=False, include_path=None, gen_kwargs=None, verbosity='INFO', wandb_args='', predict_only=False, seed=[0, 1234, 1234], trust_remote_code=False)
Namespace(model='xhf', tasks='gsm8k', model_args='pretrained=meta-llama/Meta-Llama-3-8B-Instruct,cats=True,spr=0.8,,check=True,kernel_size=16,thr=0.1', num_fewshot=None, batch_size='1', max_batch_size=None, device=None, output_path=None, limit=0.5, topp=1.1, topk=64, spr=0.25, sink=8, local=256, use_cache=None, cache_requests=None, check_integrity=False, write_out=False, log_samples=False, show_config=False, include_path=None, gen_kwargs=None, verbosity='INFO', wandb_args='', predict_only=False, seed=[0, 1234, 1234], trust_remote_code=False)
6736 421 16.0
7445 467 15.942184154175589
7456 466 16.0
7328 458 16.0
7750 485 15.97938144329897
8166 511 15.980430528375734
8176 511 16.0
8131 509 15.974459724950885
xhf (pretrained=meta-llama/Meta-Llama-3-8B-Instruct,cats=True,spr=0.8,,check=True,kernel_size=16,thr=0.1), gen_kwargs: (None), limit: 0.5, num_fewshot: None, batch_size: 1
|Tasks|Version|     Filter     |n-shot|  Metric   |Value |   |Stderr|
|-----|------:|----------------|-----:|-----------|-----:|---|-----:|
|gsm8k|      3|strict-match    |     5|exact_match|0.7455|±  |0.0170|
|     |       |flexible-extract|     5|exact_match|0.7470|±  |0.0169|

Namespace(model='xhf', tasks='gsm8k', model_args='pretrained=meta-llama/Meta-Llama-3-8B-Instruct,cats=True,spr=0.9,check=True,kernel_size=16,thr=0.1', num_fewshot=None, batch_size='1', max_batch_size=None, device=None, output_path=None, limit=0.5, topp=1.1, topk=64, spr=0.25, sink=8, local=256, use_cache=None, cache_requests=None, check_integrity=False, write_out=False, log_samples=False, show_config=False, include_path=None, gen_kwargs=None, verbosity='INFO', wandb_args='', predict_only=False, seed=[0, 1234, 1234], trust_remote_code=False)
Namespace(model='xhf', tasks='gsm8k', model_args='pretrained=meta-llama/Meta-Llama-3-8B-Instruct,cats=True,spr=0.9,check=True,kernel_size=16,thr=0.1', num_fewshot=None, batch_size='1', max_batch_size=None, device=None, output_path=None, limit=0.5, topp=1.1, topk=64, spr=0.25, sink=8, local=256, use_cache=None, cache_requests=None, check_integrity=False, write_out=False, log_samples=False, show_config=False, include_path=None, gen_kwargs=None, verbosity='INFO', wandb_args='', predict_only=False, seed=[0, 1234, 1234], trust_remote_code=False)
Namespace(model='xhf', tasks='gsm8k', model_args='pretrained=meta-llama/Meta-Llama-3-8B-Instruct,cats=True,spr=0.9,check=True,kernel_size=16,thr=0.1', num_fewshot=None, batch_size='1', max_batch_size=None, device=None, output_path=None, limit=0.5, topp=1.1, topk=64, spr=0.25, sink=8, local=256, use_cache=None, cache_requests=None, check_integrity=False, write_out=False, log_samples=False, show_config=False, include_path=None, gen_kwargs=None, verbosity='INFO', wandb_args='', predict_only=False, seed=[0, 1234, 1234], trust_remote_code=False)
Namespace(model='xhf', tasks='gsm8k', model_args='pretrained=meta-llama/Meta-Llama-3-8B-Instruct,cats=True,spr=0.9,check=True,kernel_size=16,thr=0.1', num_fewshot=None, batch_size='1', max_batch_size=None, device=None, output_path=None, limit=0.5, topp=1.1, topk=64, spr=0.25, sink=8, local=256, use_cache=None, cache_requests=None, check_integrity=False, write_out=False, log_samples=False, show_config=False, include_path=None, gen_kwargs=None, verbosity='INFO', wandb_args='', predict_only=False, seed=[0, 1234, 1234], trust_remote_code=False)
Namespace(model='xhf', tasks='gsm8k', model_args='pretrained=meta-llama/Meta-Llama-3-8B-Instruct,cats=True,spr=0.9,check=True,kernel_size=16,thr=0.1', num_fewshot=None, batch_size='1', max_batch_size=None, device=None, output_path=None, limit=0.5, topp=1.1, topk=64, spr=0.25, sink=8, local=256, use_cache=None, cache_requests=None, check_integrity=False, write_out=False, log_samples=False, show_config=False, include_path=None, gen_kwargs=None, verbosity='INFO', wandb_args='', predict_only=False, seed=[0, 1234, 1234], trust_remote_code=False)
Namespace(model='xhf', tasks='gsm8k', model_args='pretrained=meta-llama/Meta-Llama-3-8B-Instruct,cats=True,spr=0.9,check=True,kernel_size=16,thr=0.1', num_fewshot=None, batch_size='1', max_batch_size=None, device=None, output_path=None, limit=0.5, topp=1.1, topk=64, spr=0.25, sink=8, local=256, use_cache=None, cache_requests=None, check_integrity=False, write_out=False, log_samples=False, show_config=False, include_path=None, gen_kwargs=None, verbosity='INFO', wandb_args='', predict_only=False, seed=[0, 1234, 1234], trust_remote_code=False)
Namespace(model='xhf', tasks='gsm8k', model_args='pretrained=meta-llama/Meta-Llama-3-8B-Instruct,cats=True,spr=0.9,check=True,kernel_size=16,thr=0.1', num_fewshot=None, batch_size='1', max_batch_size=None, device=None, output_path=None, limit=0.5, topp=1.1, topk=64, spr=0.25, sink=8, local=256, use_cache=None, cache_requests=None, check_integrity=False, write_out=False, log_samples=False, show_config=False, include_path=None, gen_kwargs=None, verbosity='INFO', wandb_args='', predict_only=False, seed=[0, 1234, 1234], trust_remote_code=False)
Namespace(model='xhf', tasks='gsm8k', model_args='pretrained=meta-llama/Meta-Llama-3-8B-Instruct,cats=True,spr=0.9,check=True,kernel_size=16,thr=0.1', num_fewshot=None, batch_size='1', max_batch_size=None, device=None, output_path=None, limit=0.5, topp=1.1, topk=64, spr=0.25, sink=8, local=256, use_cache=None, cache_requests=None, check_integrity=False, write_out=False, log_samples=False, show_config=False, include_path=None, gen_kwargs=None, verbosity='INFO', wandb_args='', predict_only=False, seed=[0, 1234, 1234], trust_remote_code=False)
6528 408 16.0
6960 435 16.0
7360 460 16.0
7680 480 16.0
7904 494 16.0
8048 503 16.0
7472 467 16.0
8144 509 16.0
xhf (pretrained=meta-llama/Meta-Llama-3-8B-Instruct,cats=True,spr=0.9,check=True,kernel_size=16,thr=0.1), gen_kwargs: (None), limit: 0.5, num_fewshot: None, batch_size: 1
|Tasks|Version|     Filter     |n-shot|  Metric   |Value |   |Stderr|
|-----|------:|----------------|-----:|-----------|-----:|---|-----:|
|gsm8k|      3|strict-match    |     5|exact_match|0.7530|±  |0.0168|
|     |       |flexible-extract|     5|exact_match|0.7545|±  |0.0168|

