Already on 'yangexp2'
WARNING: Ignoring invalid distribution ~umpy (/private/home/beidic/.conda/envs/griffin/lib/python3.12/site-packages)
WARNING: Ignoring invalid distribution ~umpy (/private/home/beidic/.conda/envs/griffin/lib/python3.12/site-packages)
WARNING: Ignoring invalid distribution ~umpy (/private/home/beidic/.conda/envs/griffin/lib/python3.12/site-packages)
WARNING: Ignoring invalid distribution ~umpy (/private/home/beidic/.conda/envs/griffin/lib/python3.12/site-packages)
WARNING: Ignoring invalid distribution ~umpy (/private/home/beidic/.conda/envs/griffin/lib/python3.12/site-packages)
WARNING: Skipping /private/home/beidic/.conda/envs/griffin/lib/python3.12/site-packages/~umpy-1.26.4.dist-info due to invalid metadata entry 'name'
WARNING: Ignoring invalid distribution ~sspec (/private/home/beidic/.conda/envs/griffin/lib/python3.12/site-packages)
WARNING: Skipping /private/home/beidic/.conda/envs/griffin/lib/python3.12/site-packages/~sspec-2024.5.0.dist-info due to invalid metadata entry 'name'
ERROR: Exception:
Traceback (most recent call last):
  File "/private/home/beidic/.conda/envs/griffin/lib/python3.12/site-packages/pip/_internal/cli/base_command.py", line 180, in exc_logging_wrapper
    status = run_func(*args)
             ^^^^^^^^^^^^^^^
  File "/private/home/beidic/.conda/envs/griffin/lib/python3.12/site-packages/pip/_internal/cli/req_command.py", line 245, in wrapper
    return func(self, options, args)
           ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/private/home/beidic/.conda/envs/griffin/lib/python3.12/site-packages/pip/_internal/commands/install.py", line 324, in run
    session = self.get_default_session(options)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/private/home/beidic/.conda/envs/griffin/lib/python3.12/site-packages/pip/_internal/cli/req_command.py", line 95, in get_default_session
    self._session = self.enter_context(self._build_session(options))
                                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/private/home/beidic/.conda/envs/griffin/lib/python3.12/site-packages/pip/_internal/cli/req_command.py", line 122, in _build_session
    session = PipSession(
              ^^^^^^^^^^^
  File "/private/home/beidic/.conda/envs/griffin/lib/python3.12/site-packages/pip/_internal/network/session.py", line 342, in __init__
    self.headers["User-Agent"] = user_agent()
                                 ^^^^^^^^^^^^
  File "/private/home/beidic/.conda/envs/griffin/lib/python3.12/site-packages/pip/_internal/network/session.py", line 175, in user_agent
    setuptools_dist = get_default_environment().get_distribution("setuptools")
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/private/home/beidic/.conda/envs/griffin/lib/python3.12/site-packages/pip/_internal/metadata/importlib/_envs.py", line 189, in get_distribution
    return next(matches, None)
           ^^^^^^^^^^^^^^^^^^^
  File "/private/home/beidic/.conda/envs/griffin/lib/python3.12/site-packages/pip/_internal/metadata/importlib/_envs.py", line 184, in <genexpr>
    matches = (
              ^
  File "/private/home/beidic/.conda/envs/griffin/lib/python3.12/site-packages/pip/_internal/metadata/base.py", line 626, in iter_all_distributions
    for dist in self._iter_distributions():
  File "/private/home/beidic/.conda/envs/griffin/lib/python3.12/site-packages/pip/_internal/metadata/importlib/_envs.py", line 177, in _iter_distributions
    for dist in finder.find_eggs(location):
  File "/private/home/beidic/.conda/envs/griffin/lib/python3.12/site-packages/pip/_internal/metadata/importlib/_envs.py", line 144, in find_eggs
    yield from self._find_eggs_in_dir(location)
  File "/private/home/beidic/.conda/envs/griffin/lib/python3.12/site-packages/pip/_internal/metadata/importlib/_envs.py", line 111, in _find_eggs_in_dir
    from pip._vendor.pkg_resources import find_distributions
  File "/private/home/beidic/.conda/envs/griffin/lib/python3.12/site-packages/pip/_vendor/pkg_resources/__init__.py", line 3327, in <module>
    @_call_aside
     ^^^^^^^^^^^
  File "/private/home/beidic/.conda/envs/griffin/lib/python3.12/site-packages/pip/_vendor/pkg_resources/__init__.py", line 3302, in _call_aside
    f(*args, **kwargs)
  File "/private/home/beidic/.conda/envs/griffin/lib/python3.12/site-packages/pip/_vendor/pkg_resources/__init__.py", line 3340, in _initialize_master_working_set
    working_set = WorkingSet._build_master()
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/private/home/beidic/.conda/envs/griffin/lib/python3.12/site-packages/pip/_vendor/pkg_resources/__init__.py", line 622, in _build_master
    ws = cls()
         ^^^^^
  File "/private/home/beidic/.conda/envs/griffin/lib/python3.12/site-packages/pip/_vendor/pkg_resources/__init__.py", line 615, in __init__
    self.add_entry(entry)
  File "/private/home/beidic/.conda/envs/griffin/lib/python3.12/site-packages/pip/_vendor/pkg_resources/__init__.py", line 671, in add_entry
    for dist in find_distributions(entry, True):
  File "/private/home/beidic/.conda/envs/griffin/lib/python3.12/site-packages/pip/_vendor/pkg_resources/__init__.py", line 2134, in find_on_path
    for dist in factory(fullpath):
  File "/private/home/beidic/.conda/envs/griffin/lib/python3.12/site-packages/pip/_vendor/pkg_resources/__init__.py", line 2192, in distributions_from_metadata
    if len(os.listdir(path)) == 0:
           ^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/private/home/beidic/.conda/envs/griffin/lib/python3.12/site-packages/~equests-2.32.3.dist-info'
WARNING: Ignoring invalid distribution ~uggingface-hub (/private/home/beidic/.conda/envs/griffin/lib/python3.12/site-packages)
WARNING: Skipping /private/home/beidic/.conda/envs/griffin/lib/python3.12/site-packages/~uggingface_hub-0.23.2.dist-info due to invalid metadata entry 'name'
wandb: Currently logged in as: stevenzhou0816100. Use `wandb login --relogin` to force relogin
/var/spool/slurm//job28549289/slurm_script: line 60: transformers-cli: command not found
Traceback (most recent call last):
  File "/private/home/beidic/.conda/envs/griffin/bin/huggingface-cli", line 8, in <module>
    sys.exit(main())
             ^^^^^^
  File "/private/home/beidic/.conda/envs/griffin/lib/python3.12/site-packages/huggingface_hub/commands/huggingface_cli.py", line 51, in main
    service.run()
  File "/private/home/beidic/.conda/envs/griffin/lib/python3.12/site-packages/huggingface_hub/commands/user.py", line 98, in run
    login(token=self.args.token, add_to_git_credential=self.args.add_to_git_credential)
  File "/private/home/beidic/.conda/envs/griffin/lib/python3.12/site-packages/huggingface_hub/_login.py", line 111, in login
    _login(token, add_to_git_credential=add_to_git_credential, write_permission=write_permission)
  File "/private/home/beidic/.conda/envs/griffin/lib/python3.12/site-packages/huggingface_hub/_login.py", line 307, in _login
    raise ValueError("Invalid token passed!")
ValueError: Invalid token passed!
The following values were not passed to `accelerate launch` and had defaults used instead:
		More than one GPU was found, enabling multi-GPU training.
		If this was unintended please pass in `--num_processes=1`.
	`--mixed_precision` was set to a value of `'no'`
	`--dynamo_backend` was set to a value of `'no'`
To avoid this warning pass in values for each of the problematic parameters or run `accelerate config`.
2024-06-03:14:50:50,608 INFO     [main.py:288] Verbosity set to INFO
2024-06-03:14:50:50,609 INFO     [main.py:288] Verbosity set to INFO
2024-06-03:14:50:50,609 INFO     [main.py:288] Verbosity set to INFO
2024-06-03:14:50:50,609 INFO     [main.py:288] Verbosity set to INFO
2024-06-03:14:50:50,609 INFO     [main.py:288] Verbosity set to INFO
2024-06-03:14:50:50,609 INFO     [main.py:288] Verbosity set to INFO
2024-06-03:14:50:50,609 INFO     [main.py:288] Verbosity set to INFO
2024-06-03:14:50:50,614 INFO     [main.py:288] Verbosity set to INFO
2024-06-03:14:50:58,765 INFO     [main.py:378] Selected Tasks: ['gsm8k']
2024-06-03:14:50:58,766 INFO     [main.py:378] Selected Tasks: ['gsm8k']
2024-06-03:14:50:58,766 INFO     [main.py:378] Selected Tasks: ['gsm8k']
2024-06-03:14:50:58,766 INFO     [main.py:378] Selected Tasks: ['gsm8k']
2024-06-03:14:50:58,766 INFO     [main.py:378] Selected Tasks: ['gsm8k']
2024-06-03:14:50:58,766 INFO     [main.py:378] Selected Tasks: ['gsm8k']
2024-06-03:14:50:58,766 INFO     [main.py:378] Selected Tasks: ['gsm8k']
2024-06-03:14:50:58,768 INFO     [main.py:378] Selected Tasks: ['gsm8k']
2024-06-03:14:50:58,777 INFO     [xevaluator.py:137] Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234
2024-06-03:14:50:58,777 INFO     [xevaluator.py:184] Initializing xhf model, with arguments: {'pretrained': 'meta-llama/Llama-2-7b-chat-hf', 'cats': True, 'check': False}
2024-06-03:14:50:58,777 INFO     [xevaluator.py:137] Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234
2024-06-03:14:50:58,777 INFO     [xevaluator.py:137] Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234
2024-06-03:14:50:58,777 INFO     [xevaluator.py:137] Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234
2024-06-03:14:50:58,777 INFO     [xevaluator.py:137] Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234
2024-06-03:14:50:58,777 INFO     [xevaluator.py:137] Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234
2024-06-03:14:50:58,777 INFO     [xevaluator.py:184] Initializing xhf model, with arguments: {'pretrained': 'meta-llama/Llama-2-7b-chat-hf', 'cats': True, 'check': False}
2024-06-03:14:50:58,777 INFO     [xevaluator.py:184] Initializing xhf model, with arguments: {'pretrained': 'meta-llama/Llama-2-7b-chat-hf', 'cats': True, 'check': False}
2024-06-03:14:50:58,777 INFO     [xevaluator.py:184] Initializing xhf model, with arguments: {'pretrained': 'meta-llama/Llama-2-7b-chat-hf', 'cats': True, 'check': False}
2024-06-03:14:50:58,777 INFO     [xevaluator.py:184] Initializing xhf model, with arguments: {'pretrained': 'meta-llama/Llama-2-7b-chat-hf', 'cats': True, 'check': False}
2024-06-03:14:50:58,777 INFO     [xevaluator.py:137] Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234
2024-06-03:14:50:58,777 INFO     [xevaluator.py:137] Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234
2024-06-03:14:50:58,778 INFO     [xevaluator.py:184] Initializing xhf model, with arguments: {'pretrained': 'meta-llama/Llama-2-7b-chat-hf', 'cats': True, 'check': False}
2024-06-03:14:50:58,778 INFO     [xevaluator.py:184] Initializing xhf model, with arguments: {'pretrained': 'meta-llama/Llama-2-7b-chat-hf', 'cats': True, 'check': False}
2024-06-03:14:50:58,778 INFO     [xevaluator.py:184] Initializing xhf model, with arguments: {'pretrained': 'meta-llama/Llama-2-7b-chat-hf', 'cats': True, 'check': False}
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [01:10<01:10, 70.94s/it]Loading checkpoint shards:  50%|█████     | 1/2 [01:12<01:12, 72.16s/it]Loading checkpoint shards:  50%|█████     | 1/2 [01:12<01:12, 72.29s/it]Loading checkpoint shards:  50%|█████     | 1/2 [01:12<01:12, 72.08s/it]Loading checkpoint shards:  50%|█████     | 1/2 [01:12<01:12, 72.69s/it]Loading checkpoint shards:  50%|█████     | 1/2 [01:12<01:12, 72.14s/it]Loading checkpoint shards:  50%|█████     | 1/2 [01:12<01:12, 72.15s/it]Loading checkpoint shards:  50%|█████     | 1/2 [01:12<01:12, 72.11s/it]Loading checkpoint shards: 100%|██████████| 2/2 [01:34<00:00, 43.10s/it]Loading checkpoint shards: 100%|██████████| 2/2 [01:34<00:00, 47.46s/it]
Loading checkpoint shards: 100%|██████████| 2/2 [01:35<00:00, 43.34s/it]Loading checkpoint shards: 100%|██████████| 2/2 [01:35<00:00, 47.66s/it]
Loading checkpoint shards: 100%|██████████| 2/2 [01:35<00:00, 43.43s/it]Loading checkpoint shards: 100%|██████████| 2/2 [01:35<00:00, 47.76s/it]
Loading checkpoint shards: 100%|██████████| 2/2 [01:35<00:00, 43.35s/it]Loading checkpoint shards: 100%|██████████| 2/2 [01:35<00:00, 47.66s/it]
Loading checkpoint shards: 100%|██████████| 2/2 [01:35<00:00, 43.61s/it]Loading checkpoint shards: 100%|██████████| 2/2 [01:35<00:00, 47.97s/it]
Loading checkpoint shards: 100%|██████████| 2/2 [01:35<00:00, 43.36s/it]Loading checkpoint shards: 100%|██████████| 2/2 [01:35<00:00, 47.68s/it]
Loading checkpoint shards: 100%|██████████| 2/2 [01:35<00:00, 43.71s/it]Loading checkpoint shards: 100%|██████████| 2/2 [01:35<00:00, 47.79s/it]
Loading checkpoint shards: 100%|██████████| 2/2 [01:35<00:00, 43.42s/it]Loading checkpoint shards: 100%|██████████| 2/2 [01:35<00:00, 47.73s/it]
Using the latest cached version of the dataset since gsm8k couldn't be found on the Hugging Face Hub
2024-06-03:14:53:05,498 WARNING  [load.py:1631] Using the latest cached version of the dataset since gsm8k couldn't be found on the Hugging Face Hub
Found the latest cached dataset configuration 'main' at /private/home/beidic/.cache/huggingface/datasets/gsm8k/main/0.0.0/e53f048856ff4f594e959d75785d2c2d37b678ee (last modified on Thu May 16 07:01:08 2024).
2024-06-03:14:53:05,501 WARNING  [cache.py:95] Found the latest cached dataset configuration 'main' at /private/home/beidic/.cache/huggingface/datasets/gsm8k/main/0.0.0/e53f048856ff4f594e959d75785d2c2d37b678ee (last modified on Thu May 16 07:01:08 2024).
2024-06-03:14:53:05,830 INFO     [task.py:395] Building contexts for gsm8k on rank 1...
  0%|          | 0/165 [00:00<?, ?it/s] 10%|▉         | 16/165 [00:00<00:00, 155.18it/s] 19%|█▉        | 32/165 [00:00<00:00, 155.94it/s] 29%|██▉       | 48/165 [00:00<00:00, 155.47it/s] 39%|███▉      | 64/165 [00:00<00:00, 155.99it/s] 48%|████▊     | 80/165 [00:00<00:00, 156.58it/s]Using the latest cached version of the dataset since gsm8k couldn't be found on the Hugging Face Hub
2024-06-03:14:53:06,396 WARNING  [load.py:1631] Using the latest cached version of the dataset since gsm8k couldn't be found on the Hugging Face Hub
Found the latest cached dataset configuration 'main' at /private/home/beidic/.cache/huggingface/datasets/gsm8k/main/0.0.0/e53f048856ff4f594e959d75785d2c2d37b678ee (last modified on Thu May 16 07:01:08 2024).
2024-06-03:14:53:06,398 WARNING  [cache.py:95] Found the latest cached dataset configuration 'main' at /private/home/beidic/.cache/huggingface/datasets/gsm8k/main/0.0.0/e53f048856ff4f594e959d75785d2c2d37b678ee (last modified on Thu May 16 07:01:08 2024).
 58%|█████▊    | 96/165 [00:00<00:00, 155.81it/s] 68%|██████▊   | 112/165 [00:00<00:00, 156.41it/s]2024-06-03:14:53:06,629 INFO     [task.py:395] Building contexts for gsm8k on rank 6...
  0%|          | 0/165 [00:00<?, ?it/s] 78%|███████▊  | 128/165 [00:00<00:00, 156.66it/s] 10%|▉         | 16/165 [00:00<00:00, 153.58it/s] 87%|████████▋ | 144/165 [00:00<00:00, 157.34it/s] 19%|█▉        | 32/165 [00:00<00:00, 154.31it/s] 97%|█████████▋| 160/165 [00:01<00:00, 157.19it/s]100%|██████████| 165/165 [00:01<00:00, 156.61it/s]
 29%|██▉       | 48/165 [00:00<00:00, 154.14it/s] 39%|███▉      | 64/165 [00:00<00:00, 154.05it/s] 48%|████▊     | 80/165 [00:00<00:00, 154.01it/s] 58%|█████▊    | 96/165 [00:00<00:00, 153.88it/s] 68%|██████▊   | 112/165 [00:00<00:00, 153.90it/s] 78%|███████▊  | 128/165 [00:00<00:00, 153.80it/s] 87%|████████▋ | 144/165 [00:00<00:00, 153.80it/s] 97%|█████████▋| 160/165 [00:01<00:00, 153.71it/s]100%|██████████| 165/165 [00:01<00:00, 153.43it/s]
Using the latest cached version of the dataset since gsm8k couldn't be found on the Hugging Face Hub
2024-06-03:14:53:16,796 WARNING  [load.py:1631] Using the latest cached version of the dataset since gsm8k couldn't be found on the Hugging Face Hub
Found the latest cached dataset configuration 'main' at /private/home/beidic/.cache/huggingface/datasets/gsm8k/main/0.0.0/e53f048856ff4f594e959d75785d2c2d37b678ee (last modified on Thu May 16 07:01:08 2024).
2024-06-03:14:53:16,798 WARNING  [cache.py:95] Found the latest cached dataset configuration 'main' at /private/home/beidic/.cache/huggingface/datasets/gsm8k/main/0.0.0/e53f048856ff4f594e959d75785d2c2d37b678ee (last modified on Thu May 16 07:01:08 2024).
2024-06-03:14:53:16,960 INFO     [task.py:395] Building contexts for gsm8k on rank 4...
  0%|          | 0/165 [00:00<?, ?it/s] 13%|█▎        | 22/165 [00:00<00:00, 214.39it/s]Using the latest cached version of the dataset since gsm8k couldn't be found on the Hugging Face Hub
2024-06-03:14:53:17,125 WARNING  [load.py:1631] Using the latest cached version of the dataset since gsm8k couldn't be found on the Hugging Face Hub
Found the latest cached dataset configuration 'main' at /private/home/beidic/.cache/huggingface/datasets/gsm8k/main/0.0.0/e53f048856ff4f594e959d75785d2c2d37b678ee (last modified on Thu May 16 07:01:08 2024).
2024-06-03:14:53:17,126 WARNING  [cache.py:95] Found the latest cached dataset configuration 'main' at /private/home/beidic/.cache/huggingface/datasets/gsm8k/main/0.0.0/e53f048856ff4f594e959d75785d2c2d37b678ee (last modified on Thu May 16 07:01:08 2024).
 27%|██▋       | 44/165 [00:00<00:00, 211.29it/s]2024-06-03:14:53:17,280 INFO     [task.py:395] Building contexts for gsm8k on rank 5...
 40%|████      | 66/165 [00:00<00:00, 210.59it/s]  0%|          | 0/165 [00:00<?, ?it/s] 53%|█████▎    | 88/165 [00:00<00:00, 211.00it/s] 13%|█▎        | 22/165 [00:00<00:00, 211.98it/s] 67%|██████▋   | 110/165 [00:00<00:00, 210.91it/s] 27%|██▋       | 44/165 [00:00<00:00, 211.70it/s]2024-06-03:14:53:17,594 INFO     [xhuggingface.py:314] Using 8 devices with data parallelism
 80%|████████  | 132/165 [00:00<00:00, 210.53it/s] 40%|████      | 66/165 [00:00<00:00, 211.98it/s] 93%|█████████▎| 154/165 [00:00<00:00, 210.78it/s] 53%|█████▎    | 88/165 [00:00<00:00, 212.41it/s]100%|██████████| 165/165 [00:00<00:00, 211.03it/s]
 67%|██████▋   | 110/165 [00:00<00:00, 213.00it/s]Using the latest cached version of the dataset since gsm8k couldn't be found on the Hugging Face Hub
2024-06-03:14:53:17,833 WARNING  [load.py:1631] Using the latest cached version of the dataset since gsm8k couldn't be found on the Hugging Face Hub
Found the latest cached dataset configuration 'main' at /private/home/beidic/.cache/huggingface/datasets/gsm8k/main/0.0.0/e53f048856ff4f594e959d75785d2c2d37b678ee (last modified on Thu May 16 07:01:08 2024).
2024-06-03:14:53:17,835 WARNING  [cache.py:95] Found the latest cached dataset configuration 'main' at /private/home/beidic/.cache/huggingface/datasets/gsm8k/main/0.0.0/e53f048856ff4f594e959d75785d2c2d37b678ee (last modified on Thu May 16 07:01:08 2024).
 80%|████████  | 132/165 [00:00<00:00, 212.52it/s] 93%|█████████▎| 154/165 [00:00<00:00, 213.67it/s]100%|██████████| 165/165 [00:00<00:00, 213.26it/s]
2024-06-03:14:53:18,134 INFO     [task.py:395] Building contexts for gsm8k on rank 0...
  0%|          | 0/165 [00:00<?, ?it/s] 13%|█▎        | 21/165 [00:00<00:00, 207.65it/s]Using the latest cached version of the dataset since gsm8k couldn't be found on the Hugging Face Hub
2024-06-03:14:53:18,337 WARNING  [load.py:1631] Using the latest cached version of the dataset since gsm8k couldn't be found on the Hugging Face Hub
Found the latest cached dataset configuration 'main' at /private/home/beidic/.cache/huggingface/datasets/gsm8k/main/0.0.0/e53f048856ff4f594e959d75785d2c2d37b678ee (last modified on Thu May 16 07:01:08 2024).
2024-06-03:14:53:18,340 WARNING  [cache.py:95] Found the latest cached dataset configuration 'main' at /private/home/beidic/.cache/huggingface/datasets/gsm8k/main/0.0.0/e53f048856ff4f594e959d75785d2c2d37b678ee (last modified on Thu May 16 07:01:08 2024).
 25%|██▌       | 42/165 [00:00<00:00, 208.92it/s] 38%|███▊      | 63/165 [00:00<00:00, 208.73it/s] 52%|█████▏    | 85/165 [00:00<00:00, 209.41it/s]2024-06-03:14:53:18,653 INFO     [task.py:395] Building contexts for gsm8k on rank 7...
 65%|██████▍   | 107/165 [00:00<00:00, 209.73it/s]  0%|          | 0/164 [00:00<?, ?it/s] 78%|███████▊  | 128/165 [00:00<00:00, 209.77it/s]  9%|▉         | 15/164 [00:00<00:01, 144.53it/s] 90%|█████████ | 149/165 [00:00<00:00, 209.71it/s] 18%|█▊        | 30/164 [00:00<00:00, 145.05it/s]100%|██████████| 165/165 [00:00<00:00, 209.52it/s]
 27%|██▋       | 45/164 [00:00<00:00, 145.10it/s] 37%|███▋      | 60/164 [00:00<00:00, 145.12it/s] 46%|████▌     | 75/164 [00:00<00:00, 145.23it/s] 55%|█████▍    | 90/164 [00:00<00:00, 144.81it/s] 64%|██████▍   | 105/164 [00:00<00:00, 144.95it/s] 73%|███████▎  | 120/164 [00:00<00:00, 144.97it/s] 82%|████████▏ | 135/164 [00:00<00:00, 145.10it/s] 91%|█████████▏| 150/164 [00:01<00:00, 145.31it/s]100%|██████████| 164/164 [00:01<00:00, 145.10it/s]
Using the latest cached version of the dataset since gsm8k couldn't be found on the Hugging Face Hub
2024-06-03:14:53:23,244 WARNING  [load.py:1631] Using the latest cached version of the dataset since gsm8k couldn't be found on the Hugging Face Hub
Found the latest cached dataset configuration 'main' at /private/home/beidic/.cache/huggingface/datasets/gsm8k/main/0.0.0/e53f048856ff4f594e959d75785d2c2d37b678ee (last modified on Thu May 16 07:01:08 2024).
2024-06-03:14:53:23,246 WARNING  [cache.py:95] Found the latest cached dataset configuration 'main' at /private/home/beidic/.cache/huggingface/datasets/gsm8k/main/0.0.0/e53f048856ff4f594e959d75785d2c2d37b678ee (last modified on Thu May 16 07:01:08 2024).
2024-06-03:14:53:23,483 INFO     [task.py:395] Building contexts for gsm8k on rank 2...
  0%|          | 0/165 [00:00<?, ?it/s]  9%|▉         | 15/165 [00:00<00:01, 148.00it/s] 18%|█▊        | 30/165 [00:00<00:00, 145.97it/s] 27%|██▋       | 45/165 [00:00<00:00, 144.45it/s] 36%|███▋      | 60/165 [00:00<00:00, 144.46it/s] 45%|████▌     | 75/165 [00:00<00:00, 146.03it/s] 55%|█████▍    | 90/165 [00:00<00:00, 146.85it/s] 64%|██████▎   | 105/165 [00:00<00:00, 147.46it/s] 73%|███████▎  | 120/165 [00:00<00:00, 147.66it/s] 82%|████████▏ | 135/165 [00:00<00:00, 148.10it/s] 91%|█████████ | 150/165 [00:01<00:00, 148.25it/s]100%|██████████| 165/165 [00:01<00:00, 148.54it/s]100%|██████████| 165/165 [00:01<00:00, 147.28it/s]
Using the latest cached version of the dataset since gsm8k couldn't be found on the Hugging Face Hub
2024-06-03:14:53:24,677 WARNING  [load.py:1631] Using the latest cached version of the dataset since gsm8k couldn't be found on the Hugging Face Hub
Found the latest cached dataset configuration 'main' at /private/home/beidic/.cache/huggingface/datasets/gsm8k/main/0.0.0/e53f048856ff4f594e959d75785d2c2d37b678ee (last modified on Thu May 16 07:01:08 2024).
2024-06-03:14:53:24,679 WARNING  [cache.py:95] Found the latest cached dataset configuration 'main' at /private/home/beidic/.cache/huggingface/datasets/gsm8k/main/0.0.0/e53f048856ff4f594e959d75785d2c2d37b678ee (last modified on Thu May 16 07:01:08 2024).
2024-06-03:14:53:24,969 INFO     [task.py:395] Building contexts for gsm8k on rank 3...
  0%|          | 0/165 [00:00<?, ?it/s] 11%|█         | 18/165 [00:00<00:00, 172.84it/s] 22%|██▏       | 36/165 [00:00<00:00, 173.30it/s] 33%|███▎      | 54/165 [00:00<00:00, 173.32it/s] 44%|████▎     | 72/165 [00:00<00:00, 173.36it/s] 55%|█████▍    | 90/165 [00:00<00:00, 173.30it/s] 65%|██████▌   | 108/165 [00:00<00:00, 173.41it/s] 76%|███████▋  | 126/165 [00:00<00:00, 173.41it/s] 87%|████████▋ | 144/165 [00:00<00:00, 173.45it/s] 98%|█████████▊| 162/165 [00:00<00:00, 173.42it/s]100%|██████████| 165/165 [00:00<00:00, 173.36it/s]
2024-06-03:14:53:29,187 INFO     [xevaluator.py:395] Running generate_until requests
2024-06-03:14:53:29,187 INFO     [xevaluator.py:395] Running generate_until requests
2024-06-03:14:53:29,187 INFO     [xevaluator.py:395] Running generate_until requests
2024-06-03:14:53:29,187 INFO     [xevaluator.py:395] Running generate_until requests
2024-06-03:14:53:29,187 INFO     [xevaluator.py:395] Running generate_until requests
2024-06-03:14:53:29,187 INFO     [xevaluator.py:395] Running generate_until requests
2024-06-03:14:53:29,187 INFO     [xevaluator.py:395] Running generate_until requests
2024-06-03:14:53:29,187 INFO     [xevaluator.py:395] Running generate_until requests
Running generate_until requests:   0%|          | 0/165 [00:00<?, ?it/s]Running generate_until requests:   1%|          | 1/165 [00:13<35:48, 13.10s/it]Running generate_until requests:   1%|          | 2/165 [00:21<27:37, 10.17s/it]Running generate_until requests:   2%|▏         | 3/165 [00:28<24:15,  8.98s/it]Running generate_until requests:   2%|▏         | 4/165 [00:41<27:53, 10.39s/it]Running generate_until requests:   3%|▎         | 5/165 [00:53<29:46, 11.17s/it]Running generate_until requests:   4%|▎         | 6/165 [01:03<27:55, 10.54s/it]Running generate_until requests:   4%|▍         | 7/165 [01:08<23:08,  8.79s/it]Running generate_until requests:   5%|▍         | 8/165 [01:17<23:21,  8.93s/it]Running generate_until requests:   5%|▌         | 9/165 [01:24<21:35,  8.30s/it]Running generate_until requests:   6%|▌         | 10/165 [01:31<20:26,  7.91s/it]Running generate_until requests:   7%|▋         | 11/165 [01:45<24:38,  9.60s/it]Running generate_until requests:   7%|▋         | 12/165 [01:48<20:05,  7.88s/it]Running generate_until requests:   8%|▊         | 13/165 [01:55<19:05,  7.53s/it]Running generate_until requests:   8%|▊         | 14/165 [02:01<17:58,  7.14s/it]Running generate_until requests:   9%|▉         | 15/165 [02:16<23:29,  9.40s/it]Running generate_until requests:  10%|▉         | 16/165 [02:21<20:05,  8.09s/it]Running generate_until requests:  10%|█         | 17/165 [02:27<18:23,  7.46s/it]Running generate_until requests:  11%|█         | 18/165 [02:34<17:44,  7.24s/it]Running generate_until requests:  12%|█▏        | 19/165 [02:41<17:50,  7.33s/it]Running generate_until requests:  12%|█▏        | 20/165 [02:48<17:31,  7.25s/it]Running generate_until requests:  13%|█▎        | 21/165 [02:54<16:25,  6.84s/it]Running generate_until requests:  13%|█▎        | 22/165 [03:00<15:40,  6.58s/it]Running generate_until requests:  14%|█▍        | 23/165 [03:10<18:01,  7.61s/it]Running generate_until requests:  15%|█▍        | 24/165 [03:17<17:18,  7.37s/it]Running generate_until requests:  15%|█▌        | 25/165 [03:25<17:31,  7.51s/it]Running generate_until requests:  16%|█▌        | 26/165 [03:31<16:03,  6.93s/it]Running generate_until requests:  16%|█▋        | 27/165 [03:37<15:54,  6.92s/it]Running generate_until requests:  17%|█▋        | 28/165 [03:47<17:44,  7.77s/it]Running generate_until requests:  18%|█▊        | 29/165 [03:53<15:56,  7.03s/it]Running generate_until requests:  18%|█▊        | 30/165 [04:00<16:01,  7.12s/it]Running generate_until requests:  19%|█▉        | 31/165 [04:07<16:05,  7.20s/it]Running generate_until requests:  19%|█▉        | 32/165 [04:15<16:07,  7.27s/it]Running generate_until requests:  20%|██        | 33/165 [04:19<14:05,  6.40s/it]Running generate_until requests:  21%|██        | 34/165 [04:27<14:53,  6.82s/it]Running generate_until requests:  21%|██        | 35/165 [04:33<14:10,  6.54s/it]Running generate_until requests:  22%|██▏       | 36/165 [04:39<14:00,  6.52s/it]Running generate_until requests:  22%|██▏       | 37/165 [04:44<12:32,  5.88s/it]Running generate_until requests:  23%|██▎       | 38/165 [04:55<15:53,  7.51s/it]Running generate_until requests:  24%|██▎       | 39/165 [05:06<17:51,  8.51s/it]Running generate_until requests:  24%|██▍       | 40/165 [05:13<17:13,  8.27s/it]Running generate_until requests:  25%|██▍       | 41/165 [05:21<16:34,  8.02s/it]Running generate_until requests:  25%|██▌       | 42/165 [05:29<16:14,  7.93s/it]Running generate_until requests:  26%|██▌       | 43/165 [05:34<14:50,  7.30s/it]Running generate_until requests:  27%|██▋       | 44/165 [05:42<14:42,  7.29s/it]Running generate_until requests:  27%|██▋       | 45/165 [05:50<15:08,  7.57s/it]Running generate_until requests:  28%|██▊       | 46/165 [06:04<19:11,  9.68s/it]Running generate_until requests:  28%|██▊       | 47/165 [06:11<17:02,  8.66s/it]Running generate_until requests:  29%|██▉       | 48/165 [06:15<14:21,  7.36s/it]Running generate_until requests:  30%|██▉       | 49/165 [06:19<12:25,  6.43s/it]Running generate_until requests:  30%|███       | 50/165 [06:27<12:53,  6.73s/it]Running generate_until requests:  31%|███       | 51/165 [06:34<12:59,  6.84s/it]Running generate_until requests:  32%|███▏      | 52/165 [06:39<11:43,  6.22s/it]Running generate_until requests:  32%|███▏      | 53/165 [06:51<15:08,  8.11s/it]Running generate_until requests:  33%|███▎      | 54/165 [07:00<15:13,  8.23s/it]Running generate_until requests:  33%|███▎      | 55/165 [07:14<18:37, 10.16s/it]Running generate_until requests:  34%|███▍      | 56/165 [07:22<17:13,  9.48s/it]Running generate_until requests:  35%|███▍      | 57/165 [07:29<15:39,  8.69s/it]Running generate_until requests:  35%|███▌      | 58/165 [07:42<17:36,  9.88s/it]Running generate_until requests:  36%|███▌      | 59/165 [07:48<15:21,  8.69s/it]Running generate_until requests:  36%|███▋      | 60/165 [07:54<13:46,  7.87s/it]Running generate_until requests:  37%|███▋      | 61/165 [08:00<12:48,  7.39s/it]Running generate_until requests:  38%|███▊      | 62/165 [08:07<12:28,  7.27s/it]Running generate_until requests:  38%|███▊      | 63/165 [08:16<13:07,  7.72s/it]Running generate_until requests:  39%|███▉      | 64/165 [08:22<12:24,  7.37s/it]Running generate_until requests:  39%|███▉      | 65/165 [08:30<12:23,  7.43s/it]Running generate_until requests:  40%|████      | 66/165 [08:36<11:47,  7.15s/it]Running generate_until requests:  41%|████      | 67/165 [08:43<11:13,  6.87s/it]Running generate_until requests:  41%|████      | 68/165 [08:52<12:28,  7.72s/it]Running generate_until requests:  42%|████▏     | 69/165 [08:58<11:39,  7.29s/it]Running generate_until requests:  42%|████▏     | 70/165 [09:05<11:07,  7.03s/it]Running generate_until requests:  43%|████▎     | 71/165 [09:12<11:04,  7.07s/it]Running generate_until requests:  44%|████▎     | 72/165 [09:19<10:53,  7.02s/it]Running generate_until requests:  44%|████▍     | 73/165 [09:24<10:04,  6.57s/it]Running generate_until requests:  45%|████▍     | 74/165 [09:34<11:11,  7.38s/it]Running generate_until requests:  45%|████▌     | 75/165 [09:40<10:26,  6.96s/it]Running generate_until requests:  46%|████▌     | 76/165 [09:47<10:21,  6.98s/it]Running generate_until requests:  47%|████▋     | 77/165 [09:57<11:43,  8.00s/it]Running generate_until requests:  47%|████▋     | 78/165 [10:03<10:48,  7.46s/it]Running generate_until requests:  48%|████▊     | 79/165 [10:12<11:19,  7.90s/it]Running generate_until requests:  48%|████▊     | 80/165 [10:19<10:36,  7.49s/it]Running generate_until requests:  49%|████▉     | 81/165 [10:25<10:07,  7.23s/it]Running generate_until requests:  50%|████▉     | 82/165 [10:35<10:55,  7.89s/it]Running generate_until requests:  50%|█████     | 83/165 [10:46<12:11,  8.92s/it]Running generate_until requests:  51%|█████     | 84/165 [10:52<10:56,  8.11s/it]Running generate_until requests:  52%|█████▏    | 85/165 [10:59<10:19,  7.75s/it]Running generate_until requests:  52%|█████▏    | 86/165 [11:07<10:16,  7.80s/it]Running generate_until requests:  53%|█████▎    | 87/165 [11:10<07:59,  6.15s/it]Running generate_until requests:  53%|█████▎    | 88/165 [11:15<07:44,  6.03s/it]Running generate_until requests:  54%|█████▍    | 89/165 [11:21<07:36,  6.01s/it]Running generate_until requests:  55%|█████▍    | 90/165 [11:26<06:54,  5.53s/it]Running generate_until requests:  55%|█████▌    | 91/165 [11:32<07:14,  5.87s/it]Running generate_until requests:  56%|█████▌    | 92/165 [11:41<08:06,  6.66s/it]Running generate_until requests:  56%|█████▋    | 93/165 [11:46<07:34,  6.31s/it]Running generate_until requests:  57%|█████▋    | 94/165 [11:52<07:23,  6.25s/it]Running generate_until requests:  58%|█████▊    | 95/165 [11:59<07:33,  6.48s/it]Running generate_until requests:  58%|█████▊    | 96/165 [12:06<07:25,  6.45s/it]Running generate_until requests:  59%|█████▉    | 97/165 [12:15<08:15,  7.29s/it]Running generate_until requests:  59%|█████▉    | 98/165 [12:22<08:09,  7.31s/it]Running generate_until requests:  60%|██████    | 99/165 [12:28<07:32,  6.86s/it]Running generate_until requests:  61%|██████    | 100/165 [12:35<07:20,  6.78s/it]Running generate_until requests:  61%|██████    | 101/165 [12:42<07:12,  6.76s/it]Running generate_until requests:  62%|██████▏   | 102/165 [12:46<06:22,  6.07s/it]Running generate_until requests:  62%|██████▏   | 103/165 [12:51<05:47,  5.60s/it]Running generate_until requests:  63%|██████▎   | 104/165 [12:56<05:36,  5.51s/it]Running generate_until requests:  64%|██████▎   | 105/165 [13:03<06:01,  6.03s/it]Running generate_until requests:  64%|██████▍   | 106/165 [13:08<05:38,  5.73s/it]Running generate_until requests:  65%|██████▍   | 107/165 [13:14<05:39,  5.85s/it]Running generate_until requests:  65%|██████▌   | 108/165 [13:19<05:12,  5.49s/it]Running generate_until requests:  66%|██████▌   | 109/165 [13:26<05:27,  5.85s/it]Running generate_until requests:  67%|██████▋   | 110/165 [13:32<05:24,  5.89s/it]Running generate_until requests:  67%|██████▋   | 111/165 [13:46<07:38,  8.50s/it]Running generate_until requests:  68%|██████▊   | 112/165 [13:51<06:26,  7.29s/it]Running generate_until requests:  68%|██████▊   | 113/165 [13:56<05:52,  6.77s/it]Running generate_until requests:  69%|██████▉   | 114/165 [14:05<06:12,  7.31s/it]Running generate_until requests:  70%|██████▉   | 115/165 [14:10<05:30,  6.60s/it]Running generate_until requests:  70%|███████   | 116/165 [14:13<04:29,  5.49s/it]Running generate_until requests:  71%|███████   | 117/165 [14:18<04:21,  5.45s/it]Running generate_until requests:  72%|███████▏  | 118/165 [14:24<04:28,  5.71s/it]Running generate_until requests:  72%|███████▏  | 119/165 [14:32<04:53,  6.38s/it]Running generate_until requests:  73%|███████▎  | 120/165 [14:35<03:58,  5.30s/it]Running generate_until requests:  73%|███████▎  | 121/165 [14:38<03:19,  4.54s/it]Running generate_until requests:  74%|███████▍  | 122/165 [14:48<04:28,  6.25s/it]Running generate_until requests:  75%|███████▍  | 123/165 [14:56<04:42,  6.73s/it]Running generate_until requests:  75%|███████▌  | 124/165 [15:03<04:44,  6.95s/it]Running generate_until requests:  76%|███████▌  | 125/165 [15:09<04:18,  6.45s/it]Running generate_until requests:  76%|███████▋  | 126/165 [15:21<05:17,  8.15s/it]Running generate_until requests:  77%|███████▋  | 127/165 [15:28<04:59,  7.87s/it]Running generate_until requests:  78%|███████▊  | 128/165 [15:33<04:19,  7.01s/it]Running generate_until requests:  78%|███████▊  | 129/165 [15:41<04:23,  7.33s/it]Running generate_until requests:  79%|███████▉  | 130/165 [15:49<04:27,  7.64s/it]Running generate_until requests:  79%|███████▉  | 131/165 [15:54<03:49,  6.76s/it]Running generate_until requests:  80%|████████  | 132/165 [15:59<03:29,  6.35s/it]Running generate_until requests:  81%|████████  | 133/165 [16:06<03:22,  6.33s/it]Running generate_until requests:  81%|████████  | 134/165 [16:15<03:42,  7.16s/it]Running generate_until requests:  82%|████████▏ | 135/165 [16:17<02:49,  5.64s/it]Running generate_until requests:  82%|████████▏ | 136/165 [16:21<02:31,  5.23s/it]Running generate_until requests:  83%|████████▎ | 137/165 [16:28<02:42,  5.79s/it]Running generate_until requests:  84%|████████▎ | 138/165 [16:34<02:38,  5.87s/it]Running generate_until requests:  84%|████████▍ | 139/165 [16:39<02:26,  5.63s/it]Running generate_until requests:  85%|████████▍ | 140/165 [16:45<02:16,  5.48s/it]Running generate_until requests:  85%|████████▌ | 141/165 [16:51<02:18,  5.75s/it]Running generate_until requests:  86%|████████▌ | 142/165 [16:54<01:54,  5.00s/it]Running generate_until requests:  87%|████████▋ | 143/165 [17:02<02:10,  5.91s/it]Running generate_until requests:  87%|████████▋ | 144/165 [17:08<02:01,  5.79s/it]Running generate_until requests:  88%|████████▊ | 145/165 [17:13<01:51,  5.59s/it]Running generate_until requests:  88%|████████▊ | 146/165 [17:18<01:43,  5.45s/it]Running generate_until requests:  89%|████████▉ | 147/165 [17:23<01:37,  5.41s/it]Running generate_until requests:  90%|████████▉ | 148/165 [17:29<01:34,  5.55s/it]Running generate_until requests:  90%|█████████ | 149/165 [17:33<01:20,  5.01s/it]Running generate_until requests:  91%|█████████ | 150/165 [17:38<01:13,  4.90s/it]Running generate_until requests:  92%|█████████▏| 151/165 [17:43<01:10,  5.00s/it]Running generate_until requests:  92%|█████████▏| 152/165 [17:48<01:05,  5.01s/it]Running generate_until requests:  93%|█████████▎| 153/165 [17:53<00:58,  4.91s/it]Running generate_until requests:  93%|█████████▎| 154/165 [18:00<01:02,  5.68s/it]Running generate_until requests:  94%|█████████▍| 155/165 [18:04<00:52,  5.29s/it]Running generate_until requests:  95%|█████████▍| 156/165 [18:10<00:48,  5.42s/it]Running generate_until requests:  95%|█████████▌| 157/165 [18:19<00:50,  6.32s/it]Running generate_until requests:  96%|█████████▌| 158/165 [18:24<00:41,  5.97s/it]Running generate_until requests:  96%|█████████▋| 159/165 [18:30<00:35,  5.94s/it]Running generate_until requests:  97%|█████████▋| 160/165 [18:37<00:32,  6.47s/it]Running generate_until requests:  98%|█████████▊| 161/165 [18:42<00:23,  5.93s/it]Running generate_until requests:  98%|█████████▊| 162/165 [18:47<00:16,  5.53s/it]Running generate_until requests:  99%|█████████▉| 163/165 [18:52<00:10,  5.39s/it]Running generate_until requests:  99%|█████████▉| 164/165 [18:56<00:05,  5.11s/it]Running generate_until requests: 100%|██████████| 165/165 [19:03<00:00,  5.58s/it]Running generate_until requests: 100%|██████████| 165/165 [19:03<00:00,  6.93s/it]
[2024-06-03 15:14:55,505] torch.distributed.elastic.multiprocessing.api: [WARNING] Sending process 747418 closing signal SIGTERM
[2024-06-03 15:14:55,521] torch.distributed.elastic.multiprocessing.api: [WARNING] Sending process 747419 closing signal SIGTERM
[2024-06-03 15:14:55,521] torch.distributed.elastic.multiprocessing.api: [WARNING] Sending process 747420 closing signal SIGTERM
[2024-06-03 15:14:55,521] torch.distributed.elastic.multiprocessing.api: [WARNING] Sending process 747421 closing signal SIGTERM
[2024-06-03 15:14:55,521] torch.distributed.elastic.multiprocessing.api: [WARNING] Sending process 747422 closing signal SIGTERM
[2024-06-03 15:14:59,324] torch.distributed.elastic.multiprocessing.api: [ERROR] failed (exitcode: -7) local_rank: 5 (pid: 747423) of binary: /private/home/beidic/.conda/envs/griffin/bin/python
Traceback (most recent call last):
  File "/private/home/beidic/.conda/envs/griffin/bin/accelerate", line 8, in <module>
    sys.exit(main())
             ^^^^^^
  File "/private/home/beidic/.conda/envs/griffin/lib/python3.12/site-packages/accelerate/commands/accelerate_cli.py", line 47, in main
    args.func(args)
  File "/private/home/beidic/.conda/envs/griffin/lib/python3.12/site-packages/accelerate/commands/launch.py", line 985, in launch_command
    multi_gpu_launcher(args)
  File "/private/home/beidic/.conda/envs/griffin/lib/python3.12/site-packages/accelerate/commands/launch.py", line 654, in multi_gpu_launcher
    distrib_run.run(args)
  File "/private/home/beidic/.conda/envs/griffin/lib/python3.12/site-packages/torch/distributed/run.py", line 803, in run
    elastic_launch(
  File "/private/home/beidic/.conda/envs/griffin/lib/python3.12/site-packages/torch/distributed/launcher/api.py", line 135, in __call__
    return launch_agent(self._config, self._entrypoint, list(args))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/private/home/beidic/.conda/envs/griffin/lib/python3.12/site-packages/torch/distributed/launcher/api.py", line 268, in launch_agent
    raise ChildFailedError(
torch.distributed.elastic.multiprocessing.errors.ChildFailedError: 
======================================================
main.py FAILED
------------------------------------------------------
Failures:
[1]:
  time      : 2024-06-03_15:14:55
  host      : learnfair7717.h2.fair
  rank      : 6 (local_rank: 6)
  exitcode  : -7 (pid: 747424)
  error_file: <N/A>
  traceback : Signal 7 (SIGBUS) received by PID 747424
[2]:
  time      : 2024-06-03_15:14:55
  host      : learnfair7717.h2.fair
  rank      : 7 (local_rank: 7)
  exitcode  : -7 (pid: 747425)
  error_file: <N/A>
  traceback : Signal 7 (SIGBUS) received by PID 747425
------------------------------------------------------
Root Cause (first observed failure):
[0]:
  time      : 2024-06-03_15:14:55
  host      : learnfair7717.h2.fair
  rank      : 5 (local_rank: 5)
  exitcode  : -7 (pid: 747423)
  error_file: <N/A>
  traceback : Signal 7 (SIGBUS) received by PID 747423
======================================================
/var/spool/slurm//job28549289/slurm_script: line 63: 747366 Bus error               (core dumped) accelerate launch --main_process_port 29510 --num_processes 8 --num_machines 1 main.py --model xhf --model_args pretrained=meta-llama/Llama-2-7b-chat-hf,cats=True,check=False --tasks gsm8k --batch_size 1
