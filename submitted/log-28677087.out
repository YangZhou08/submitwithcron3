M	__pycache__/cache.cpython-312.pyc
M	__pycache__/xevaluator.cpython-312.pyc
M	__pycache__/xhuggingface.cpython-312.pyc
Your branch is up to date with 'origin/yangexp2'.
Already up to date.
/private/home/beidic/.conda/envs/griffin/bin/python
[1m[31mERROR! `huggingface-cli login` uses an outdated login mechanism that is not compatible with the Hugging Face Hub backend anymore. Please use `huggingface-cli login instead.[0m
The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-cli` if you want to set the git credential as well.
Namespace(model='xhf', tasks='gsm8k', model_args='pretrained=meta-llama/Meta-Llama-3-8B-Instruct,cats=True,spr=0.3,check=True,kernel_size=16,thr=0.05', num_fewshot=None, batch_size='1', max_batch_size=None, device=None, output_path=None, limit=0.5, topp=1.1, topk=64, spr=0.25, sink=8, local=256, use_cache=None, cache_requests=None, check_integrity=False, write_out=False, log_samples=False, show_config=False, include_path=None, gen_kwargs=None, verbosity='INFO', wandb_args='', predict_only=False, seed=[0, 1234, 1234], trust_remote_code=False)
Namespace(model='xhf', tasks='gsm8k', model_args='pretrained=meta-llama/Meta-Llama-3-8B-Instruct,cats=True,spr=0.3,check=True,kernel_size=16,thr=0.05', num_fewshot=None, batch_size='1', max_batch_size=None, device=None, output_path=None, limit=0.5, topp=1.1, topk=64, spr=0.25, sink=8, local=256, use_cache=None, cache_requests=None, check_integrity=False, write_out=False, log_samples=False, show_config=False, include_path=None, gen_kwargs=None, verbosity='INFO', wandb_args='', predict_only=False, seed=[0, 1234, 1234], trust_remote_code=False)
Namespace(model='xhf', tasks='gsm8k', model_args='pretrained=meta-llama/Meta-Llama-3-8B-Instruct,cats=True,spr=0.3,check=True,kernel_size=16,thr=0.05', num_fewshot=None, batch_size='1', max_batch_size=None, device=None, output_path=None, limit=0.5, topp=1.1, topk=64, spr=0.25, sink=8, local=256, use_cache=None, cache_requests=None, check_integrity=False, write_out=False, log_samples=False, show_config=False, include_path=None, gen_kwargs=None, verbosity='INFO', wandb_args='', predict_only=False, seed=[0, 1234, 1234], trust_remote_code=False)
Namespace(model='xhf', tasks='gsm8k', model_args='pretrained=meta-llama/Meta-Llama-3-8B-Instruct,cats=True,spr=0.3,check=True,kernel_size=16,thr=0.05', num_fewshot=None, batch_size='1', max_batch_size=None, device=None, output_path=None, limit=0.5, topp=1.1, topk=64, spr=0.25, sink=8, local=256, use_cache=None, cache_requests=None, check_integrity=False, write_out=False, log_samples=False, show_config=False, include_path=None, gen_kwargs=None, verbosity='INFO', wandb_args='', predict_only=False, seed=[0, 1234, 1234], trust_remote_code=False)
Namespace(model='xhf', tasks='gsm8k', model_args='pretrained=meta-llama/Meta-Llama-3-8B-Instruct,cats=True,spr=0.3,check=True,kernel_size=16,thr=0.05', num_fewshot=None, batch_size='1', max_batch_size=None, device=None, output_path=None, limit=0.5, topp=1.1, topk=64, spr=0.25, sink=8, local=256, use_cache=None, cache_requests=None, check_integrity=False, write_out=False, log_samples=False, show_config=False, include_path=None, gen_kwargs=None, verbosity='INFO', wandb_args='', predict_only=False, seed=[0, 1234, 1234], trust_remote_code=False)
Namespace(model='xhf', tasks='gsm8k', model_args='pretrained=meta-llama/Meta-Llama-3-8B-Instruct,cats=True,spr=0.3,check=True,kernel_size=16,thr=0.05', num_fewshot=None, batch_size='1', max_batch_size=None, device=None, output_path=None, limit=0.5, topp=1.1, topk=64, spr=0.25, sink=8, local=256, use_cache=None, cache_requests=None, check_integrity=False, write_out=False, log_samples=False, show_config=False, include_path=None, gen_kwargs=None, verbosity='INFO', wandb_args='', predict_only=False, seed=[0, 1234, 1234], trust_remote_code=False)
Namespace(model='xhf', tasks='gsm8k', model_args='pretrained=meta-llama/Meta-Llama-3-8B-Instruct,cats=True,spr=0.3,check=True,kernel_size=16,thr=0.05', num_fewshot=None, batch_size='1', max_batch_size=None, device=None, output_path=None, limit=0.5, topp=1.1, topk=64, spr=0.25, sink=8, local=256, use_cache=None, cache_requests=None, check_integrity=False, write_out=False, log_samples=False, show_config=False, include_path=None, gen_kwargs=None, verbosity='INFO', wandb_args='', predict_only=False, seed=[0, 1234, 1234], trust_remote_code=False)
Namespace(model='xhf', tasks='gsm8k', model_args='pretrained=meta-llama/Meta-Llama-3-8B-Instruct,cats=True,spr=0.3,check=True,kernel_size=16,thr=0.05', num_fewshot=None, batch_size='1', max_batch_size=None, device=None, output_path=None, limit=0.5, topp=1.1, topk=64, spr=0.25, sink=8, local=256, use_cache=None, cache_requests=None, check_integrity=False, write_out=False, log_samples=False, show_config=False, include_path=None, gen_kwargs=None, verbosity='INFO', wandb_args='', predict_only=False, seed=[0, 1234, 1234], trust_remote_code=False)
8017 926 8.657667386609072
6881 797 8.633626097867001
7512 859 8.745052386495926
7273 882 8.246031746031745
7907 930 8.502150537634408
7900 937 8.431163287086447
8213 956 8.591004184100418
8252 973 8.48098663926002
xhf (pretrained=meta-llama/Meta-Llama-3-8B-Instruct,cats=True,spr=0.3,check=True,kernel_size=16,thr=0.05), gen_kwargs: (None), limit: 0.5, num_fewshot: None, batch_size: 1
|Tasks|Version|     Filter     |n-shot|  Metric   |Value |   |Stderr|
|-----|------:|----------------|-----:|-----------|-----:|---|-----:|
|gsm8k|      3|strict-match    |     5|exact_match|0.5864|Â±  |0.0192|
|     |       |flexible-extract|     5|exact_match|0.6015|Â±  |0.0191|

Namespace(model='xhf', tasks='gsm8k', model_args='pretrained=meta-llama/Meta-Llama-3-8B-Instruct,cats=True,spr=0.3,check=True,kernel_size=16,thr=0.1', num_fewshot=None, batch_size='1', max_batch_size=None, device=None, output_path=None, limit=0.5, topp=1.1, topk=64, spr=0.25, sink=8, local=256, use_cache=None, cache_requests=None, check_integrity=False, write_out=False, log_samples=False, show_config=False, include_path=None, gen_kwargs=None, verbosity='INFO', wandb_args='', predict_only=False, seed=[0, 1234, 1234], trust_remote_code=False)
Namespace(model='xhf', tasks='gsm8k', model_args='pretrained=meta-llama/Meta-Llama-3-8B-Instruct,cats=True,spr=0.3,check=True,kernel_size=16,thr=0.1', num_fewshot=None, batch_size='1', max_batch_size=None, device=None, output_path=None, limit=0.5, topp=1.1, topk=64, spr=0.25, sink=8, local=256, use_cache=None, cache_requests=None, check_integrity=False, write_out=False, log_samples=False, show_config=False, include_path=None, gen_kwargs=None, verbosity='INFO', wandb_args='', predict_only=False, seed=[0, 1234, 1234], trust_remote_code=False)
Namespace(model='xhf', tasks='gsm8k', model_args='pretrained=meta-llama/Meta-Llama-3-8B-Instruct,cats=True,spr=0.3,check=True,kernel_size=16,thr=0.1', num_fewshot=None, batch_size='1', max_batch_size=None, device=None, output_path=None, limit=0.5, topp=1.1, topk=64, spr=0.25, sink=8, local=256, use_cache=None, cache_requests=None, check_integrity=False, write_out=False, log_samples=False, show_config=False, include_path=None, gen_kwargs=None, verbosity='INFO', wandb_args='', predict_only=False, seed=[0, 1234, 1234], trust_remote_code=False)
Namespace(model='xhf', tasks='gsm8k', model_args='pretrained=meta-llama/Meta-Llama-3-8B-Instruct,cats=True,spr=0.3,check=True,kernel_size=16,thr=0.1', num_fewshot=None, batch_size='1', max_batch_size=None, device=None, output_path=None, limit=0.5, topp=1.1, topk=64, spr=0.25, sink=8, local=256, use_cache=None, cache_requests=None, check_integrity=False, write_out=False, log_samples=False, show_config=False, include_path=None, gen_kwargs=None, verbosity='INFO', wandb_args='', predict_only=False, seed=[0, 1234, 1234], trust_remote_code=False)
Namespace(model='xhf', tasks='gsm8k', model_args='pretrained=meta-llama/Meta-Llama-3-8B-Instruct,cats=True,spr=0.3,check=True,kernel_size=16,thr=0.1', num_fewshot=None, batch_size='1', max_batch_size=None, device=None, output_path=None, limit=0.5, topp=1.1, topk=64, spr=0.25, sink=8, local=256, use_cache=None, cache_requests=None, check_integrity=False, write_out=False, log_samples=False, show_config=False, include_path=None, gen_kwargs=None, verbosity='INFO', wandb_args='', predict_only=False, seed=[0, 1234, 1234], trust_remote_code=False)
Namespace(model='xhf', tasks='gsm8k', model_args='pretrained=meta-llama/Meta-Llama-3-8B-Instruct,cats=True,spr=0.3,check=True,kernel_size=16,thr=0.1', num_fewshot=None, batch_size='1', max_batch_size=None, device=None, output_path=None, limit=0.5, topp=1.1, topk=64, spr=0.25, sink=8, local=256, use_cache=None, cache_requests=None, check_integrity=False, write_out=False, log_samples=False, show_config=False, include_path=None, gen_kwargs=None, verbosity='INFO', wandb_args='', predict_only=False, seed=[0, 1234, 1234], trust_remote_code=False)
Namespace(model='xhf', tasks='gsm8k', model_args='pretrained=meta-llama/Meta-Llama-3-8B-Instruct,cats=True,spr=0.3,check=True,kernel_size=16,thr=0.1', num_fewshot=None, batch_size='1', max_batch_size=None, device=None, output_path=None, limit=0.5, topp=1.1, topk=64, spr=0.25, sink=8, local=256, use_cache=None, cache_requests=None, check_integrity=False, write_out=False, log_samples=False, show_config=False, include_path=None, gen_kwargs=None, verbosity='INFO', wandb_args='', predict_only=False, seed=[0, 1234, 1234], trust_remote_code=False)
Namespace(model='xhf', tasks='gsm8k', model_args='pretrained=meta-llama/Meta-Llama-3-8B-Instruct,cats=True,spr=0.3,check=True,kernel_size=16,thr=0.1', num_fewshot=None, batch_size='1', max_batch_size=None, device=None, output_path=None, limit=0.5, topp=1.1, topk=64, spr=0.25, sink=8, local=256, use_cache=None, cache_requests=None, check_integrity=False, write_out=False, log_samples=False, show_config=False, include_path=None, gen_kwargs=None, verbosity='INFO', wandb_args='', predict_only=False, seed=[0, 1234, 1234], trust_remote_code=False)
7203 899 8.012235817575084
8177 1058 7.728733459357278
7940 1025 7.746341463414634
7333 941 7.792773645058449
8362 1087 7.6927322907083715
7476 999 7.483483483483483
7724 1009 7.655104063429138
7786 1006 7.739562624254473
xhf (pretrained=meta-llama/Meta-Llama-3-8B-Instruct,cats=True,spr=0.3,check=True,kernel_size=16,thr=0.1), gen_kwargs: (None), limit: 0.5, num_fewshot: None, batch_size: 1
|Tasks|Version|     Filter     |n-shot|  Metric   |Value |   |Stderr|
|-----|------:|----------------|-----:|-----------|-----:|---|-----:|
|gsm8k|      3|strict-match    |     5|exact_match|0.5970|Â±  |0.0191|
|     |       |flexible-extract|     5|exact_match|0.6182|Â±  |0.0189|

Namespace(model='xhf', tasks='gsm8k', model_args='pretrained=meta-llama/Meta-Llama-3-8B-Instruct,cats=True,spr=0.3,check=True,kernel_size=16,thr=0.15', num_fewshot=None, batch_size='1', max_batch_size=None, device=None, output_path=None, limit=0.5, topp=1.1, topk=64, spr=0.25, sink=8, local=256, use_cache=None, cache_requests=None, check_integrity=False, write_out=False, log_samples=False, show_config=False, include_path=None, gen_kwargs=None, verbosity='INFO', wandb_args='', predict_only=False, seed=[0, 1234, 1234], trust_remote_code=False)
Namespace(model='xhf', tasks='gsm8k', model_args='pretrained=meta-llama/Meta-Llama-3-8B-Instruct,cats=True,spr=0.3,check=True,kernel_size=16,thr=0.15', num_fewshot=None, batch_size='1', max_batch_size=None, device=None, output_path=None, limit=0.5, topp=1.1, topk=64, spr=0.25, sink=8, local=256, use_cache=None, cache_requests=None, check_integrity=False, write_out=False, log_samples=False, show_config=False, include_path=None, gen_kwargs=None, verbosity='INFO', wandb_args='', predict_only=False, seed=[0, 1234, 1234], trust_remote_code=False)
Namespace(model='xhf', tasks='gsm8k', model_args='pretrained=meta-llama/Meta-Llama-3-8B-Instruct,cats=True,spr=0.3,check=True,kernel_size=16,thr=0.15', num_fewshot=None, batch_size='1', max_batch_size=None, device=None, output_path=None, limit=0.5, topp=1.1, topk=64, spr=0.25, sink=8, local=256, use_cache=None, cache_requests=None, check_integrity=False, write_out=False, log_samples=False, show_config=False, include_path=None, gen_kwargs=None, verbosity='INFO', wandb_args='', predict_only=False, seed=[0, 1234, 1234], trust_remote_code=False)
Namespace(model='xhf', tasks='gsm8k', model_args='pretrained=meta-llama/Meta-Llama-3-8B-Instruct,cats=True,spr=0.3,check=True,kernel_size=16,thr=0.15', num_fewshot=None, batch_size='1', max_batch_size=None, device=None, output_path=None, limit=0.5, topp=1.1, topk=64, spr=0.25, sink=8, local=256, use_cache=None, cache_requests=None, check_integrity=False, write_out=False, log_samples=False, show_config=False, include_path=None, gen_kwargs=None, verbosity='INFO', wandb_args='', predict_only=False, seed=[0, 1234, 1234], trust_remote_code=False)
Namespace(model='xhf', tasks='gsm8k', model_args='pretrained=meta-llama/Meta-Llama-3-8B-Instruct,cats=True,spr=0.3,check=True,kernel_size=16,thr=0.15', num_fewshot=None, batch_size='1', max_batch_size=None, device=None, output_path=None, limit=0.5, topp=1.1, topk=64, spr=0.25, sink=8, local=256, use_cache=None, cache_requests=None, check_integrity=False, write_out=False, log_samples=False, show_config=False, include_path=None, gen_kwargs=None, verbosity='INFO', wandb_args='', predict_only=False, seed=[0, 1234, 1234], trust_remote_code=False)
Namespace(model='xhf', tasks='gsm8k', model_args='pretrained=meta-llama/Meta-Llama-3-8B-Instruct,cats=True,spr=0.3,check=True,kernel_size=16,thr=0.15', num_fewshot=None, batch_size='1', max_batch_size=None, device=None, output_path=None, limit=0.5, topp=1.1, topk=64, spr=0.25, sink=8, local=256, use_cache=None, cache_requests=None, check_integrity=False, write_out=False, log_samples=False, show_config=False, include_path=None, gen_kwargs=None, verbosity='INFO', wandb_args='', predict_only=False, seed=[0, 1234, 1234], trust_remote_code=False)
Namespace(model='xhf', tasks='gsm8k', model_args='pretrained=meta-llama/Meta-Llama-3-8B-Instruct,cats=True,spr=0.3,check=True,kernel_size=16,thr=0.15', num_fewshot=None, batch_size='1', max_batch_size=None, device=None, output_path=None, limit=0.5, topp=1.1, topk=64, spr=0.25, sink=8, local=256, use_cache=None, cache_requests=None, check_integrity=False, write_out=False, log_samples=False, show_config=False, include_path=None, gen_kwargs=None, verbosity='INFO', wandb_args='', predict_only=False, seed=[0, 1234, 1234], trust_remote_code=False)
Namespace(model='xhf', tasks='gsm8k', model_args='pretrained=meta-llama/Meta-Llama-3-8B-Instruct,cats=True,spr=0.3,check=True,kernel_size=16,thr=0.15', num_fewshot=None, batch_size='1', max_batch_size=None, device=None, output_path=None, limit=0.5, topp=1.1, topk=64, spr=0.25, sink=8, local=256, use_cache=None, cache_requests=None, check_integrity=False, write_out=False, log_samples=False, show_config=False, include_path=None, gen_kwargs=None, verbosity='INFO', wandb_args='', predict_only=False, seed=[0, 1234, 1234], trust_remote_code=False)
7062 950 7.433684210526316
7534 1072 7.027985074626866
7724 1081 7.145235892691952
7181 998 7.195390781563126
8308 1107 7.504968383017164
7383 1059 6.971671388101983
8173 1141 7.163014899211218
8094 1117 7.246195165622202
xhf (pretrained=meta-llama/Meta-Llama-3-8B-Instruct,cats=True,spr=0.3,check=True,kernel_size=16,thr=0.15), gen_kwargs: (None), limit: 0.5, num_fewshot: None, batch_size: 1
|Tasks|Version|     Filter     |n-shot|  Metric   |Value |   |Stderr|
|-----|------:|----------------|-----:|-----------|-----:|---|-----:|
|gsm8k|      3|strict-match    |     5|exact_match|0.6106|Â±  |0.0190|
|     |       |flexible-extract|     5|exact_match|0.6364|Â±  |0.0187|

Namespace(model='xhf', tasks='gsm8k', model_args='pretrained=meta-llama/Meta-Llama-3-8B-Instruct,cats=True,spr=0.3,check=True,kernel_size=16,thr=0.2', num_fewshot=None, batch_size='1', max_batch_size=None, device=None, output_path=None, limit=0.5, topp=1.1, topk=64, spr=0.25, sink=8, local=256, use_cache=None, cache_requests=None, check_integrity=False, write_out=False, log_samples=False, show_config=False, include_path=None, gen_kwargs=None, verbosity='INFO', wandb_args='', predict_only=False, seed=[0, 1234, 1234], trust_remote_code=False)
Namespace(model='xhf', tasks='gsm8k', model_args='pretrained=meta-llama/Meta-Llama-3-8B-Instruct,cats=True,spr=0.3,check=True,kernel_size=16,thr=0.2', num_fewshot=None, batch_size='1', max_batch_size=None, device=None, output_path=None, limit=0.5, topp=1.1, topk=64, spr=0.25, sink=8, local=256, use_cache=None, cache_requests=None, check_integrity=False, write_out=False, log_samples=False, show_config=False, include_path=None, gen_kwargs=None, verbosity='INFO', wandb_args='', predict_only=False, seed=[0, 1234, 1234], trust_remote_code=False)
Namespace(model='xhf', tasks='gsm8k', model_args='pretrained=meta-llama/Meta-Llama-3-8B-Instruct,cats=True,spr=0.3,check=True,kernel_size=16,thr=0.2', num_fewshot=None, batch_size='1', max_batch_size=None, device=None, output_path=None, limit=0.5, topp=1.1, topk=64, spr=0.25, sink=8, local=256, use_cache=None, cache_requests=None, check_integrity=False, write_out=False, log_samples=False, show_config=False, include_path=None, gen_kwargs=None, verbosity='INFO', wandb_args='', predict_only=False, seed=[0, 1234, 1234], trust_remote_code=False)
Namespace(model='xhf', tasks='gsm8k', model_args='pretrained=meta-llama/Meta-Llama-3-8B-Instruct,cats=True,spr=0.3,check=True,kernel_size=16,thr=0.2', num_fewshot=None, batch_size='1', max_batch_size=None, device=None, output_path=None, limit=0.5, topp=1.1, topk=64, spr=0.25, sink=8, local=256, use_cache=None, cache_requests=None, check_integrity=False, write_out=False, log_samples=False, show_config=False, include_path=None, gen_kwargs=None, verbosity='INFO', wandb_args='', predict_only=False, seed=[0, 1234, 1234], trust_remote_code=False)
Namespace(model='xhf', tasks='gsm8k', model_args='pretrained=meta-llama/Meta-Llama-3-8B-Instruct,cats=True,spr=0.3,check=True,kernel_size=16,thr=0.2', num_fewshot=None, batch_size='1', max_batch_size=None, device=None, output_path=None, limit=0.5, topp=1.1, topk=64, spr=0.25, sink=8, local=256, use_cache=None, cache_requests=None, check_integrity=False, write_out=False, log_samples=False, show_config=False, include_path=None, gen_kwargs=None, verbosity='INFO', wandb_args='', predict_only=False, seed=[0, 1234, 1234], trust_remote_code=False)
Namespace(model='xhf', tasks='gsm8k', model_args='pretrained=meta-llama/Meta-Llama-3-8B-Instruct,cats=True,spr=0.3,check=True,kernel_size=16,thr=0.2', num_fewshot=None, batch_size='1', max_batch_size=None, device=None, output_path=None, limit=0.5, topp=1.1, topk=64, spr=0.25, sink=8, local=256, use_cache=None, cache_requests=None, check_integrity=False, write_out=False, log_samples=False, show_config=False, include_path=None, gen_kwargs=None, verbosity='INFO', wandb_args='', predict_only=False, seed=[0, 1234, 1234], trust_remote_code=False)
Namespace(model='xhf', tasks='gsm8k', model_args='pretrained=meta-llama/Meta-Llama-3-8B-Instruct,cats=True,spr=0.3,check=True,kernel_size=16,thr=0.2', num_fewshot=None, batch_size='1', max_batch_size=None, device=None, output_path=None, limit=0.5, topp=1.1, topk=64, spr=0.25, sink=8, local=256, use_cache=None, cache_requests=None, check_integrity=False, write_out=False, log_samples=False, show_config=False, include_path=None, gen_kwargs=None, verbosity='INFO', wandb_args='', predict_only=False, seed=[0, 1234, 1234], trust_remote_code=False)
Namespace(model='xhf', tasks='gsm8k', model_args='pretrained=meta-llama/Meta-Llama-3-8B-Instruct,cats=True,spr=0.3,check=True,kernel_size=16,thr=0.2', num_fewshot=None, batch_size='1', max_batch_size=None, device=None, output_path=None, limit=0.5, topp=1.1, topk=64, spr=0.25, sink=8, local=256, use_cache=None, cache_requests=None, check_integrity=False, write_out=False, log_samples=False, show_config=False, include_path=None, gen_kwargs=None, verbosity='INFO', wandb_args='', predict_only=False, seed=[0, 1234, 1234], trust_remote_code=False)
7367 1110 6.636936936936937
7051 1017 6.933136676499508
7590 1151 6.594265855777585
6992 1038 6.736030828516378
7944 1168 6.801369863013699
7751 1161 6.676141257536607
7928 1146 6.9179755671902265
7604 1082 7.027726432532347
xhf (pretrained=meta-llama/Meta-Llama-3-8B-Instruct,cats=True,spr=0.3,check=True,kernel_size=16,thr=0.2), gen_kwargs: (None), limit: 0.5, num_fewshot: None, batch_size: 1
|Tasks|Version|     Filter     |n-shot|  Metric   |Value |   |Stderr|
|-----|------:|----------------|-----:|-----------|-----:|---|-----:|
|gsm8k|      3|strict-match    |     5|exact_match|0.6152|Â±  |0.0190|
|     |       |flexible-extract|     5|exact_match|0.6561|Â±  |0.0185|

Namespace(model='xhf', tasks='gsm8k', model_args='pretrained=meta-llama/Meta-Llama-3-8B-Instruct,cats=True,spr=0.3,check=True,kernel_size=16,thr=0.3', num_fewshot=None, batch_size='1', max_batch_size=None, device=None, output_path=None, limit=0.5, topp=1.1, topk=64, spr=0.25, sink=8, local=256, use_cache=None, cache_requests=None, check_integrity=False, write_out=False, log_samples=False, show_config=False, include_path=None, gen_kwargs=None, verbosity='INFO', wandb_args='', predict_only=False, seed=[0, 1234, 1234], trust_remote_code=False)
Namespace(model='xhf', tasks='gsm8k', model_args='pretrained=meta-llama/Meta-Llama-3-8B-Instruct,cats=True,spr=0.3,check=True,kernel_size=16,thr=0.3', num_fewshot=None, batch_size='1', max_batch_size=None, device=None, output_path=None, limit=0.5, topp=1.1, topk=64, spr=0.25, sink=8, local=256, use_cache=None, cache_requests=None, check_integrity=False, write_out=False, log_samples=False, show_config=False, include_path=None, gen_kwargs=None, verbosity='INFO', wandb_args='', predict_only=False, seed=[0, 1234, 1234], trust_remote_code=False)
Namespace(model='xhf', tasks='gsm8k', model_args='pretrained=meta-llama/Meta-Llama-3-8B-Instruct,cats=True,spr=0.3,check=True,kernel_size=16,thr=0.3', num_fewshot=None, batch_size='1', max_batch_size=None, device=None, output_path=None, limit=0.5, topp=1.1, topk=64, spr=0.25, sink=8, local=256, use_cache=None, cache_requests=None, check_integrity=False, write_out=False, log_samples=False, show_config=False, include_path=None, gen_kwargs=None, verbosity='INFO', wandb_args='', predict_only=False, seed=[0, 1234, 1234], trust_remote_code=False)
Namespace(model='xhf', tasks='gsm8k', model_args='pretrained=meta-llama/Meta-Llama-3-8B-Instruct,cats=True,spr=0.3,check=True,kernel_size=16,thr=0.3', num_fewshot=None, batch_size='1', max_batch_size=None, device=None, output_path=None, limit=0.5, topp=1.1, topk=64, spr=0.25, sink=8, local=256, use_cache=None, cache_requests=None, check_integrity=False, write_out=False, log_samples=False, show_config=False, include_path=None, gen_kwargs=None, verbosity='INFO', wandb_args='', predict_only=False, seed=[0, 1234, 1234], trust_remote_code=False)
Namespace(model='xhf', tasks='gsm8k', model_args='pretrained=meta-llama/Meta-Llama-3-8B-Instruct,cats=True,spr=0.3,check=True,kernel_size=16,thr=0.3', num_fewshot=None, batch_size='1', max_batch_size=None, device=None, output_path=None, limit=0.5, topp=1.1, topk=64, spr=0.25, sink=8, local=256, use_cache=None, cache_requests=None, check_integrity=False, write_out=False, log_samples=False, show_config=False, include_path=None, gen_kwargs=None, verbosity='INFO', wandb_args='', predict_only=False, seed=[0, 1234, 1234], trust_remote_code=False)
Namespace(model='xhf', tasks='gsm8k', model_args='pretrained=meta-llama/Meta-Llama-3-8B-Instruct,cats=True,spr=0.3,check=True,kernel_size=16,thr=0.3', num_fewshot=None, batch_size='1', max_batch_size=None, device=None, output_path=None, limit=0.5, topp=1.1, topk=64, spr=0.25, sink=8, local=256, use_cache=None, cache_requests=None, check_integrity=False, write_out=False, log_samples=False, show_config=False, include_path=None, gen_kwargs=None, verbosity='INFO', wandb_args='', predict_only=False, seed=[0, 1234, 1234], trust_remote_code=False)
Namespace(model='xhf', tasks='gsm8k', model_args='pretrained=meta-llama/Meta-Llama-3-8B-Instruct,cats=True,spr=0.3,check=True,kernel_size=16,thr=0.3', num_fewshot=None, batch_size='1', max_batch_size=None, device=None, output_path=None, limit=0.5, topp=1.1, topk=64, spr=0.25, sink=8, local=256, use_cache=None, cache_requests=None, check_integrity=False, write_out=False, log_samples=False, show_config=False, include_path=None, gen_kwargs=None, verbosity='INFO', wandb_args='', predict_only=False, seed=[0, 1234, 1234], trust_remote_code=False)
Namespace(model='xhf', tasks='gsm8k', model_args='pretrained=meta-llama/Meta-Llama-3-8B-Instruct,cats=True,spr=0.3,check=True,kernel_size=16,thr=0.3', num_fewshot=None, batch_size='1', max_batch_size=None, device=None, output_path=None, limit=0.5, topp=1.1, topk=64, spr=0.25, sink=8, local=256, use_cache=None, cache_requests=None, check_integrity=False, write_out=False, log_samples=False, show_config=False, include_path=None, gen_kwargs=None, verbosity='INFO', wandb_args='', predict_only=False, seed=[0, 1234, 1234], trust_remote_code=False)
8114 1294 6.27047913446677
6805 1105 6.158371040723982
7239 1197 6.0476190476190474
7070 1137 6.218117854001759
7984 1263 6.321456848772764
7990 1298 6.155624036979969
7570 1227 6.169519152404238
7803 1271 6.1392604248623135
xhf (pretrained=meta-llama/Meta-Llama-3-8B-Instruct,cats=True,spr=0.3,check=True,kernel_size=16,thr=0.3), gen_kwargs: (None), limit: 0.5, num_fewshot: None, batch_size: 1
|Tasks|Version|     Filter     |n-shot|  Metric   |Value |   |Stderr|
|-----|------:|----------------|-----:|-----------|-----:|---|-----:|
|gsm8k|      3|strict-match    |     5|exact_match|0.5970|Â±  |0.0191|
|     |       |flexible-extract|     5|exact_match|0.6606|Â±  |0.0184|

Namespace(model='xhf', tasks='gsm8k', model_args='pretrained=meta-llama/Meta-Llama-3-8B-Instruct,cats=True,spr=0.3,check=True,kernel_size=16,thr=0.4', num_fewshot=None, batch_size='1', max_batch_size=None, device=None, output_path=None, limit=0.5, topp=1.1, topk=64, spr=0.25, sink=8, local=256, use_cache=None, cache_requests=None, check_integrity=False, write_out=False, log_samples=False, show_config=False, include_path=None, gen_kwargs=None, verbosity='INFO', wandb_args='', predict_only=False, seed=[0, 1234, 1234], trust_remote_code=False)
Namespace(model='xhf', tasks='gsm8k', model_args='pretrained=meta-llama/Meta-Llama-3-8B-Instruct,cats=True,spr=0.3,check=True,kernel_size=16,thr=0.4', num_fewshot=None, batch_size='1', max_batch_size=None, device=None, output_path=None, limit=0.5, topp=1.1, topk=64, spr=0.25, sink=8, local=256, use_cache=None, cache_requests=None, check_integrity=False, write_out=False, log_samples=False, show_config=False, include_path=None, gen_kwargs=None, verbosity='INFO', wandb_args='', predict_only=False, seed=[0, 1234, 1234], trust_remote_code=False)
Namespace(model='xhf', tasks='gsm8k', model_args='pretrained=meta-llama/Meta-Llama-3-8B-Instruct,cats=True,spr=0.3,check=True,kernel_size=16,thr=0.4', num_fewshot=None, batch_size='1', max_batch_size=None, device=None, output_path=None, limit=0.5, topp=1.1, topk=64, spr=0.25, sink=8, local=256, use_cache=None, cache_requests=None, check_integrity=False, write_out=False, log_samples=False, show_config=False, include_path=None, gen_kwargs=None, verbosity='INFO', wandb_args='', predict_only=False, seed=[0, 1234, 1234], trust_remote_code=False)
Namespace(model='xhf', tasks='gsm8k', model_args='pretrained=meta-llama/Meta-Llama-3-8B-Instruct,cats=True,spr=0.3,check=True,kernel_size=16,thr=0.4', num_fewshot=None, batch_size='1', max_batch_size=None, device=None, output_path=None, limit=0.5, topp=1.1, topk=64, spr=0.25, sink=8, local=256, use_cache=None, cache_requests=None, check_integrity=False, write_out=False, log_samples=False, show_config=False, include_path=None, gen_kwargs=None, verbosity='INFO', wandb_args='', predict_only=False, seed=[0, 1234, 1234], trust_remote_code=False)
Namespace(model='xhf', tasks='gsm8k', model_args='pretrained=meta-llama/Meta-Llama-3-8B-Instruct,cats=True,spr=0.3,check=True,kernel_size=16,thr=0.4', num_fewshot=None, batch_size='1', max_batch_size=None, device=None, output_path=None, limit=0.5, topp=1.1, topk=64, spr=0.25, sink=8, local=256, use_cache=None, cache_requests=None, check_integrity=False, write_out=False, log_samples=False, show_config=False, include_path=None, gen_kwargs=None, verbosity='INFO', wandb_args='', predict_only=False, seed=[0, 1234, 1234], trust_remote_code=False)
Namespace(model='xhf', tasks='gsm8k', model_args='pretrained=meta-llama/Meta-Llama-3-8B-Instruct,cats=True,spr=0.3,check=True,kernel_size=16,thr=0.4', num_fewshot=None, batch_size='1', max_batch_size=None, device=None, output_path=None, limit=0.5, topp=1.1, topk=64, spr=0.25, sink=8, local=256, use_cache=None, cache_requests=None, check_integrity=False, write_out=False, log_samples=False, show_config=False, include_path=None, gen_kwargs=None, verbosity='INFO', wandb_args='', predict_only=False, seed=[0, 1234, 1234], trust_remote_code=False)
Namespace(model='xhf', tasks='gsm8k', model_args='pretrained=meta-llama/Meta-Llama-3-8B-Instruct,cats=True,spr=0.3,check=True,kernel_size=16,thr=0.4', num_fewshot=None, batch_size='1', max_batch_size=None, device=None, output_path=None, limit=0.5, topp=1.1, topk=64, spr=0.25, sink=8, local=256, use_cache=None, cache_requests=None, check_integrity=False, write_out=False, log_samples=False, show_config=False, include_path=None, gen_kwargs=None, verbosity='INFO', wandb_args='', predict_only=False, seed=[0, 1234, 1234], trust_remote_code=False)
Namespace(model='xhf', tasks='gsm8k', model_args='pretrained=meta-llama/Meta-Llama-3-8B-Instruct,cats=True,spr=0.3,check=True,kernel_size=16,thr=0.4', num_fewshot=None, batch_size='1', max_batch_size=None, device=None, output_path=None, limit=0.5, topp=1.1, topk=64, spr=0.25, sink=8, local=256, use_cache=None, cache_requests=None, check_integrity=False, write_out=False, log_samples=False, show_config=False, include_path=None, gen_kwargs=None, verbosity='INFO', wandb_args='', predict_only=False, seed=[0, 1234, 1234], trust_remote_code=False)
6806 1195 5.695397489539749
7931 1393 5.693467336683417
7264 1362 5.333333333333333
7148 1275 5.606274509803922
7258 1275 5.692549019607843
8005 1385 5.7797833935018055
8173 1437 5.687543493389005
8243 1410 5.846099290780142
xhf (pretrained=meta-llama/Meta-Llama-3-8B-Instruct,cats=True,spr=0.3,check=True,kernel_size=16,thr=0.4), gen_kwargs: (None), limit: 0.5, num_fewshot: None, batch_size: 1
|Tasks|Version|     Filter     |n-shot|  Metric   |Value |   |Stderr|
|-----|------:|----------------|-----:|-----------|-----:|---|-----:|
|gsm8k|      3|strict-match    |     5|exact_match|0.5697|Â±  |0.0193|
|     |       |flexible-extract|     5|exact_match|0.6545|Â±  |0.0185|

