fatal: Unable to create '/private/home/beidic/yang/GRIFFIN2/.git/index.lock': File exists.

Another git process seems to be running in this repository, e.g.
an editor opened by 'git commit'. Please make sure all processes
are terminated then try again. If it still fails, a git process
may have crashed in this repository earlier:
remove the file manually to continue.
WARNING: Ignoring invalid distribution ~umpy (/private/home/beidic/.conda/envs/griffin/lib/python3.12/site-packages)
WARNING: Ignoring invalid distribution ~umpy (/private/home/beidic/.conda/envs/griffin/lib/python3.12/site-packages)
WARNING: Ignoring invalid distribution ~umpy (/private/home/beidic/.conda/envs/griffin/lib/python3.12/site-packages)
WARNING: Ignoring invalid distribution ~umpy (/private/home/beidic/.conda/envs/griffin/lib/python3.12/site-packages)
WARNING: Ignoring invalid distribution ~umpy (/private/home/beidic/.conda/envs/griffin/lib/python3.12/site-packages)
WARNING: Ignoring invalid distribution ~umpy (/private/home/beidic/.conda/envs/griffin/lib/python3.12/site-packages)
wandb: Currently logged in as: stevenzhou0816100. Use `wandb login --relogin` to force relogin
Traceback (most recent call last):
  File "/private/home/beidic/.conda/envs/griffin/lib/python3.12/site-packages/transformers/__init__.py", line 1240, in <module>
    raise OptionalDependencyNotAvailable()
transformers.utils.import_utils.OptionalDependencyNotAvailable

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/private/home/beidic/.conda/envs/griffin/bin/transformers-cli", line 5, in <module>
  File "/private/home/beidic/.conda/envs/griffin/lib/python3.12/site-packages/transformers/__init__.py", line 1242, in <module>
    from .utils import dummy_tensorflow_text_objects
ImportError: cannot import name 'dummy_tensorflow_text_objects' from 'transformers.utils' (/private/home/beidic/.conda/envs/griffin/lib/python3.12/site-packages/transformers/utils/__init__.py)
Traceback (most recent call last):
  File "/private/home/beidic/.conda/envs/griffin/bin/huggingface-cli", line 8, in <module>
    sys.exit(main())
             ^^^^^^
  File "/private/home/beidic/.conda/envs/griffin/lib/python3.12/site-packages/huggingface_hub/commands/huggingface_cli.py", line 51, in main
    service.run()
  File "/private/home/beidic/.conda/envs/griffin/lib/python3.12/site-packages/huggingface_hub/commands/user.py", line 98, in run
    login(token=self.args.token, add_to_git_credential=self.args.add_to_git_credential)
  File "/private/home/beidic/.conda/envs/griffin/lib/python3.12/site-packages/huggingface_hub/_login.py", line 111, in login
    _login(token, add_to_git_credential=add_to_git_credential, write_permission=write_permission)
  File "/private/home/beidic/.conda/envs/griffin/lib/python3.12/site-packages/huggingface_hub/_login.py", line 307, in _login
    raise ValueError("Invalid token passed!")
ValueError: Invalid token passed!
The following values were not passed to `accelerate launch` and had defaults used instead:
		More than one GPU was found, enabling multi-GPU training.
		If this was unintended please pass in `--num_processes=1`.
	`--mixed_precision` was set to a value of `'no'`
	`--dynamo_backend` was set to a value of `'no'`
To avoid this warning pass in values for each of the problematic parameters or run `accelerate config`.
2024-06-03:14:40:41,732 INFO     [main.py:288] Verbosity set to INFO
2024-06-03:14:40:41,732 INFO     [main.py:288] Verbosity set to INFO
2024-06-03:14:40:41,733 INFO     [main.py:288] Verbosity set to INFO
2024-06-03:14:40:41,733 INFO     [main.py:288] Verbosity set to INFO
2024-06-03:14:40:41,733 INFO     [main.py:288] Verbosity set to INFO
2024-06-03:14:40:41,733 INFO     [main.py:288] Verbosity set to INFO
2024-06-03:14:40:41,733 INFO     [main.py:288] Verbosity set to INFO
2024-06-03:14:40:41,733 INFO     [main.py:288] Verbosity set to INFO
2024-06-03:14:40:47,709 INFO     [main.py:378] Selected Tasks: ['gsm8k']
2024-06-03:14:40:47,710 INFO     [main.py:378] Selected Tasks: ['gsm8k']
2024-06-03:14:40:47,710 INFO     [main.py:378] Selected Tasks: ['gsm8k']
2024-06-03:14:40:47,710 INFO     [main.py:378] Selected Tasks: ['gsm8k']
2024-06-03:14:40:47,711 INFO     [main.py:378] Selected Tasks: ['gsm8k']
2024-06-03:14:40:47,719 INFO     [xevaluator.py:137] Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234
2024-06-03:14:40:47,719 INFO     [xevaluator.py:184] Initializing xhf model, with arguments: {'pretrained': 'meta-llama/Llama-2-7b-hf', 'cats': True, 'check': True, 'kernel_size': 16, 'spr': 0.5, 'thr': 0.1}
2024-06-03:14:40:47,719 INFO     [xevaluator.py:137] Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234
2024-06-03:14:40:47,719 INFO     [xevaluator.py:137] Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234
2024-06-03:14:40:47,719 INFO     [xevaluator.py:137] Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234
2024-06-03:14:40:47,719 INFO     [xevaluator.py:137] Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234
2024-06-03:14:40:47,719 INFO     [xevaluator.py:184] Initializing xhf model, with arguments: {'pretrained': 'meta-llama/Llama-2-7b-hf', 'cats': True, 'check': True, 'kernel_size': 16, 'spr': 0.5, 'thr': 0.1}
2024-06-03:14:40:47,719 INFO     [xevaluator.py:184] Initializing xhf model, with arguments: {'pretrained': 'meta-llama/Llama-2-7b-hf', 'cats': True, 'check': True, 'kernel_size': 16, 'spr': 0.5, 'thr': 0.1}
2024-06-03:14:40:47,719 INFO     [xevaluator.py:184] Initializing xhf model, with arguments: {'pretrained': 'meta-llama/Llama-2-7b-hf', 'cats': True, 'check': True, 'kernel_size': 16, 'spr': 0.5, 'thr': 0.1}
2024-06-03:14:40:47,719 INFO     [xevaluator.py:184] Initializing xhf model, with arguments: {'pretrained': 'meta-llama/Llama-2-7b-hf', 'cats': True, 'check': True, 'kernel_size': 16, 'spr': 0.5, 'thr': 0.1}
2024-06-03:14:40:47,730 INFO     [main.py:378] Selected Tasks: ['gsm8k']
2024-06-03:14:40:47,734 INFO     [xevaluator.py:137] Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234
2024-06-03:14:40:47,734 INFO     [xevaluator.py:184] Initializing xhf model, with arguments: {'pretrained': 'meta-llama/Llama-2-7b-hf', 'cats': True, 'check': True, 'kernel_size': 16, 'spr': 0.5, 'thr': 0.1}
2024-06-03:14:40:47,790 INFO     [main.py:378] Selected Tasks: ['gsm8k']
2024-06-03:14:40:47,793 INFO     [xevaluator.py:137] Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234
2024-06-03:14:40:47,793 INFO     [xevaluator.py:184] Initializing xhf model, with arguments: {'pretrained': 'meta-llama/Llama-2-7b-hf', 'cats': True, 'check': True, 'kernel_size': 16, 'spr': 0.5, 'thr': 0.1}
2024-06-03:14:40:47,915 INFO     [main.py:378] Selected Tasks: ['gsm8k']
2024-06-03:14:40:47,918 INFO     [xevaluator.py:137] Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234
2024-06-03:14:40:47,918 INFO     [xevaluator.py:184] Initializing xhf model, with arguments: {'pretrained': 'meta-llama/Llama-2-7b-hf', 'cats': True, 'check': True, 'kernel_size': 16, 'spr': 0.5, 'thr': 0.1}
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:57<00:57, 57.12s/it]Loading checkpoint shards:  50%|█████     | 1/2 [00:59<00:59, 59.39s/it]Loading checkpoint shards:  50%|█████     | 1/2 [00:59<00:59, 59.54s/it]Loading checkpoint shards:  50%|█████     | 1/2 [00:59<00:59, 59.36s/it]Loading checkpoint shards:  50%|█████     | 1/2 [00:59<00:59, 59.58s/it]Loading checkpoint shards:  50%|█████     | 1/2 [00:59<00:59, 59.50s/it]Loading checkpoint shards:  50%|█████     | 1/2 [00:59<00:59, 59.62s/it]Loading checkpoint shards:  50%|█████     | 1/2 [00:59<00:59, 59.98s/it]Loading checkpoint shards: 100%|██████████| 2/2 [01:16<00:00, 34.71s/it]Loading checkpoint shards: 100%|██████████| 2/2 [01:16<00:00, 38.41s/it]
Loading checkpoint shards: 100%|██████████| 2/2 [01:17<00:00, 35.29s/it]Loading checkpoint shards: 100%|██████████| 2/2 [01:17<00:00, 38.93s/it]
Loading checkpoint shards: 100%|██████████| 2/2 [01:17<00:00, 35.26s/it]Loading checkpoint shards: 100%|██████████| 2/2 [01:17<00:00, 38.90s/it]
Loading checkpoint shards: 100%|██████████| 2/2 [01:17<00:00, 35.24s/it]Loading checkpoint shards: 100%|██████████| 2/2 [01:17<00:00, 38.87s/it]
Loading checkpoint shards: 100%|██████████| 2/2 [01:18<00:00, 35.46s/it]Loading checkpoint shards: 100%|██████████| 2/2 [01:18<00:00, 39.14s/it]
Loading checkpoint shards: 100%|██████████| 2/2 [01:17<00:00, 35.62s/it]Loading checkpoint shards: 100%|██████████| 2/2 [01:17<00:00, 38.84s/it]
Loading checkpoint shards: 100%|██████████| 2/2 [01:17<00:00, 35.33s/it]Loading checkpoint shards: 100%|██████████| 2/2 [01:17<00:00, 38.97s/it]
Loading checkpoint shards: 100%|██████████| 2/2 [01:17<00:00, 35.32s/it]Loading checkpoint shards: 100%|██████████| 2/2 [01:17<00:00, 38.96s/it]
Using the latest cached version of the dataset since gsm8k couldn't be found on the Hugging Face Hub
2024-06-03:14:42:35,615 WARNING  [load.py:1631] Using the latest cached version of the dataset since gsm8k couldn't be found on the Hugging Face Hub
Found the latest cached dataset configuration 'main' at /private/home/beidic/.cache/huggingface/datasets/gsm8k/main/0.0.0/e53f048856ff4f594e959d75785d2c2d37b678ee (last modified on Thu May 16 07:01:08 2024).
2024-06-03:14:42:35,618 WARNING  [cache.py:95] Found the latest cached dataset configuration 'main' at /private/home/beidic/.cache/huggingface/datasets/gsm8k/main/0.0.0/e53f048856ff4f594e959d75785d2c2d37b678ee (last modified on Thu May 16 07:01:08 2024).
2024-06-03:14:42:35,940 INFO     [task.py:395] Building contexts for gsm8k on rank 3...
  0%|          | 0/165 [00:00<?, ?it/s] 10%|▉         | 16/165 [00:00<00:00, 153.24it/s] 19%|█▉        | 32/165 [00:00<00:00, 153.89it/s] 29%|██▉       | 48/165 [00:00<00:00, 153.68it/s] 39%|███▉      | 64/165 [00:00<00:00, 153.71it/s]Using the latest cached version of the dataset since gsm8k couldn't be found on the Hugging Face Hub
 48%|████▊     | 80/165 [00:00<00:00, 153.90it/s]2024-06-03:14:42:36,494 WARNING  [load.py:1631] Using the latest cached version of the dataset since gsm8k couldn't be found on the Hugging Face Hub
Found the latest cached dataset configuration 'main' at /private/home/beidic/.cache/huggingface/datasets/gsm8k/main/0.0.0/e53f048856ff4f594e959d75785d2c2d37b678ee (last modified on Thu May 16 07:01:08 2024).
2024-06-03:14:42:36,496 WARNING  [cache.py:95] Found the latest cached dataset configuration 'main' at /private/home/beidic/.cache/huggingface/datasets/gsm8k/main/0.0.0/e53f048856ff4f594e959d75785d2c2d37b678ee (last modified on Thu May 16 07:01:08 2024).
 58%|█████▊    | 96/165 [00:00<00:00, 151.59it/s]2024-06-03:14:42:36,689 INFO     [task.py:395] Building contexts for gsm8k on rank 7...
 68%|██████▊   | 112/165 [00:00<00:00, 152.27it/s]  0%|          | 0/164 [00:00<?, ?it/s] 78%|███████▊  | 128/165 [00:00<00:00, 153.01it/s] 13%|█▎        | 21/164 [00:00<00:00, 207.69it/s] 87%|████████▋ | 144/165 [00:00<00:00, 153.23it/s] 26%|██▌       | 42/164 [00:00<00:00, 208.83it/s] 97%|█████████▋| 160/165 [00:01<00:00, 153.07it/s] 38%|███▊      | 63/164 [00:00<00:00, 208.75it/s]100%|██████████| 165/165 [00:01<00:00, 153.09it/s]
 51%|█████     | 84/164 [00:00<00:00, 209.01it/s] 64%|██████▍   | 105/164 [00:00<00:00, 209.05it/s] 77%|███████▋  | 126/164 [00:00<00:00, 208.96it/s] 90%|████████▉ | 147/164 [00:00<00:00, 208.68it/s]100%|██████████| 164/164 [00:00<00:00, 208.80it/s]
Using the latest cached version of the dataset since gsm8k couldn't be found on the Hugging Face Hub
2024-06-03:14:42:46,716 WARNING  [load.py:1631] Using the latest cached version of the dataset since gsm8k couldn't be found on the Hugging Face Hub
Found the latest cached dataset configuration 'main' at /private/home/beidic/.cache/huggingface/datasets/gsm8k/main/0.0.0/e53f048856ff4f594e959d75785d2c2d37b678ee (last modified on Thu May 16 07:01:08 2024).
2024-06-03:14:42:46,719 WARNING  [cache.py:95] Found the latest cached dataset configuration 'main' at /private/home/beidic/.cache/huggingface/datasets/gsm8k/main/0.0.0/e53f048856ff4f594e959d75785d2c2d37b678ee (last modified on Thu May 16 07:01:08 2024).
Using the latest cached version of the dataset since gsm8k couldn't be found on the Hugging Face Hub
2024-06-03:14:42:46,753 WARNING  [load.py:1631] Using the latest cached version of the dataset since gsm8k couldn't be found on the Hugging Face Hub
Found the latest cached dataset configuration 'main' at /private/home/beidic/.cache/huggingface/datasets/gsm8k/main/0.0.0/e53f048856ff4f594e959d75785d2c2d37b678ee (last modified on Thu May 16 07:01:08 2024).
2024-06-03:14:42:46,755 WARNING  [cache.py:95] Found the latest cached dataset configuration 'main' at /private/home/beidic/.cache/huggingface/datasets/gsm8k/main/0.0.0/e53f048856ff4f594e959d75785d2c2d37b678ee (last modified on Thu May 16 07:01:08 2024).
2024-06-03:14:42:46,887 INFO     [task.py:395] Building contexts for gsm8k on rank 2...
2024-06-03:14:42:46,905 INFO     [task.py:395] Building contexts for gsm8k on rank 6...
  0%|          | 0/165 [00:00<?, ?it/s]  0%|          | 0/165 [00:00<?, ?it/s] 13%|█▎        | 22/165 [00:00<00:00, 215.85it/s] 13%|█▎        | 22/165 [00:00<00:00, 215.65it/s] 27%|██▋       | 44/165 [00:00<00:00, 216.38it/s] 27%|██▋       | 44/165 [00:00<00:00, 215.99it/s] 40%|████      | 66/165 [00:00<00:00, 216.52it/s] 40%|████      | 66/165 [00:00<00:00, 215.76it/s] 53%|█████▎    | 88/165 [00:00<00:00, 215.68it/s] 53%|█████▎    | 88/165 [00:00<00:00, 215.07it/s] 67%|██████▋   | 110/165 [00:00<00:00, 215.36it/s] 67%|██████▋   | 110/165 [00:00<00:00, 214.62it/s] 80%|████████  | 132/165 [00:00<00:00, 215.70it/s] 80%|████████  | 132/165 [00:00<00:00, 214.98it/s] 93%|█████████▎| 154/165 [00:00<00:00, 216.55it/s] 93%|█████████▎| 154/165 [00:00<00:00, 215.96it/s]100%|██████████| 165/165 [00:00<00:00, 216.28it/s]
100%|██████████| 165/165 [00:00<00:00, 215.78it/s]
2024-06-03:14:42:48,334 INFO     [xhuggingface.py:314] Using 8 devices with data parallelism
Using the latest cached version of the dataset since gsm8k couldn't be found on the Hugging Face Hub
2024-06-03:14:42:48,572 WARNING  [load.py:1631] Using the latest cached version of the dataset since gsm8k couldn't be found on the Hugging Face Hub
Found the latest cached dataset configuration 'main' at /private/home/beidic/.cache/huggingface/datasets/gsm8k/main/0.0.0/e53f048856ff4f594e959d75785d2c2d37b678ee (last modified on Thu May 16 07:01:08 2024).
2024-06-03:14:42:48,574 WARNING  [cache.py:95] Found the latest cached dataset configuration 'main' at /private/home/beidic/.cache/huggingface/datasets/gsm8k/main/0.0.0/e53f048856ff4f594e959d75785d2c2d37b678ee (last modified on Thu May 16 07:01:08 2024).
Using the latest cached version of the dataset since gsm8k couldn't be found on the Hugging Face Hub
2024-06-03:14:42:48,691 WARNING  [load.py:1631] Using the latest cached version of the dataset since gsm8k couldn't be found on the Hugging Face Hub
Found the latest cached dataset configuration 'main' at /private/home/beidic/.cache/huggingface/datasets/gsm8k/main/0.0.0/e53f048856ff4f594e959d75785d2c2d37b678ee (last modified on Thu May 16 07:01:08 2024).
2024-06-03:14:42:48,693 WARNING  [cache.py:95] Found the latest cached dataset configuration 'main' at /private/home/beidic/.cache/huggingface/datasets/gsm8k/main/0.0.0/e53f048856ff4f594e959d75785d2c2d37b678ee (last modified on Thu May 16 07:01:08 2024).
2024-06-03:14:42:48,829 INFO     [task.py:395] Building contexts for gsm8k on rank 0...
  0%|          | 0/165 [00:00<?, ?it/s]  8%|▊         | 14/165 [00:00<00:01, 136.65it/s]2024-06-03:14:42:49,051 INFO     [task.py:395] Building contexts for gsm8k on rank 1...
 17%|█▋        | 28/165 [00:00<00:00, 137.12it/s]  0%|          | 0/165 [00:00<?, ?it/s] 25%|██▌       | 42/165 [00:00<00:00, 135.07it/s]  8%|▊         | 14/165 [00:00<00:01, 134.47it/s] 34%|███▍      | 56/165 [00:00<00:00, 134.98it/s] 17%|█▋        | 28/165 [00:00<00:01, 135.03it/s] 42%|████▏     | 70/165 [00:00<00:00, 134.20it/s] 25%|██▌       | 42/165 [00:00<00:00, 134.15it/s] 51%|█████     | 84/165 [00:00<00:00, 133.77it/s] 34%|███▍      | 56/165 [00:00<00:00, 133.58it/s] 59%|█████▉    | 98/165 [00:00<00:00, 133.65it/s] 42%|████▏     | 70/165 [00:00<00:00, 133.59it/s] 68%|██████▊   | 112/165 [00:00<00:00, 133.26it/s] 51%|█████     | 84/165 [00:00<00:00, 133.42it/s] 76%|███████▋  | 126/165 [00:00<00:00, 133.67it/s] 59%|█████▉    | 98/165 [00:00<00:00, 134.35it/s] 85%|████████▍ | 140/165 [00:01<00:00, 133.95it/s] 68%|██████▊   | 112/165 [00:00<00:00, 134.75it/s] 93%|█████████▎| 154/165 [00:01<00:00, 133.88it/s] 76%|███████▋  | 126/165 [00:00<00:00, 134.61it/s]100%|██████████| 165/165 [00:01<00:00, 134.16it/s]
 85%|████████▌ | 141/165 [00:01<00:00, 138.08it/s] 96%|█████████▋| 159/165 [00:01<00:00, 150.07it/s]100%|██████████| 165/165 [00:01<00:00, 140.39it/s]
Using the latest cached version of the dataset since gsm8k couldn't be found on the Hugging Face Hub
2024-06-03:14:42:53,250 WARNING  [load.py:1631] Using the latest cached version of the dataset since gsm8k couldn't be found on the Hugging Face Hub
Found the latest cached dataset configuration 'main' at /private/home/beidic/.cache/huggingface/datasets/gsm8k/main/0.0.0/e53f048856ff4f594e959d75785d2c2d37b678ee (last modified on Thu May 16 07:01:08 2024).
2024-06-03:14:42:53,252 WARNING  [cache.py:95] Found the latest cached dataset configuration 'main' at /private/home/beidic/.cache/huggingface/datasets/gsm8k/main/0.0.0/e53f048856ff4f594e959d75785d2c2d37b678ee (last modified on Thu May 16 07:01:08 2024).
2024-06-03:14:42:53,439 INFO     [task.py:395] Building contexts for gsm8k on rank 4...
  0%|          | 0/165 [00:00<?, ?it/s] 12%|█▏        | 19/165 [00:00<00:00, 186.13it/s] 23%|██▎       | 38/165 [00:00<00:00, 186.68it/s] 35%|███▍      | 57/165 [00:00<00:00, 168.06it/s] 45%|████▌     | 75/165 [00:00<00:00, 168.33it/s] 57%|█████▋    | 94/165 [00:00<00:00, 175.01it/s]Using the latest cached version of the dataset since gsm8k couldn't be found on the Hugging Face Hub
2024-06-03:14:42:54,083 WARNING  [load.py:1631] Using the latest cached version of the dataset since gsm8k couldn't be found on the Hugging Face Hub
Found the latest cached dataset configuration 'main' at /private/home/beidic/.cache/huggingface/datasets/gsm8k/main/0.0.0/e53f048856ff4f594e959d75785d2c2d37b678ee (last modified on Thu May 16 07:01:08 2024).
2024-06-03:14:42:54,085 WARNING  [cache.py:95] Found the latest cached dataset configuration 'main' at /private/home/beidic/.cache/huggingface/datasets/gsm8k/main/0.0.0/e53f048856ff4f594e959d75785d2c2d37b678ee (last modified on Thu May 16 07:01:08 2024).
 68%|██████▊   | 113/165 [00:00<00:00, 177.60it/s] 79%|███████▉  | 131/165 [00:00<00:00, 164.79it/s] 90%|████████▉ | 148/165 [00:00<00:00, 154.33it/s]2024-06-03:14:42:54,374 INFO     [task.py:395] Building contexts for gsm8k on rank 5...
  0%|          | 0/165 [00:00<?, ?it/s] 99%|█████████▉| 164/165 [00:01<00:00, 149.10it/s]100%|██████████| 165/165 [00:01<00:00, 162.00it/s]
 10%|▉         | 16/165 [00:00<00:00, 153.75it/s] 21%|██        | 35/165 [00:00<00:00, 171.36it/s] 33%|███▎      | 54/165 [00:00<00:00, 176.99it/s] 44%|████▍     | 73/165 [00:00<00:00, 179.39it/s] 56%|█████▌    | 92/165 [00:00<00:00, 180.87it/s] 67%|██████▋   | 111/165 [00:00<00:00, 182.23it/s] 79%|███████▉  | 130/165 [00:00<00:00, 182.61it/s] 90%|█████████ | 149/165 [00:00<00:00, 182.99it/s]100%|██████████| 165/165 [00:00<00:00, 180.13it/s]
2024-06-03:14:42:59,355 INFO     [xevaluator.py:395] Running generate_until requests
2024-06-03:14:42:59,355 INFO     [xevaluator.py:395] Running generate_until requests
2024-06-03:14:42:59,355 INFO     [xevaluator.py:395] Running generate_until requests
2024-06-03:14:42:59,355 INFO     [xevaluator.py:395] Running generate_until requests
2024-06-03:14:42:59,355 INFO     [xevaluator.py:395] Running generate_until requests
2024-06-03:14:42:59,355 INFO     [xevaluator.py:395] Running generate_until requests
2024-06-03:14:42:59,355 INFO     [xevaluator.py:395] Running generate_until requests
Running generate_until requests:   0%|          | 0/165 [00:00<?, ?it/s]2024-06-03:14:42:59,356 INFO     [xevaluator.py:395] Running generate_until requests
Running generate_until requests:   1%|          | 1/165 [00:19<52:08, 19.08s/it]Running generate_until requests:   1%|          | 2/165 [00:28<36:16, 13.35s/it]Running generate_until requests:   2%|▏         | 3/165 [00:43<37:41, 13.96s/it]Running generate_until requests:   2%|▏         | 4/165 [01:00<41:02, 15.29s/it]Running generate_until requests:   3%|▎         | 5/165 [01:12<37:43, 14.15s/it]Running generate_until requests:   4%|▎         | 6/165 [01:24<35:30, 13.40s/it]Running generate_until requests:   4%|▍         | 7/165 [01:27<26:03,  9.90s/it]Running generate_until requests:   5%|▍         | 8/165 [01:34<23:30,  8.98s/it]Running generate_until requests:   5%|▌         | 9/165 [01:39<20:09,  7.75s/it]Running generate_until requests:   6%|▌         | 10/165 [01:44<17:37,  6.83s/it]Running generate_until requests:   7%|▋         | 11/165 [01:51<17:53,  6.97s/it]Running generate_until requests:   7%|▋         | 12/165 [01:54<14:43,  5.78s/it]Running generate_until requests:   8%|▊         | 13/165 [01:58<13:36,  5.37s/it]Running generate_until requests:   8%|▊         | 14/165 [02:06<15:04,  5.99s/it]Running generate_until requests:   9%|▉         | 15/165 [02:10<13:21,  5.34s/it]Running generate_until requests:  10%|▉         | 16/165 [02:14<12:42,  5.12s/it]Running generate_until requests:  10%|█         | 17/165 [02:21<13:52,  5.62s/it]Running generate_until requests:  11%|█         | 18/165 [02:25<12:39,  5.17s/it]Running generate_until requests:  12%|█▏        | 19/165 [02:33<14:22,  5.91s/it]Running generate_until requests:  12%|█▏        | 20/165 [02:38<14:07,  5.84s/it]Running generate_until requests:  13%|█▎        | 21/165 [02:43<13:08,  5.48s/it]Running generate_until requests:  13%|█▎        | 22/165 [02:48<12:22,  5.20s/it]Running generate_until requests:  14%|█▍        | 23/165 [03:00<17:38,  7.45s/it]Running generate_until requests:  15%|█▍        | 24/165 [03:13<21:25,  9.12s/it]Running generate_until requests:  15%|█▌        | 25/165 [03:26<23:54, 10.25s/it]Running generate_until requests:  16%|█▌        | 26/165 [03:33<21:06,  9.11s/it]Running generate_until requests:  16%|█▋        | 27/165 [03:37<17:56,  7.80s/it]Running generate_until requests:  17%|█▋        | 28/165 [03:50<21:08,  9.26s/it]Running generate_until requests:  18%|█▊        | 29/165 [03:56<18:30,  8.17s/it]Running generate_until requests:  18%|█▊        | 30/165 [03:58<14:33,  6.47s/it]Running generate_until requests:  19%|█▉        | 31/165 [04:04<13:57,  6.25s/it]Running generate_until requests:  19%|█▉        | 32/165 [04:09<13:21,  6.03s/it]Running generate_until requests:  20%|██        | 33/165 [04:12<10:44,  4.88s/it]Running generate_until requests:  21%|██        | 34/165 [04:16<10:14,  4.69s/it]Running generate_until requests:  21%|██        | 35/165 [04:21<10:46,  4.97s/it]Running generate_until requests:  22%|██▏       | 36/165 [04:30<12:42,  5.91s/it]Running generate_until requests:  22%|██▏       | 37/165 [04:32<10:19,  4.84s/it]Running generate_until requests:  23%|██▎       | 38/165 [04:39<11:25,  5.40s/it]Running generate_until requests:  24%|██▎       | 39/165 [04:47<13:15,  6.31s/it]Running generate_until requests:  24%|██▍       | 40/165 [04:51<11:50,  5.69s/it]Running generate_until requests:  25%|██▍       | 41/165 [04:57<11:46,  5.70s/it]Running generate_until requests:  25%|██▌       | 42/165 [05:06<13:25,  6.55s/it]Running generate_until requests:  26%|██▌       | 43/165 [05:10<12:19,  6.06s/it]Running generate_until requests:  27%|██▋       | 44/165 [05:19<13:40,  6.78s/it]Running generate_until requests:  27%|██▋       | 45/165 [05:25<13:02,  6.52s/it]Running generate_until requests:  28%|██▊       | 46/165 [05:30<12:01,  6.06s/it]Running generate_until requests:  28%|██▊       | 47/165 [05:34<10:55,  5.56s/it]Running generate_until requests:  29%|██▉       | 48/165 [05:37<09:14,  4.74s/it]Running generate_until requests:  30%|██▉       | 49/165 [05:42<09:17,  4.80s/it]Running generate_until requests:  30%|███       | 50/165 [05:47<09:28,  4.94s/it]Running generate_until requests:  31%|███       | 51/165 [05:55<10:52,  5.73s/it]Running generate_until requests:  32%|███▏      | 52/165 [06:08<14:52,  7.90s/it]Running generate_until requests:  32%|███▏      | 53/165 [06:19<16:40,  8.94s/it]Running generate_until requests:  33%|███▎      | 54/165 [06:31<18:19,  9.91s/it]Running generate_until requests:  33%|███▎      | 55/165 [06:44<19:40, 10.73s/it]Running generate_until requests:  34%|███▍      | 56/165 [06:49<16:25,  9.04s/it]Running generate_until requests:  35%|███▍      | 57/165 [06:54<13:55,  7.73s/it]Running generate_until requests:  35%|███▌      | 58/165 [07:01<13:43,  7.70s/it]Running generate_until requests:  36%|███▌      | 59/165 [07:06<12:12,  6.91s/it]Running generate_until requests:  36%|███▋      | 60/165 [07:11<11:03,  6.32s/it]Running generate_until requests:  37%|███▋      | 61/165 [07:16<10:11,  5.88s/it]Running generate_until requests:  38%|███▊      | 62/165 [07:20<08:53,  5.18s/it]Running generate_until requests:  38%|███▊      | 63/165 [07:22<07:12,  4.24s/it]Running generate_until requests:  39%|███▉      | 64/165 [07:27<07:29,  4.45s/it]Running generate_until requests:  39%|███▉      | 65/165 [07:29<06:32,  3.93s/it]Running generate_until requests:  40%|████      | 66/165 [07:42<10:48,  6.55s/it]Running generate_until requests:  41%|████      | 67/165 [07:44<08:37,  5.28s/it]Running generate_until requests:  41%|████      | 68/165 [07:57<12:06,  7.49s/it]Running generate_until requests:  42%|████▏     | 69/165 [08:05<12:20,  7.72s/it]Running generate_until requests:  42%|████▏     | 70/165 [08:18<14:33,  9.19s/it]Running generate_until requests:  43%|████▎     | 71/165 [08:30<15:49, 10.10s/it]Running generate_until requests:  44%|████▎     | 72/165 [08:36<13:24,  8.65s/it]Running generate_until requests:  44%|████▍     | 73/165 [08:42<12:14,  7.98s/it]Running generate_until requests:  45%|████▍     | 74/165 [08:47<10:36,  6.99s/it]Running generate_until requests:  45%|████▌     | 75/165 [08:59<13:02,  8.70s/it]Running generate_until requests:  46%|████▌     | 76/165 [09:05<11:27,  7.73s/it]Running generate_until requests:  47%|████▋     | 77/165 [09:17<13:30,  9.21s/it]Running generate_until requests:  47%|████▋     | 78/165 [09:25<12:32,  8.64s/it]Running generate_until requests:  48%|████▊     | 79/165 [09:38<14:15,  9.95s/it]Running generate_until requests:  48%|████▊     | 80/165 [09:46<13:29,  9.52s/it]Running generate_until requests:  49%|████▉     | 81/165 [09:59<14:41, 10.50s/it]Running generate_until requests:  50%|████▉     | 82/165 [10:03<11:43,  8.48s/it]Running generate_until requests:  50%|█████     | 83/165 [10:15<13:08,  9.62s/it]Running generate_until requests:  51%|█████     | 84/165 [10:20<11:07,  8.24s/it]Running generate_until requests:  52%|█████▏    | 85/165 [10:29<11:11,  8.40s/it]Running generate_until requests:  52%|█████▏    | 86/165 [10:36<10:37,  8.07s/it]Running generate_until requests:  53%|█████▎    | 87/165 [10:41<09:05,  6.99s/it]Running generate_until requests:  53%|█████▎    | 88/165 [10:45<07:46,  6.05s/it]Running generate_until requests:  54%|█████▍    | 89/165 [10:50<07:37,  6.02s/it]Running generate_until requests:  55%|█████▍    | 90/165 [10:53<06:22,  5.09s/it]Running generate_until requests:  55%|█████▌    | 91/165 [10:58<06:12,  5.03s/it]Running generate_until requests:  56%|█████▌    | 92/165 [11:03<06:06,  5.01s/it]Running generate_until requests:  56%|█████▋    | 93/165 [11:10<06:29,  5.41s/it]Running generate_until requests:  57%|█████▋    | 94/165 [11:19<07:41,  6.50s/it]Running generate_until requests:  58%|█████▊    | 95/165 [11:25<07:40,  6.57s/it]Running generate_until requests:  58%|█████▊    | 96/165 [11:30<06:56,  6.04s/it]Running generate_until requests:  59%|█████▉    | 97/165 [11:33<05:43,  5.05s/it]Running generate_until requests:  59%|█████▉    | 98/165 [11:37<05:16,  4.72s/it]Running generate_until requests:  60%|██████    | 99/165 [11:45<06:18,  5.73s/it]Running generate_until requests:  61%|██████    | 100/165 [11:49<05:43,  5.29s/it]Running generate_until requests:  61%|██████    | 101/165 [11:55<05:50,  5.47s/it]Running generate_until requests:  62%|██████▏   | 102/165 [12:00<05:28,  5.22s/it]Running generate_until requests:  62%|██████▏   | 103/165 [12:04<04:56,  4.79s/it]Running generate_until requests:  63%|██████▎   | 104/165 [12:07<04:27,  4.39s/it]Running generate_until requests:  64%|██████▎   | 105/165 [12:16<05:42,  5.70s/it]Running generate_until requests:  64%|██████▍   | 106/165 [12:20<05:03,  5.15s/it]Running generate_until requests:  65%|██████▍   | 107/165 [12:32<07:08,  7.40s/it]Running generate_until requests:  65%|██████▌   | 108/165 [12:36<06:01,  6.34s/it]Running generate_until requests:  66%|██████▌   | 109/165 [12:41<05:23,  5.77s/it]Running generate_until requests:  67%|██████▋   | 110/165 [12:47<05:21,  5.84s/it]Running generate_until requests:  67%|██████▋   | 111/165 [12:54<05:33,  6.18s/it]Running generate_until requests:  68%|██████▊   | 112/165 [12:57<04:50,  5.48s/it]Running generate_until requests:  68%|██████▊   | 113/165 [13:02<04:37,  5.34s/it]Running generate_until requests:  69%|██████▉   | 114/165 [13:09<04:45,  5.59s/it]Running generate_until requests:  70%|██████▉   | 115/165 [13:13<04:24,  5.29s/it]Running generate_until requests:  70%|███████   | 116/165 [13:16<03:49,  4.68s/it]Running generate_until requests:  71%|███████   | 117/165 [13:19<03:10,  3.98s/it]Running generate_until requests:  72%|███████▏  | 118/165 [13:23<03:05,  3.95s/it]Running generate_until requests:  72%|███████▏  | 119/165 [13:28<03:17,  4.30s/it]Running generate_until requests:  73%|███████▎  | 120/165 [13:31<03:04,  4.10s/it]Running generate_until requests:  73%|███████▎  | 121/165 [13:35<02:53,  3.94s/it]Running generate_until requests:  74%|███████▍  | 122/165 [13:40<03:03,  4.26s/it]Running generate_until requests:  75%|███████▍  | 123/165 [13:47<03:34,  5.10s/it]Running generate_until requests:  75%|███████▌  | 124/165 [13:53<03:39,  5.35s/it]Running generate_until requests:  76%|███████▌  | 125/165 [13:57<03:20,  5.02s/it]Running generate_until requests:  76%|███████▋  | 126/165 [14:05<03:44,  5.77s/it]Running generate_until requests:  77%|███████▋  | 127/165 [14:11<03:42,  5.86s/it]Running generate_until requests:  78%|███████▊  | 128/165 [14:15<03:13,  5.23s/it]Running generate_until requests:  78%|███████▊  | 129/165 [14:20<03:13,  5.36s/it]Running generate_until requests:  79%|███████▉  | 130/165 [14:28<03:30,  6.01s/it]Running generate_until requests:  79%|███████▉  | 131/165 [14:35<03:41,  6.52s/it]Running generate_until requests:  80%|████████  | 132/165 [14:40<03:15,  5.93s/it]Running generate_until requests:  81%|████████  | 133/165 [14:45<03:04,  5.75s/it]Running generate_until requests:  81%|████████  | 134/165 [14:58<04:06,  7.94s/it]Running generate_until requests:  82%|████████▏ | 135/165 [15:01<03:06,  6.23s/it]Running generate_until requests:  82%|████████▏ | 136/165 [15:05<02:44,  5.67s/it]Running generate_until requests:  83%|████████▎ | 137/165 [15:10<02:35,  5.56s/it]Running generate_until requests:  84%|████████▎ | 138/165 [15:16<02:34,  5.74s/it]Running generate_until requests:  84%|████████▍ | 139/165 [15:20<02:09,  4.98s/it]Running generate_until requests:  85%|████████▍ | 140/165 [15:23<01:52,  4.52s/it]Running generate_until requests:  85%|████████▌ | 141/165 [15:31<02:11,  5.48s/it]Running generate_until requests:  86%|████████▌ | 142/165 [15:34<01:48,  4.72s/it]Running generate_until requests:  87%|████████▋ | 143/165 [15:39<01:46,  4.83s/it]Running generate_until requests:  87%|████████▋ | 144/165 [15:44<01:44,  5.00s/it]Running generate_until requests:  88%|████████▊ | 145/165 [15:52<01:53,  5.70s/it]Running generate_until requests:  88%|████████▊ | 146/165 [15:57<01:45,  5.57s/it]Running generate_until requests:  89%|████████▉ | 147/165 [16:05<01:55,  6.44s/it]Running generate_until requests:  90%|████████▉ | 148/165 [16:11<01:46,  6.29s/it]Running generate_until requests:  90%|█████████ | 149/165 [16:14<01:22,  5.18s/it]Running generate_until requests:  91%|█████████ | 150/165 [16:18<01:11,  4.76s/it]Running generate_until requests:  92%|█████████▏| 151/165 [16:22<01:05,  4.68s/it]Running generate_until requests:  92%|█████████▏| 152/165 [16:26<00:56,  4.34s/it]Running generate_until requests:  93%|█████████▎| 153/165 [16:38<01:19,  6.67s/it]Running generate_until requests:  93%|█████████▎| 154/165 [16:43<01:07,  6.14s/it]Running generate_until requests:  94%|█████████▍| 155/165 [16:45<00:50,  5.02s/it]Running generate_until requests:  95%|█████████▍| 156/165 [16:49<00:43,  4.81s/it]Running generate_until requests:  95%|█████████▌| 157/165 [16:54<00:38,  4.77s/it]Running generate_until requests:  96%|█████████▌| 158/165 [17:07<00:49,  7.14s/it]Running generate_until requests:  96%|█████████▋| 159/165 [17:17<00:48,  8.02s/it]Running generate_until requests:  97%|█████████▋| 160/165 [17:23<00:37,  7.51s/it]Running generate_until requests:  98%|█████████▊| 161/165 [17:27<00:25,  6.28s/it]Running generate_until requests:  98%|█████████▊| 162/165 [17:39<00:24,  8.17s/it]Running generate_until requests:  99%|█████████▉| 163/165 [17:46<00:15,  7.64s/it]Running generate_until requests:  99%|█████████▉| 164/165 [17:47<00:05,  5.88s/it]Running generate_until requests: 100%|██████████| 165/165 [17:53<00:00,  5.90s/it]Running generate_until requests: 100%|██████████| 165/165 [17:53<00:00,  6.51s/it]
[2024-06-03 15:05:47,238] torch.distributed.elastic.multiprocessing.api: [WARNING] Sending process 3734364 closing signal SIGTERM
[2024-06-03 15:05:47,254] torch.distributed.elastic.multiprocessing.api: [WARNING] Sending process 3734365 closing signal SIGTERM
[2024-06-03 15:05:47,254] torch.distributed.elastic.multiprocessing.api: [WARNING] Sending process 3734366 closing signal SIGTERM
[2024-06-03 15:05:47,254] torch.distributed.elastic.multiprocessing.api: [WARNING] Sending process 3734367 closing signal SIGTERM
[2024-06-03 15:05:47,254] torch.distributed.elastic.multiprocessing.api: [WARNING] Sending process 3734368 closing signal SIGTERM
[2024-06-03 15:05:48,070] torch.distributed.elastic.multiprocessing.api: [ERROR] failed (exitcode: -7) local_rank: 5 (pid: 3734369) of binary: /private/home/beidic/.conda/envs/griffin/bin/python
Traceback (most recent call last):
  File "/private/home/beidic/.conda/envs/griffin/bin/accelerate", line 8, in <module>
    sys.exit(main())
             ^^^^^^
  File "/private/home/beidic/.conda/envs/griffin/lib/python3.12/site-packages/accelerate/commands/accelerate_cli.py", line 47, in main
    args.func(args)
  File "/private/home/beidic/.conda/envs/griffin/lib/python3.12/site-packages/accelerate/commands/launch.py", line 985, in launch_command
    multi_gpu_launcher(args)
  File "/private/home/beidic/.conda/envs/griffin/lib/python3.12/site-packages/accelerate/commands/launch.py", line 654, in multi_gpu_launcher
    distrib_run.run(args)
  File "/private/home/beidic/.conda/envs/griffin/lib/python3.12/site-packages/torch/distributed/run.py", line 803, in run
    elastic_launch(
  File "/private/home/beidic/.conda/envs/griffin/lib/python3.12/site-packages/torch/distributed/launcher/api.py", line 135, in __call__
    return launch_agent(self._config, self._entrypoint, list(args))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/private/home/beidic/.conda/envs/griffin/lib/python3.12/site-packages/torch/distributed/launcher/api.py", line 268, in launch_agent
    raise ChildFailedError(
torch.distributed.elastic.multiprocessing.errors.ChildFailedError: 
=======================================================
main.py FAILED
-------------------------------------------------------
Failures:
[1]:
  time      : 2024-06-03_15:05:47
  host      : learnfair7705.h2.fair
  rank      : 6 (local_rank: 6)
  exitcode  : -7 (pid: 3734370)
  error_file: <N/A>
  traceback : Signal 7 (SIGBUS) received by PID 3734370
[2]:
  time      : 2024-06-03_15:05:47
  host      : learnfair7705.h2.fair
  rank      : 7 (local_rank: 7)
  exitcode  : -7 (pid: 3734371)
  error_file: <N/A>
  traceback : Signal 7 (SIGBUS) received by PID 3734371
-------------------------------------------------------
Root Cause (first observed failure):
[0]:
  time      : 2024-06-03_15:05:47
  host      : learnfair7705.h2.fair
  rank      : 5 (local_rank: 5)
  exitcode  : -7 (pid: 3734369)
  error_file: <N/A>
  traceback : Signal 7 (SIGBUS) received by PID 3734369
=======================================================
/var/spool/slurm//job28548887/slurm_script: line 63: 3734323 Bus error               (core dumped) accelerate launch --main_process_port 29510 --num_processes 8 --num_machines 1 main.py --model xhf --model_args pretrained=meta-llama/Llama-2-7b-hf,cats=True,check=True,kernel_size=16,spr=0.5,thr=0.1 --tasks gsm8k --batch_size 1
