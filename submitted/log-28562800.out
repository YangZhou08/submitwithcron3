M	__pycache__/cache.cpython-312.pyc
M	__pycache__/xevaluator.cpython-312.pyc
M	__pycache__/xhuggingface.cpython-312.pyc
Your branch is up to date with 'origin/yangexp2'.
Already up to date.
Looking in indexes: https://pypi.org/simple, http://webservice
Requirement already satisfied: termcolor in /private/home/beidic/.conda/envs/griffin/lib/python3.12/site-packages (2.4.0)
Looking in indexes: https://pypi.org/simple, http://webservice
Requirement already satisfied: wandb in /private/home/beidic/.conda/envs/griffin/lib/python3.12/site-packages (0.16.3)
Requirement already satisfied: Click!=8.0.0,>=7.1 in /private/home/beidic/.conda/envs/griffin/lib/python3.12/site-packages (from wandb) (8.1.7)
Requirement already satisfied: GitPython!=3.1.29,>=1.0.0 in /private/home/beidic/.conda/envs/griffin/lib/python3.12/site-packages (from wandb) (3.1.42)
Requirement already satisfied: requests<3,>=2.0.0 in /private/home/beidic/.conda/envs/griffin/lib/python3.12/site-packages (from wandb) (2.32.3)
Requirement already satisfied: psutil>=5.0.0 in /private/home/beidic/.conda/envs/griffin/lib/python3.12/site-packages (from wandb) (5.9.8)
Requirement already satisfied: sentry-sdk>=1.0.0 in /private/home/beidic/.conda/envs/griffin/lib/python3.12/site-packages (from wandb) (1.40.6)
Requirement already satisfied: docker-pycreds>=0.4.0 in /private/home/beidic/.conda/envs/griffin/lib/python3.12/site-packages (from wandb) (0.4.0)
Requirement already satisfied: PyYAML in /private/home/beidic/.conda/envs/griffin/lib/python3.12/site-packages (from wandb) (6.0.1)
Requirement already satisfied: setproctitle in /private/home/beidic/.conda/envs/griffin/lib/python3.12/site-packages (from wandb) (1.3.3)
Requirement already satisfied: setuptools in /private/home/beidic/.conda/envs/griffin/lib/python3.12/site-packages (from wandb) (68.2.2)
Requirement already satisfied: appdirs>=1.4.3 in /private/home/beidic/.conda/envs/griffin/lib/python3.12/site-packages (from wandb) (1.4.4)
Requirement already satisfied: protobuf!=4.21.0,<5,>=3.19.0 in /private/home/beidic/.conda/envs/griffin/lib/python3.12/site-packages (from wandb) (4.25.2)
Requirement already satisfied: six>=1.4.0 in /private/home/beidic/.conda/envs/griffin/lib/python3.12/site-packages (from docker-pycreds>=0.4.0->wandb) (1.16.0)
Requirement already satisfied: gitdb<5,>=4.0.1 in /private/home/beidic/.conda/envs/griffin/lib/python3.12/site-packages (from GitPython!=3.1.29,>=1.0.0->wandb) (4.0.11)
Requirement already satisfied: charset-normalizer<4,>=2 in /private/home/beidic/.conda/envs/griffin/lib/python3.12/site-packages (from requests<3,>=2.0.0->wandb) (3.3.2)
Requirement already satisfied: idna<4,>=2.5 in /private/home/beidic/.conda/envs/griffin/lib/python3.12/site-packages (from requests<3,>=2.0.0->wandb) (3.7)
Requirement already satisfied: urllib3<3,>=1.21.1 in /private/home/beidic/.conda/envs/griffin/lib/python3.12/site-packages (from requests<3,>=2.0.0->wandb) (2.2.1)
Requirement already satisfied: certifi>=2017.4.17 in /private/home/beidic/.conda/envs/griffin/lib/python3.12/site-packages (from requests<3,>=2.0.0->wandb) (2024.6.2)
Requirement already satisfied: smmap<6,>=3.0.1 in /private/home/beidic/.conda/envs/griffin/lib/python3.12/site-packages (from gitdb<5,>=4.0.1->GitPython!=3.1.29,>=1.0.0->wandb) (5.0.1)
Looking in indexes: https://pypi.org/simple, http://webservice
Requirement already satisfied: huggingface_hub[cli] in /private/home/beidic/.conda/envs/griffin/lib/python3.12/site-packages (0.23.2)
Requirement already satisfied: filelock in /private/home/beidic/.conda/envs/griffin/lib/python3.12/site-packages (from huggingface_hub[cli]) (3.14.0)
Requirement already satisfied: fsspec>=2023.5.0 in /private/home/beidic/.conda/envs/griffin/lib/python3.12/site-packages (from huggingface_hub[cli]) (2024.6.0)
Requirement already satisfied: packaging>=20.9 in /private/home/beidic/.conda/envs/griffin/lib/python3.12/site-packages (from huggingface_hub[cli]) (24.0)
Requirement already satisfied: pyyaml>=5.1 in /private/home/beidic/.conda/envs/griffin/lib/python3.12/site-packages (from huggingface_hub[cli]) (6.0.1)
Requirement already satisfied: requests in /private/home/beidic/.conda/envs/griffin/lib/python3.12/site-packages (from huggingface_hub[cli]) (2.32.3)
Requirement already satisfied: tqdm>=4.42.1 in /private/home/beidic/.conda/envs/griffin/lib/python3.12/site-packages (from huggingface_hub[cli]) (4.66.4)
Requirement already satisfied: typing-extensions>=3.7.4.3 in /private/home/beidic/.conda/envs/griffin/lib/python3.12/site-packages (from huggingface_hub[cli]) (4.12.1)
Requirement already satisfied: InquirerPy==0.3.4 in /private/home/beidic/.conda/envs/griffin/lib/python3.12/site-packages (from huggingface_hub[cli]) (0.3.4)
Requirement already satisfied: pfzy<0.4.0,>=0.3.1 in /private/home/beidic/.conda/envs/griffin/lib/python3.12/site-packages (from InquirerPy==0.3.4->huggingface_hub[cli]) (0.3.4)
Requirement already satisfied: prompt-toolkit<4.0.0,>=3.0.1 in /private/home/beidic/.conda/envs/griffin/lib/python3.12/site-packages (from InquirerPy==0.3.4->huggingface_hub[cli]) (3.0.43)
Requirement already satisfied: charset-normalizer<4,>=2 in /private/home/beidic/.conda/envs/griffin/lib/python3.12/site-packages (from requests->huggingface_hub[cli]) (3.3.2)
Requirement already satisfied: idna<4,>=2.5 in /private/home/beidic/.conda/envs/griffin/lib/python3.12/site-packages (from requests->huggingface_hub[cli]) (3.7)
Requirement already satisfied: urllib3<3,>=1.21.1 in /private/home/beidic/.conda/envs/griffin/lib/python3.12/site-packages (from requests->huggingface_hub[cli]) (2.2.1)
Requirement already satisfied: certifi>=2017.4.17 in /private/home/beidic/.conda/envs/griffin/lib/python3.12/site-packages (from requests->huggingface_hub[cli]) (2024.6.2)
Requirement already satisfied: wcwidth in /private/home/beidic/.conda/envs/griffin/lib/python3.12/site-packages (from prompt-toolkit<4.0.0,>=3.0.1->InquirerPy==0.3.4->huggingface_hub[cli]) (0.2.13)
Looking in indexes: https://pypi.org/simple, http://webservice
Requirement already satisfied: matplotlib in /private/home/beidic/.conda/envs/griffin/lib/python3.12/site-packages (3.8.0)
Requirement already satisfied: contourpy>=1.0.1 in /private/home/beidic/.conda/envs/griffin/lib/python3.12/site-packages (from matplotlib) (1.2.0)
Requirement already satisfied: cycler>=0.10 in /private/home/beidic/.conda/envs/griffin/lib/python3.12/site-packages (from matplotlib) (0.11.0)
Requirement already satisfied: fonttools>=4.22.0 in /private/home/beidic/.conda/envs/griffin/lib/python3.12/site-packages (from matplotlib) (4.25.0)
Requirement already satisfied: kiwisolver>=1.0.1 in /private/home/beidic/.conda/envs/griffin/lib/python3.12/site-packages (from matplotlib) (1.4.4)
Requirement already satisfied: numpy<2,>=1.21 in /private/home/beidic/.conda/envs/griffin/lib/python3.12/site-packages (from matplotlib) (1.26.4)
Requirement already satisfied: packaging>=20.0 in /private/home/beidic/.conda/envs/griffin/lib/python3.12/site-packages (from matplotlib) (24.0)
Requirement already satisfied: pillow>=6.2.0 in /private/home/beidic/.conda/envs/griffin/lib/python3.12/site-packages (from matplotlib) (10.0.1)
Requirement already satisfied: pyparsing>=2.3.1 in /private/home/beidic/.conda/envs/griffin/lib/python3.12/site-packages (from matplotlib) (3.0.9)
Requirement already satisfied: python-dateutil>=2.7 in /private/home/beidic/.conda/envs/griffin/lib/python3.12/site-packages (from matplotlib) (2.8.2)
Requirement already satisfied: six>=1.5 in /private/home/beidic/.conda/envs/griffin/lib/python3.12/site-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)
Looking in indexes: https://pypi.org/simple, http://webservice
Requirement already satisfied: langdetect in /private/home/beidic/.conda/envs/griffin/lib/python3.12/site-packages (1.0.9)
Requirement already satisfied: six in /private/home/beidic/.conda/envs/griffin/lib/python3.12/site-packages (from langdetect) (1.16.0)
Looking in indexes: https://pypi.org/simple, http://webservice
Requirement already satisfied: immutabledict in /private/home/beidic/.conda/envs/griffin/lib/python3.12/site-packages (4.2.0)
Looking in indexes: https://pypi.org/simple, http://webservice
Requirement already satisfied: sentencepiece in /private/home/beidic/.conda/envs/griffin/lib/python3.12/site-packages (0.1.99)
/private/home/beidic/.conda/envs/griffin/bin/python
/private/home/beidic/.conda/envs/griffin/bin/python
[1m[31mERROR! `huggingface-cli login` uses an outdated login mechanism that is not compatible with the Hugging Face Hub backend anymore. Please use `huggingface-cli login instead.[0m
The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-cli` if you want to set the git credential as well.
Namespace(model='xhf', tasks='gsm8k', model_args='pretrained=meta-llama/Meta-Llama-3-8B-Instruct,cats=True,spr=0.1,,check=True,kernel_size=16,thr=0.1', num_fewshot=None, batch_size='1', max_batch_size=None, device=None, output_path=None, limit=0.5, topp=1.1, topk=64, spr=0.25, sink=8, local=256, use_cache=None, cache_requests=None, check_integrity=False, write_out=False, log_samples=False, show_config=False, include_path=None, gen_kwargs=None, verbosity='INFO', wandb_args='', predict_only=False, seed=[0, 1234, 1234], trust_remote_code=False)
Namespace(model='xhf', tasks='gsm8k', model_args='pretrained=meta-llama/Meta-Llama-3-8B-Instruct,cats=True,spr=0.1,,check=True,kernel_size=16,thr=0.1', num_fewshot=None, batch_size='1', max_batch_size=None, device=None, output_path=None, limit=0.5, topp=1.1, topk=64, spr=0.25, sink=8, local=256, use_cache=None, cache_requests=None, check_integrity=False, write_out=False, log_samples=False, show_config=False, include_path=None, gen_kwargs=None, verbosity='INFO', wandb_args='', predict_only=False, seed=[0, 1234, 1234], trust_remote_code=False)Namespace(model='xhf', tasks='gsm8k', model_args='pretrained=meta-llama/Meta-Llama-3-8B-Instruct,cats=True,spr=0.1,,check=True,kernel_size=16,thr=0.1', num_fewshot=None, batch_size='1', max_batch_size=None, device=None, output_path=None, limit=0.5, topp=1.1, topk=64, spr=0.25, sink=8, local=256, use_cache=None, cache_requests=None, check_integrity=False, write_out=False, log_samples=False, show_config=False, include_path=None, gen_kwargs=None, verbosity='INFO', wandb_args='', predict_only=False, seed=[0, 1234, 1234], trust_remote_code=False)

Namespace(model='xhf', tasks='gsm8k', model_args='pretrained=meta-llama/Meta-Llama-3-8B-Instruct,cats=True,spr=0.1,,check=True,kernel_size=16,thr=0.1', num_fewshot=None, batch_size='1', max_batch_size=None, device=None, output_path=None, limit=0.5, topp=1.1, topk=64, spr=0.25, sink=8, local=256, use_cache=None, cache_requests=None, check_integrity=False, write_out=False, log_samples=False, show_config=False, include_path=None, gen_kwargs=None, verbosity='INFO', wandb_args='', predict_only=False, seed=[0, 1234, 1234], trust_remote_code=False)
Namespace(model='xhf', tasks='gsm8k', model_args='pretrained=meta-llama/Meta-Llama-3-8B-Instruct,cats=True,spr=0.1,,check=True,kernel_size=16,thr=0.1', num_fewshot=None, batch_size='1', max_batch_size=None, device=None, output_path=None, limit=0.5, topp=1.1, topk=64, spr=0.25, sink=8, local=256, use_cache=None, cache_requests=None, check_integrity=False, write_out=False, log_samples=False, show_config=False, include_path=None, gen_kwargs=None, verbosity='INFO', wandb_args='', predict_only=False, seed=[0, 1234, 1234], trust_remote_code=False)
Namespace(model='xhf', tasks='gsm8k', model_args='pretrained=meta-llama/Meta-Llama-3-8B-Instruct,cats=True,spr=0.1,,check=True,kernel_size=16,thr=0.1', num_fewshot=None, batch_size='1', max_batch_size=None, device=None, output_path=None, limit=0.5, topp=1.1, topk=64, spr=0.25, sink=8, local=256, use_cache=None, cache_requests=None, check_integrity=False, write_out=False, log_samples=False, show_config=False, include_path=None, gen_kwargs=None, verbosity='INFO', wandb_args='', predict_only=False, seed=[0, 1234, 1234], trust_remote_code=False)
Namespace(model='xhf', tasks='gsm8k', model_args='pretrained=meta-llama/Meta-Llama-3-8B-Instruct,cats=True,spr=0.1,,check=True,kernel_size=16,thr=0.1', num_fewshot=None, batch_size='1', max_batch_size=None, device=None, output_path=None, limit=0.5, topp=1.1, topk=64, spr=0.25, sink=8, local=256, use_cache=None, cache_requests=None, check_integrity=False, write_out=False, log_samples=False, show_config=False, include_path=None, gen_kwargs=None, verbosity='INFO', wandb_args='', predict_only=False, seed=[0, 1234, 1234], trust_remote_code=False)
Namespace(model='xhf', tasks='gsm8k', model_args='pretrained=meta-llama/Meta-Llama-3-8B-Instruct,cats=True,spr=0.1,,check=True,kernel_size=16,thr=0.1', num_fewshot=None, batch_size='1', max_batch_size=None, device=None, output_path=None, limit=0.5, topp=1.1, topk=64, spr=0.25, sink=8, local=256, use_cache=None, cache_requests=None, check_integrity=False, write_out=False, log_samples=False, show_config=False, include_path=None, gen_kwargs=None, verbosity='INFO', wandb_args='', predict_only=False, seed=[0, 1234, 1234], trust_remote_code=False)
7976 5406 1.4753977062523123
7849 5477 1.4330838050027388
6988 4735 1.475818373812038
8296 5587 1.4848756040809021
7655 5273 1.4517352550730134
8359 5592 1.4948140200286124
8078 5594 1.444047193421523
8515 5909 1.4410221695718395
Namespace(model='xhf', tasks='gsm8k', model_args='pretrained=meta-llama/Meta-Llama-3-8B-Instruct,cats=True,spr=0.2,,check=True,kernel_size=16,thr=0.1', num_fewshot=None, batch_size='1', max_batch_size=None, device=None, output_path=None, limit=0.5, topp=1.1, topk=64, spr=0.25, sink=8, local=256, use_cache=None, cache_requests=None, check_integrity=False, write_out=False, log_samples=False, show_config=False, include_path=None, gen_kwargs=None, verbosity='INFO', wandb_args='', predict_only=False, seed=[0, 1234, 1234], trust_remote_code=False)
Namespace(model='xhf', tasks='gsm8k', model_args='pretrained=meta-llama/Meta-Llama-3-8B-Instruct,cats=True,spr=0.2,,check=True,kernel_size=16,thr=0.1', num_fewshot=None, batch_size='1', max_batch_size=None, device=None, output_path=None, limit=0.5, topp=1.1, topk=64, spr=0.25, sink=8, local=256, use_cache=None, cache_requests=None, check_integrity=False, write_out=False, log_samples=False, show_config=False, include_path=None, gen_kwargs=None, verbosity='INFO', wandb_args='', predict_only=False, seed=[0, 1234, 1234], trust_remote_code=False)
Namespace(model='xhf', tasks='gsm8k', model_args='pretrained=meta-llama/Meta-Llama-3-8B-Instruct,cats=True,spr=0.2,,check=True,kernel_size=16,thr=0.1', num_fewshot=None, batch_size='1', max_batch_size=None, device=None, output_path=None, limit=0.5, topp=1.1, topk=64, spr=0.25, sink=8, local=256, use_cache=None, cache_requests=None, check_integrity=False, write_out=False, log_samples=False, show_config=False, include_path=None, gen_kwargs=None, verbosity='INFO', wandb_args='', predict_only=False, seed=[0, 1234, 1234], trust_remote_code=False)
Namespace(model='xhf', tasks='gsm8k', model_args='pretrained=meta-llama/Meta-Llama-3-8B-Instruct,cats=True,spr=0.2,,check=True,kernel_size=16,thr=0.1', num_fewshot=None, batch_size='1', max_batch_size=None, device=None, output_path=None, limit=0.5, topp=1.1, topk=64, spr=0.25, sink=8, local=256, use_cache=None, cache_requests=None, check_integrity=False, write_out=False, log_samples=False, show_config=False, include_path=None, gen_kwargs=None, verbosity='INFO', wandb_args='', predict_only=False, seed=[0, 1234, 1234], trust_remote_code=False)
Namespace(model='xhf', tasks='gsm8k', model_args='pretrained=meta-llama/Meta-Llama-3-8B-Instruct,cats=True,spr=0.2,,check=True,kernel_size=16,thr=0.1', num_fewshot=None, batch_size='1', max_batch_size=None, device=None, output_path=None, limit=0.5, topp=1.1, topk=64, spr=0.25, sink=8, local=256, use_cache=None, cache_requests=None, check_integrity=False, write_out=False, log_samples=False, show_config=False, include_path=None, gen_kwargs=None, verbosity='INFO', wandb_args='', predict_only=False, seed=[0, 1234, 1234], trust_remote_code=False)
Namespace(model='xhf', tasks='gsm8k', model_args='pretrained=meta-llama/Meta-Llama-3-8B-Instruct,cats=True,spr=0.2,,check=True,kernel_size=16,thr=0.1', num_fewshot=None, batch_size='1', max_batch_size=None, device=None, output_path=None, limit=0.5, topp=1.1, topk=64, spr=0.25, sink=8, local=256, use_cache=None, cache_requests=None, check_integrity=False, write_out=False, log_samples=False, show_config=False, include_path=None, gen_kwargs=None, verbosity='INFO', wandb_args='', predict_only=False, seed=[0, 1234, 1234], trust_remote_code=False)
Namespace(model='xhf', tasks='gsm8k', model_args='pretrained=meta-llama/Meta-Llama-3-8B-Instruct,cats=True,spr=0.2,,check=True,kernel_size=16,thr=0.1', num_fewshot=None, batch_size='1', max_batch_size=None, device=None, output_path=None, limit=0.5, topp=1.1, topk=64, spr=0.25, sink=8, local=256, use_cache=None, cache_requests=None, check_integrity=False, write_out=False, log_samples=False, show_config=False, include_path=None, gen_kwargs=None, verbosity='INFO', wandb_args='', predict_only=False, seed=[0, 1234, 1234], trust_remote_code=False)
Namespace(model='xhf', tasks='gsm8k', model_args='pretrained=meta-llama/Meta-Llama-3-8B-Instruct,cats=True,spr=0.2,,check=True,kernel_size=16,thr=0.1', num_fewshot=None, batch_size='1', max_batch_size=None, device=None, output_path=None, limit=0.5, topp=1.1, topk=64, spr=0.25, sink=8, local=256, use_cache=None, cache_requests=None, check_integrity=False, write_out=False, log_samples=False, show_config=False, include_path=None, gen_kwargs=None, verbosity='INFO', wandb_args='', predict_only=False, seed=[0, 1234, 1234], trust_remote_code=False)
6898 1812 3.806843267108168
7919 2069 3.8274528757854034
7306 1950 3.7466666666666666
7710 1967 3.9196746314184034
8079 2144 3.768190298507463
7751 2084 3.7192898272552783
7416 2011 3.687717553455992
6930 1694 4.090909090909091
xhf (pretrained=meta-llama/Meta-Llama-3-8B-Instruct,cats=True,spr=0.2,,check=True,kernel_size=16,thr=0.1), gen_kwargs: (None), limit: 0.5, num_fewshot: None, batch_size: 1
|Tasks|Version|     Filter     |n-shot|  Metric   |Value |   |Stderr|
|-----|------:|----------------|-----:|-----------|-----:|---|-----:|
|gsm8k|      3|strict-match    |     5|exact_match|0.4121|±  |0.0192|
|     |       |flexible-extract|     5|exact_match|0.6045|±  |0.0190|

Namespace(model='xhf', tasks='gsm8k', model_args='pretrained=meta-llama/Meta-Llama-3-8B-Instruct,cats=True,spr=0.3,,check=True,kernel_size=16,thr=0.1', num_fewshot=None, batch_size='1', max_batch_size=None, device=None, output_path=None, limit=0.5, topp=1.1, topk=64, spr=0.25, sink=8, local=256, use_cache=None, cache_requests=None, check_integrity=False, write_out=False, log_samples=False, show_config=False, include_path=None, gen_kwargs=None, verbosity='INFO', wandb_args='', predict_only=False, seed=[0, 1234, 1234], trust_remote_code=False)
Namespace(model='xhf', tasks='gsm8k', model_args='pretrained=meta-llama/Meta-Llama-3-8B-Instruct,cats=True,spr=0.3,,check=True,kernel_size=16,thr=0.1', num_fewshot=None, batch_size='1', max_batch_size=None, device=None, output_path=None, limit=0.5, topp=1.1, topk=64, spr=0.25, sink=8, local=256, use_cache=None, cache_requests=None, check_integrity=False, write_out=False, log_samples=False, show_config=False, include_path=None, gen_kwargs=None, verbosity='INFO', wandb_args='', predict_only=False, seed=[0, 1234, 1234], trust_remote_code=False)
Namespace(model='xhf', tasks='gsm8k', model_args='pretrained=meta-llama/Meta-Llama-3-8B-Instruct,cats=True,spr=0.3,,check=True,kernel_size=16,thr=0.1', num_fewshot=None, batch_size='1', max_batch_size=None, device=None, output_path=None, limit=0.5, topp=1.1, topk=64, spr=0.25, sink=8, local=256, use_cache=None, cache_requests=None, check_integrity=False, write_out=False, log_samples=False, show_config=False, include_path=None, gen_kwargs=None, verbosity='INFO', wandb_args='', predict_only=False, seed=[0, 1234, 1234], trust_remote_code=False)
Namespace(model='xhf', tasks='gsm8k', model_args='pretrained=meta-llama/Meta-Llama-3-8B-Instruct,cats=True,spr=0.3,,check=True,kernel_size=16,thr=0.1', num_fewshot=None, batch_size='1', max_batch_size=None, device=None, output_path=None, limit=0.5, topp=1.1, topk=64, spr=0.25, sink=8, local=256, use_cache=None, cache_requests=None, check_integrity=False, write_out=False, log_samples=False, show_config=False, include_path=None, gen_kwargs=None, verbosity='INFO', wandb_args='', predict_only=False, seed=[0, 1234, 1234], trust_remote_code=False)
Namespace(model='xhf', tasks='gsm8k', model_args='pretrained=meta-llama/Meta-Llama-3-8B-Instruct,cats=True,spr=0.3,,check=True,kernel_size=16,thr=0.1', num_fewshot=None, batch_size='1', max_batch_size=None, device=None, output_path=None, limit=0.5, topp=1.1, topk=64, spr=0.25, sink=8, local=256, use_cache=None, cache_requests=None, check_integrity=False, write_out=False, log_samples=False, show_config=False, include_path=None, gen_kwargs=None, verbosity='INFO', wandb_args='', predict_only=False, seed=[0, 1234, 1234], trust_remote_code=False)
Namespace(model='xhf', tasks='gsm8k', model_args='pretrained=meta-llama/Meta-Llama-3-8B-Instruct,cats=True,spr=0.3,,check=True,kernel_size=16,thr=0.1', num_fewshot=None, batch_size='1', max_batch_size=None, device=None, output_path=None, limit=0.5, topp=1.1, topk=64, spr=0.25, sink=8, local=256, use_cache=None, cache_requests=None, check_integrity=False, write_out=False, log_samples=False, show_config=False, include_path=None, gen_kwargs=None, verbosity='INFO', wandb_args='', predict_only=False, seed=[0, 1234, 1234], trust_remote_code=False)
Namespace(model='xhf', tasks='gsm8k', model_args='pretrained=meta-llama/Meta-Llama-3-8B-Instruct,cats=True,spr=0.3,,check=True,kernel_size=16,thr=0.1', num_fewshot=None, batch_size='1', max_batch_size=None, device=None, output_path=None, limit=0.5, topp=1.1, topk=64, spr=0.25, sink=8, local=256, use_cache=None, cache_requests=None, check_integrity=False, write_out=False, log_samples=False, show_config=False, include_path=None, gen_kwargs=None, verbosity='INFO', wandb_args='', predict_only=False, seed=[0, 1234, 1234], trust_remote_code=False)
Namespace(model='xhf', tasks='gsm8k', model_args='pretrained=meta-llama/Meta-Llama-3-8B-Instruct,cats=True,spr=0.3,,check=True,kernel_size=16,thr=0.1', num_fewshot=None, batch_size='1', max_batch_size=None, device=None, output_path=None, limit=0.5, topp=1.1, topk=64, spr=0.25, sink=8, local=256, use_cache=None, cache_requests=None, check_integrity=False, write_out=False, log_samples=False, show_config=False, include_path=None, gen_kwargs=None, verbosity='INFO', wandb_args='', predict_only=False, seed=[0, 1234, 1234], trust_remote_code=False)
7203 899 8.012235817575084
7786 1006 7.739562624254473
7940 1025 7.746341463414634
7333 941 7.792773645058449
7476 999 7.483483483483483
8177 1058 7.728733459357278
7724 1009 7.655104063429138
8362 1087 7.6927322907083715
xhf (pretrained=meta-llama/Meta-Llama-3-8B-Instruct,cats=True,spr=0.3,,check=True,kernel_size=16,thr=0.1), gen_kwargs: (None), limit: 0.5, num_fewshot: None, batch_size: 1
|Tasks|Version|     Filter     |n-shot|  Metric   |Value |   |Stderr|
|-----|------:|----------------|-----:|-----------|-----:|---|-----:|
|gsm8k|      3|strict-match    |     5|exact_match|0.5970|±  |0.0191|
|     |       |flexible-extract|     5|exact_match|0.6182|±  |0.0189|

Namespace(model='xhf', tasks='gsm8k', model_args='pretrained=meta-llama/Meta-Llama-3-8B-Instruct,cats=True,spr=0.4,,check=True,kernel_size=16,thr=0.1', num_fewshot=None, batch_size='1', max_batch_size=None, device=None, output_path=None, limit=0.5, topp=1.1, topk=64, spr=0.25, sink=8, local=256, use_cache=None, cache_requests=None, check_integrity=False, write_out=False, log_samples=False, show_config=False, include_path=None, gen_kwargs=None, verbosity='INFO', wandb_args='', predict_only=False, seed=[0, 1234, 1234], trust_remote_code=False)Namespace(model='xhf', tasks='gsm8k', model_args='pretrained=meta-llama/Meta-Llama-3-8B-Instruct,cats=True,spr=0.4,,check=True,kernel_size=16,thr=0.1', num_fewshot=None, batch_size='1', max_batch_size=None, device=None, output_path=None, limit=0.5, topp=1.1, topk=64, spr=0.25, sink=8, local=256, use_cache=None, cache_requests=None, check_integrity=False, write_out=False, log_samples=False, show_config=False, include_path=None, gen_kwargs=None, verbosity='INFO', wandb_args='', predict_only=False, seed=[0, 1234, 1234], trust_remote_code=False)

Namespace(model='xhf', tasks='gsm8k', model_args='pretrained=meta-llama/Meta-Llama-3-8B-Instruct,cats=True,spr=0.4,,check=True,kernel_size=16,thr=0.1', num_fewshot=None, batch_size='1', max_batch_size=None, device=None, output_path=None, limit=0.5, topp=1.1, topk=64, spr=0.25, sink=8, local=256, use_cache=None, cache_requests=None, check_integrity=False, write_out=False, log_samples=False, show_config=False, include_path=None, gen_kwargs=None, verbosity='INFO', wandb_args='', predict_only=False, seed=[0, 1234, 1234], trust_remote_code=False)
Namespace(model='xhf', tasks='gsm8k', model_args='pretrained=meta-llama/Meta-Llama-3-8B-Instruct,cats=True,spr=0.4,,check=True,kernel_size=16,thr=0.1', num_fewshot=None, batch_size='1', max_batch_size=None, device=None, output_path=None, limit=0.5, topp=1.1, topk=64, spr=0.25, sink=8, local=256, use_cache=None, cache_requests=None, check_integrity=False, write_out=False, log_samples=False, show_config=False, include_path=None, gen_kwargs=None, verbosity='INFO', wandb_args='', predict_only=False, seed=[0, 1234, 1234], trust_remote_code=False)
Namespace(model='xhf', tasks='gsm8k', model_args='pretrained=meta-llama/Meta-Llama-3-8B-Instruct,cats=True,spr=0.4,,check=True,kernel_size=16,thr=0.1', num_fewshot=None, batch_size='1', max_batch_size=None, device=None, output_path=None, limit=0.5, topp=1.1, topk=64, spr=0.25, sink=8, local=256, use_cache=None, cache_requests=None, check_integrity=False, write_out=False, log_samples=False, show_config=False, include_path=None, gen_kwargs=None, verbosity='INFO', wandb_args='', predict_only=False, seed=[0, 1234, 1234], trust_remote_code=False)
Namespace(model='xhf', tasks='gsm8k', model_args='pretrained=meta-llama/Meta-Llama-3-8B-Instruct,cats=True,spr=0.4,,check=True,kernel_size=16,thr=0.1', num_fewshot=None, batch_size='1', max_batch_size=None, device=None, output_path=None, limit=0.5, topp=1.1, topk=64, spr=0.25, sink=8, local=256, use_cache=None, cache_requests=None, check_integrity=False, write_out=False, log_samples=False, show_config=False, include_path=None, gen_kwargs=None, verbosity='INFO', wandb_args='', predict_only=False, seed=[0, 1234, 1234], trust_remote_code=False)
Namespace(model='xhf', tasks='gsm8k', model_args='pretrained=meta-llama/Meta-Llama-3-8B-Instruct,cats=True,spr=0.4,,check=True,kernel_size=16,thr=0.1', num_fewshot=None, batch_size='1', max_batch_size=None, device=None, output_path=None, limit=0.5, topp=1.1, topk=64, spr=0.25, sink=8, local=256, use_cache=None, cache_requests=None, check_integrity=False, write_out=False, log_samples=False, show_config=False, include_path=None, gen_kwargs=None, verbosity='INFO', wandb_args='', predict_only=False, seed=[0, 1234, 1234], trust_remote_code=False)
Namespace(model='xhf', tasks='gsm8k', model_args='pretrained=meta-llama/Meta-Llama-3-8B-Instruct,cats=True,spr=0.4,,check=True,kernel_size=16,thr=0.1', num_fewshot=None, batch_size='1', max_batch_size=None, device=None, output_path=None, limit=0.5, topp=1.1, topk=64, spr=0.25, sink=8, local=256, use_cache=None, cache_requests=None, check_integrity=False, write_out=False, log_samples=False, show_config=False, include_path=None, gen_kwargs=None, verbosity='INFO', wandb_args='', predict_only=False, seed=[0, 1234, 1234], trust_remote_code=False)
6588 527 12.500948766603415
7343 587 12.509369676320272
7823 630 12.417460317460318
8433 700 12.047142857142857
7117 584 12.186643835616438
7682 621 12.37037037037037
8266 691 11.962373371924746
7144 583 12.25385934819897
xhf (pretrained=meta-llama/Meta-Llama-3-8B-Instruct,cats=True,spr=0.4,,check=True,kernel_size=16,thr=0.1), gen_kwargs: (None), limit: 0.5, num_fewshot: None, batch_size: 1
|Tasks|Version|     Filter     |n-shot|  Metric   |Value |   |Stderr|
|-----|------:|----------------|-----:|-----------|-----:|---|-----:|
|gsm8k|      3|strict-match    |     5|exact_match|0.7167|±  |0.0176|
|     |       |flexible-extract|     5|exact_match|0.7197|±  |0.0175|

Namespace(model='xhf', tasks='gsm8k', model_args='pretrained=meta-llama/Meta-Llama-3-8B-Instruct,cats=True,spr=0.5,,check=True,kernel_size=16,thr=0.1', num_fewshot=None, batch_size='1', max_batch_size=None, device=None, output_path=None, limit=0.5, topp=1.1, topk=64, spr=0.25, sink=8, local=256, use_cache=None, cache_requests=None, check_integrity=False, write_out=False, log_samples=False, show_config=False, include_path=None, gen_kwargs=None, verbosity='INFO', wandb_args='', predict_only=False, seed=[0, 1234, 1234], trust_remote_code=False)
Namespace(model='xhf', tasks='gsm8k', model_args='pretrained=meta-llama/Meta-Llama-3-8B-Instruct,cats=True,spr=0.5,,check=True,kernel_size=16,thr=0.1', num_fewshot=None, batch_size='1', max_batch_size=None, device=None, output_path=None, limit=0.5, topp=1.1, topk=64, spr=0.25, sink=8, local=256, use_cache=None, cache_requests=None, check_integrity=False, write_out=False, log_samples=False, show_config=False, include_path=None, gen_kwargs=None, verbosity='INFO', wandb_args='', predict_only=False, seed=[0, 1234, 1234], trust_remote_code=False)
Namespace(model='xhf', tasks='gsm8k', model_args='pretrained=meta-llama/Meta-Llama-3-8B-Instruct,cats=True,spr=0.5,,check=True,kernel_size=16,thr=0.1', num_fewshot=None, batch_size='1', max_batch_size=None, device=None, output_path=None, limit=0.5, topp=1.1, topk=64, spr=0.25, sink=8, local=256, use_cache=None, cache_requests=None, check_integrity=False, write_out=False, log_samples=False, show_config=False, include_path=None, gen_kwargs=None, verbosity='INFO', wandb_args='', predict_only=False, seed=[0, 1234, 1234], trust_remote_code=False)
Namespace(model='xhf', tasks='gsm8k', model_args='pretrained=meta-llama/Meta-Llama-3-8B-Instruct,cats=True,spr=0.5,,check=True,kernel_size=16,thr=0.1', num_fewshot=None, batch_size='1', max_batch_size=None, device=None, output_path=None, limit=0.5, topp=1.1, topk=64, spr=0.25, sink=8, local=256, use_cache=None, cache_requests=None, check_integrity=False, write_out=False, log_samples=False, show_config=False, include_path=None, gen_kwargs=None, verbosity='INFO', wandb_args='', predict_only=False, seed=[0, 1234, 1234], trust_remote_code=False)
Namespace(model='xhf', tasks='gsm8k', model_args='pretrained=meta-llama/Meta-Llama-3-8B-Instruct,cats=True,spr=0.5,,check=True,kernel_size=16,thr=0.1', num_fewshot=None, batch_size='1', max_batch_size=None, device=None, output_path=None, limit=0.5, topp=1.1, topk=64, spr=0.25, sink=8, local=256, use_cache=None, cache_requests=None, check_integrity=False, write_out=False, log_samples=False, show_config=False, include_path=None, gen_kwargs=None, verbosity='INFO', wandb_args='', predict_only=False, seed=[0, 1234, 1234], trust_remote_code=False)
Namespace(model='xhf', tasks='gsm8k', model_args='pretrained=meta-llama/Meta-Llama-3-8B-Instruct,cats=True,spr=0.5,,check=True,kernel_size=16,thr=0.1', num_fewshot=None, batch_size='1', max_batch_size=None, device=None, output_path=None, limit=0.5, topp=1.1, topk=64, spr=0.25, sink=8, local=256, use_cache=None, cache_requests=None, check_integrity=False, write_out=False, log_samples=False, show_config=False, include_path=None, gen_kwargs=None, verbosity='INFO', wandb_args='', predict_only=False, seed=[0, 1234, 1234], trust_remote_code=False)
Namespace(model='xhf', tasks='gsm8k', model_args='pretrained=meta-llama/Meta-Llama-3-8B-Instruct,cats=True,spr=0.5,,check=True,kernel_size=16,thr=0.1', num_fewshot=None, batch_size='1', max_batch_size=None, device=None, output_path=None, limit=0.5, topp=1.1, topk=64, spr=0.25, sink=8, local=256, use_cache=None, cache_requests=None, check_integrity=False, write_out=False, log_samples=False, show_config=False, include_path=None, gen_kwargs=None, verbosity='INFO', wandb_args='', predict_only=False, seed=[0, 1234, 1234], trust_remote_code=False)
Namespace(model='xhf', tasks='gsm8k', model_args='pretrained=meta-llama/Meta-Llama-3-8B-Instruct,cats=True,spr=0.5,,check=True,kernel_size=16,thr=0.1', num_fewshot=None, batch_size='1', max_batch_size=None, device=None, output_path=None, limit=0.5, topp=1.1, topk=64, spr=0.25, sink=8, local=256, use_cache=None, cache_requests=None, check_integrity=False, write_out=False, log_samples=False, show_config=False, include_path=None, gen_kwargs=None, verbosity='INFO', wandb_args='', predict_only=False, seed=[0, 1234, 1234], trust_remote_code=False)
7265 494 14.706477732793521
7178 494 14.530364372469636
6770 458 14.781659388646288
8049 554 14.528880866425993
7792 532 14.646616541353383
7916 539 14.686456400742115
7893 533 14.808630393996248
7309 489 14.946830265848671
xhf (pretrained=meta-llama/Meta-Llama-3-8B-Instruct,cats=True,spr=0.5,,check=True,kernel_size=16,thr=0.1), gen_kwargs: (None), limit: 0.5, num_fewshot: None, batch_size: 1
|Tasks|Version|     Filter     |n-shot|  Metric   |Value |   |Stderr|
|-----|------:|----------------|-----:|-----------|-----:|---|-----:|
|gsm8k|      3|strict-match    |     5|exact_match|0.7152|±  |0.0176|
|     |       |flexible-extract|     5|exact_match|0.7152|±  |0.0176|

Namespace(model='xhf', tasks='gsm8k', model_args='pretrained=meta-llama/Meta-Llama-3-8B-Instruct,cats=True,spr=0.6,,check=True,kernel_size=16,thr=0.1', num_fewshot=None, batch_size='1', max_batch_size=None, device=None, output_path=None, limit=0.5, topp=1.1, topk=64, spr=0.25, sink=8, local=256, use_cache=None, cache_requests=None, check_integrity=False, write_out=False, log_samples=False, show_config=False, include_path=None, gen_kwargs=None, verbosity='INFO', wandb_args='', predict_only=False, seed=[0, 1234, 1234], trust_remote_code=False)
Namespace(model='xhf', tasks='gsm8k', model_args='pretrained=meta-llama/Meta-Llama-3-8B-Instruct,cats=True,spr=0.6,,check=True,kernel_size=16,thr=0.1', num_fewshot=None, batch_size='1', max_batch_size=None, device=None, output_path=None, limit=0.5, topp=1.1, topk=64, spr=0.25, sink=8, local=256, use_cache=None, cache_requests=None, check_integrity=False, write_out=False, log_samples=False, show_config=False, include_path=None, gen_kwargs=None, verbosity='INFO', wandb_args='', predict_only=False, seed=[0, 1234, 1234], trust_remote_code=False)
Namespace(model='xhf', tasks='gsm8k', model_args='pretrained=meta-llama/Meta-Llama-3-8B-Instruct,cats=True,spr=0.6,,check=True,kernel_size=16,thr=0.1', num_fewshot=None, batch_size='1', max_batch_size=None, device=None, output_path=None, limit=0.5, topp=1.1, topk=64, spr=0.25, sink=8, local=256, use_cache=None, cache_requests=None, check_integrity=False, write_out=False, log_samples=False, show_config=False, include_path=None, gen_kwargs=None, verbosity='INFO', wandb_args='', predict_only=False, seed=[0, 1234, 1234], trust_remote_code=False)
Namespace(model='xhf', tasks='gsm8k', model_args='pretrained=meta-llama/Meta-Llama-3-8B-Instruct,cats=True,spr=0.6,,check=True,kernel_size=16,thr=0.1', num_fewshot=None, batch_size='1', max_batch_size=None, device=None, output_path=None, limit=0.5, topp=1.1, topk=64, spr=0.25, sink=8, local=256, use_cache=None, cache_requests=None, check_integrity=False, write_out=False, log_samples=False, show_config=False, include_path=None, gen_kwargs=None, verbosity='INFO', wandb_args='', predict_only=False, seed=[0, 1234, 1234], trust_remote_code=False)
Namespace(model='xhf', tasks='gsm8k', model_args='pretrained=meta-llama/Meta-Llama-3-8B-Instruct,cats=True,spr=0.6,,check=True,kernel_size=16,thr=0.1', num_fewshot=None, batch_size='1', max_batch_size=None, device=None, output_path=None, limit=0.5, topp=1.1, topk=64, spr=0.25, sink=8, local=256, use_cache=None, cache_requests=None, check_integrity=False, write_out=False, log_samples=False, show_config=False, include_path=None, gen_kwargs=None, verbosity='INFO', wandb_args='', predict_only=False, seed=[0, 1234, 1234], trust_remote_code=False)
Namespace(model='xhf', tasks='gsm8k', model_args='pretrained=meta-llama/Meta-Llama-3-8B-Instruct,cats=True,spr=0.6,,check=True,kernel_size=16,thr=0.1', num_fewshot=None, batch_size='1', max_batch_size=None, device=None, output_path=None, limit=0.5, topp=1.1, topk=64, spr=0.25, sink=8, local=256, use_cache=None, cache_requests=None, check_integrity=False, write_out=False, log_samples=False, show_config=False, include_path=None, gen_kwargs=None, verbosity='INFO', wandb_args='', predict_only=False, seed=[0, 1234, 1234], trust_remote_code=False)
Namespace(model='xhf', tasks='gsm8k', model_args='pretrained=meta-llama/Meta-Llama-3-8B-Instruct,cats=True,spr=0.6,,check=True,kernel_size=16,thr=0.1', num_fewshot=None, batch_size='1', max_batch_size=None, device=None, output_path=None, limit=0.5, topp=1.1, topk=64, spr=0.25, sink=8, local=256, use_cache=None, cache_requests=None, check_integrity=False, write_out=False, log_samples=False, show_config=False, include_path=None, gen_kwargs=None, verbosity='INFO', wandb_args='', predict_only=False, seed=[0, 1234, 1234], trust_remote_code=False)
Namespace(model='xhf', tasks='gsm8k', model_args='pretrained=meta-llama/Meta-Llama-3-8B-Instruct,cats=True,spr=0.6,,check=True,kernel_size=16,thr=0.1', num_fewshot=None, batch_size='1', max_batch_size=None, device=None, output_path=None, limit=0.5, topp=1.1, topk=64, spr=0.25, sink=8, local=256, use_cache=None, cache_requests=None, check_integrity=False, write_out=False, log_samples=False, show_config=False, include_path=None, gen_kwargs=None, verbosity='INFO', wandb_args='', predict_only=False, seed=[0, 1234, 1234], trust_remote_code=False)
7155 461 15.52060737527115
7295 470 15.52127659574468
7923 508 15.596456692913385
6835 437 15.640732265446225
7696 492 15.642276422764228
7792 502 15.52191235059761
8078 517 15.624758220502901
7503 483 15.53416149068323
xhf (pretrained=meta-llama/Meta-Llama-3-8B-Instruct,cats=True,spr=0.6,,check=True,kernel_size=16,thr=0.1), gen_kwargs: (None), limit: 0.5, num_fewshot: None, batch_size: 1
|Tasks|Version|     Filter     |n-shot|  Metric   |Value |   |Stderr|
|-----|------:|----------------|-----:|-----------|-----:|---|-----:|
|gsm8k|      3|strict-match    |     5|exact_match|0.7561|±  |0.0167|
|     |       |flexible-extract|     5|exact_match|0.7576|±  |0.0167|

Namespace(model='xhf', tasks='gsm8k', model_args='pretrained=meta-llama/Meta-Llama-3-8B-Instruct,cats=True,spr=0.7,,check=True,kernel_size=16,thr=0.1', num_fewshot=None, batch_size='1', max_batch_size=None, device=None, output_path=None, limit=0.5, topp=1.1, topk=64, spr=0.25, sink=8, local=256, use_cache=None, cache_requests=None, check_integrity=False, write_out=False, log_samples=False, show_config=False, include_path=None, gen_kwargs=None, verbosity='INFO', wandb_args='', predict_only=False, seed=[0, 1234, 1234], trust_remote_code=False)
Namespace(model='xhf', tasks='gsm8k', model_args='pretrained=meta-llama/Meta-Llama-3-8B-Instruct,cats=True,spr=0.7,,check=True,kernel_size=16,thr=0.1', num_fewshot=None, batch_size='1', max_batch_size=None, device=None, output_path=None, limit=0.5, topp=1.1, topk=64, spr=0.25, sink=8, local=256, use_cache=None, cache_requests=None, check_integrity=False, write_out=False, log_samples=False, show_config=False, include_path=None, gen_kwargs=None, verbosity='INFO', wandb_args='', predict_only=False, seed=[0, 1234, 1234], trust_remote_code=False)
Namespace(model='xhf', tasks='gsm8k', model_args='pretrained=meta-llama/Meta-Llama-3-8B-Instruct,cats=True,spr=0.7,,check=True,kernel_size=16,thr=0.1', num_fewshot=None, batch_size='1', max_batch_size=None, device=None, output_path=None, limit=0.5, topp=1.1, topk=64, spr=0.25, sink=8, local=256, use_cache=None, cache_requests=None, check_integrity=False, write_out=False, log_samples=False, show_config=False, include_path=None, gen_kwargs=None, verbosity='INFO', wandb_args='', predict_only=False, seed=[0, 1234, 1234], trust_remote_code=False)
Namespace(model='xhf', tasks='gsm8k', model_args='pretrained=meta-llama/Meta-Llama-3-8B-Instruct,cats=True,spr=0.7,,check=True,kernel_size=16,thr=0.1', num_fewshot=None, batch_size='1', max_batch_size=None, device=None, output_path=None, limit=0.5, topp=1.1, topk=64, spr=0.25, sink=8, local=256, use_cache=None, cache_requests=None, check_integrity=False, write_out=False, log_samples=False, show_config=False, include_path=None, gen_kwargs=None, verbosity='INFO', wandb_args='', predict_only=False, seed=[0, 1234, 1234], trust_remote_code=False)
Namespace(model='xhf', tasks='gsm8k', model_args='pretrained=meta-llama/Meta-Llama-3-8B-Instruct,cats=True,spr=0.7,,check=True,kernel_size=16,thr=0.1', num_fewshot=None, batch_size='1', max_batch_size=None, device=None, output_path=None, limit=0.5, topp=1.1, topk=64, spr=0.25, sink=8, local=256, use_cache=None, cache_requests=None, check_integrity=False, write_out=False, log_samples=False, show_config=False, include_path=None, gen_kwargs=None, verbosity='INFO', wandb_args='', predict_only=False, seed=[0, 1234, 1234], trust_remote_code=False)
Namespace(model='xhf', tasks='gsm8k', model_args='pretrained=meta-llama/Meta-Llama-3-8B-Instruct,cats=True,spr=0.7,,check=True,kernel_size=16,thr=0.1', num_fewshot=None, batch_size='1', max_batch_size=None, device=None, output_path=None, limit=0.5, topp=1.1, topk=64, spr=0.25, sink=8, local=256, use_cache=None, cache_requests=None, check_integrity=False, write_out=False, log_samples=False, show_config=False, include_path=None, gen_kwargs=None, verbosity='INFO', wandb_args='', predict_only=False, seed=[0, 1234, 1234], trust_remote_code=False)
Namespace(model='xhf', tasks='gsm8k', model_args='pretrained=meta-llama/Meta-Llama-3-8B-Instruct,cats=True,spr=0.7,,check=True,kernel_size=16,thr=0.1', num_fewshot=None, batch_size='1', max_batch_size=None, device=None, output_path=None, limit=0.5, topp=1.1, topk=64, spr=0.25, sink=8, local=256, use_cache=None, cache_requests=None, check_integrity=False, write_out=False, log_samples=False, show_config=False, include_path=None, gen_kwargs=None, verbosity='INFO', wandb_args='', predict_only=False, seed=[0, 1234, 1234], trust_remote_code=False)
Namespace(model='xhf', tasks='gsm8k', model_args='pretrained=meta-llama/Meta-Llama-3-8B-Instruct,cats=True,spr=0.7,,check=True,kernel_size=16,thr=0.1', num_fewshot=None, batch_size='1', max_batch_size=None, device=None, output_path=None, limit=0.5, topp=1.1, topk=64, spr=0.25, sink=8, local=256, use_cache=None, cache_requests=None, check_integrity=False, write_out=False, log_samples=False, show_config=False, include_path=None, gen_kwargs=None, verbosity='INFO', wandb_args='', predict_only=False, seed=[0, 1234, 1234], trust_remote_code=False)
7106 445 15.968539325842697
7859 495 15.876767676767678
7521 474 15.867088607594937
6558 412 15.91747572815534
7448 468 15.914529914529915
8208 515 15.937864077669904
7861 494 15.912955465587045
8172 516 15.837209302325581
xhf (pretrained=meta-llama/Meta-Llama-3-8B-Instruct,cats=True,spr=0.7,,check=True,kernel_size=16,thr=0.1), gen_kwargs: (None), limit: 0.5, num_fewshot: None, batch_size: 1
|Tasks|Version|     Filter     |n-shot|  Metric   |Value |   |Stderr|
|-----|------:|----------------|-----:|-----------|-----:|---|-----:|
|gsm8k|      3|strict-match    |     5|exact_match|0.7364|±  |0.0172|
|     |       |flexible-extract|     5|exact_match|0.7424|±  |0.0170|

Namespace(model='xhf', tasks='gsm8k', model_args='pretrained=meta-llama/Meta-Llama-3-8B-Instruct,cats=True,spr=0.8,,check=True,kernel_size=16,thr=0.1', num_fewshot=None, batch_size='1', max_batch_size=None, device=None, output_path=None, limit=0.5, topp=1.1, topk=64, spr=0.25, sink=8, local=256, use_cache=None, cache_requests=None, check_integrity=False, write_out=False, log_samples=False, show_config=False, include_path=None, gen_kwargs=None, verbosity='INFO', wandb_args='', predict_only=False, seed=[0, 1234, 1234], trust_remote_code=False)
Namespace(model='xhf', tasks='gsm8k', model_args='pretrained=meta-llama/Meta-Llama-3-8B-Instruct,cats=True,spr=0.8,,check=True,kernel_size=16,thr=0.1', num_fewshot=None, batch_size='1', max_batch_size=None, device=None, output_path=None, limit=0.5, topp=1.1, topk=64, spr=0.25, sink=8, local=256, use_cache=None, cache_requests=None, check_integrity=False, write_out=False, log_samples=False, show_config=False, include_path=None, gen_kwargs=None, verbosity='INFO', wandb_args='', predict_only=False, seed=[0, 1234, 1234], trust_remote_code=False)
Namespace(model='xhf', tasks='gsm8k', model_args='pretrained=meta-llama/Meta-Llama-3-8B-Instruct,cats=True,spr=0.8,,check=True,kernel_size=16,thr=0.1', num_fewshot=None, batch_size='1', max_batch_size=None, device=None, output_path=None, limit=0.5, topp=1.1, topk=64, spr=0.25, sink=8, local=256, use_cache=None, cache_requests=None, check_integrity=False, write_out=False, log_samples=False, show_config=False, include_path=None, gen_kwargs=None, verbosity='INFO', wandb_args='', predict_only=False, seed=[0, 1234, 1234], trust_remote_code=False)
Namespace(model='xhf', tasks='gsm8k', model_args='pretrained=meta-llama/Meta-Llama-3-8B-Instruct,cats=True,spr=0.8,,check=True,kernel_size=16,thr=0.1', num_fewshot=None, batch_size='1', max_batch_size=None, device=None, output_path=None, limit=0.5, topp=1.1, topk=64, spr=0.25, sink=8, local=256, use_cache=None, cache_requests=None, check_integrity=False, write_out=False, log_samples=False, show_config=False, include_path=None, gen_kwargs=None, verbosity='INFO', wandb_args='', predict_only=False, seed=[0, 1234, 1234], trust_remote_code=False)
Namespace(model='xhf', tasks='gsm8k', model_args='pretrained=meta-llama/Meta-Llama-3-8B-Instruct,cats=True,spr=0.8,,check=True,kernel_size=16,thr=0.1', num_fewshot=None, batch_size='1', max_batch_size=None, device=None, output_path=None, limit=0.5, topp=1.1, topk=64, spr=0.25, sink=8, local=256, use_cache=None, cache_requests=None, check_integrity=False, write_out=False, log_samples=False, show_config=False, include_path=None, gen_kwargs=None, verbosity='INFO', wandb_args='', predict_only=False, seed=[0, 1234, 1234], trust_remote_code=False)
Namespace(model='xhf', tasks='gsm8k', model_args='pretrained=meta-llama/Meta-Llama-3-8B-Instruct,cats=True,spr=0.8,,check=True,kernel_size=16,thr=0.1', num_fewshot=None, batch_size='1', max_batch_size=None, device=None, output_path=None, limit=0.5, topp=1.1, topk=64, spr=0.25, sink=8, local=256, use_cache=None, cache_requests=None, check_integrity=False, write_out=False, log_samples=False, show_config=False, include_path=None, gen_kwargs=None, verbosity='INFO', wandb_args='', predict_only=False, seed=[0, 1234, 1234], trust_remote_code=False)
Namespace(model='xhf', tasks='gsm8k', model_args='pretrained=meta-llama/Meta-Llama-3-8B-Instruct,cats=True,spr=0.8,,check=True,kernel_size=16,thr=0.1', num_fewshot=None, batch_size='1', max_batch_size=None, device=None, output_path=None, limit=0.5, topp=1.1, topk=64, spr=0.25, sink=8, local=256, use_cache=None, cache_requests=None, check_integrity=False, write_out=False, log_samples=False, show_config=False, include_path=None, gen_kwargs=None, verbosity='INFO', wandb_args='', predict_only=False, seed=[0, 1234, 1234], trust_remote_code=False)
Namespace(model='xhf', tasks='gsm8k', model_args='pretrained=meta-llama/Meta-Llama-3-8B-Instruct,cats=True,spr=0.8,,check=True,kernel_size=16,thr=0.1', num_fewshot=None, batch_size='1', max_batch_size=None, device=None, output_path=None, limit=0.5, topp=1.1, topk=64, spr=0.25, sink=8, local=256, use_cache=None, cache_requests=None, check_integrity=False, write_out=False, log_samples=False, show_config=False, include_path=None, gen_kwargs=None, verbosity='INFO', wandb_args='', predict_only=False, seed=[0, 1234, 1234], trust_remote_code=False)
6736 421 16.0
7328 458 16.0
7456 466 16.0
7750 485 15.97938144329897
8131 509 15.974459724950885
8166 511 15.980430528375734
8176 511 16.0
7445 467 15.942184154175589
xhf (pretrained=meta-llama/Meta-Llama-3-8B-Instruct,cats=True,spr=0.8,,check=True,kernel_size=16,thr=0.1), gen_kwargs: (None), limit: 0.5, num_fewshot: None, batch_size: 1
|Tasks|Version|     Filter     |n-shot|  Metric   |Value |   |Stderr|
|-----|------:|----------------|-----:|-----------|-----:|---|-----:|
|gsm8k|      3|strict-match    |     5|exact_match|0.7455|±  |0.0170|
|     |       |flexible-extract|     5|exact_match|0.7470|±  |0.0169|

Namespace(model='xhf', tasks='gsm8k', model_args='pretrained=meta-llama/Meta-Llama-3-8B-Instruct,cats=True,spr=0.9,check=True,kernel_size=16,thr=0.1', num_fewshot=None, batch_size='1', max_batch_size=None, device=None, output_path=None, limit=0.5, topp=1.1, topk=64, spr=0.25, sink=8, local=256, use_cache=None, cache_requests=None, check_integrity=False, write_out=False, log_samples=False, show_config=False, include_path=None, gen_kwargs=None, verbosity='INFO', wandb_args='', predict_only=False, seed=[0, 1234, 1234], trust_remote_code=False)
Namespace(model='xhf', tasks='gsm8k', model_args='pretrained=meta-llama/Meta-Llama-3-8B-Instruct,cats=True,spr=0.9,check=True,kernel_size=16,thr=0.1', num_fewshot=None, batch_size='1', max_batch_size=None, device=None, output_path=None, limit=0.5, topp=1.1, topk=64, spr=0.25, sink=8, local=256, use_cache=None, cache_requests=None, check_integrity=False, write_out=False, log_samples=False, show_config=False, include_path=None, gen_kwargs=None, verbosity='INFO', wandb_args='', predict_only=False, seed=[0, 1234, 1234], trust_remote_code=False)
Namespace(model='xhf', tasks='gsm8k', model_args='pretrained=meta-llama/Meta-Llama-3-8B-Instruct,cats=True,spr=0.9,check=True,kernel_size=16,thr=0.1', num_fewshot=None, batch_size='1', max_batch_size=None, device=None, output_path=None, limit=0.5, topp=1.1, topk=64, spr=0.25, sink=8, local=256, use_cache=None, cache_requests=None, check_integrity=False, write_out=False, log_samples=False, show_config=False, include_path=None, gen_kwargs=None, verbosity='INFO', wandb_args='', predict_only=False, seed=[0, 1234, 1234], trust_remote_code=False)
Namespace(model='xhf', tasks='gsm8k', model_args='pretrained=meta-llama/Meta-Llama-3-8B-Instruct,cats=True,spr=0.9,check=True,kernel_size=16,thr=0.1', num_fewshot=None, batch_size='1', max_batch_size=None, device=None, output_path=None, limit=0.5, topp=1.1, topk=64, spr=0.25, sink=8, local=256, use_cache=None, cache_requests=None, check_integrity=False, write_out=False, log_samples=False, show_config=False, include_path=None, gen_kwargs=None, verbosity='INFO', wandb_args='', predict_only=False, seed=[0, 1234, 1234], trust_remote_code=False)
Namespace(model='xhf', tasks='gsm8k', model_args='pretrained=meta-llama/Meta-Llama-3-8B-Instruct,cats=True,spr=0.9,check=True,kernel_size=16,thr=0.1', num_fewshot=None, batch_size='1', max_batch_size=None, device=None, output_path=None, limit=0.5, topp=1.1, topk=64, spr=0.25, sink=8, local=256, use_cache=None, cache_requests=None, check_integrity=False, write_out=False, log_samples=False, show_config=False, include_path=None, gen_kwargs=None, verbosity='INFO', wandb_args='', predict_only=False, seed=[0, 1234, 1234], trust_remote_code=False)
Namespace(model='xhf', tasks='gsm8k', model_args='pretrained=meta-llama/Meta-Llama-3-8B-Instruct,cats=True,spr=0.9,check=True,kernel_size=16,thr=0.1', num_fewshot=None, batch_size='1', max_batch_size=None, device=None, output_path=None, limit=0.5, topp=1.1, topk=64, spr=0.25, sink=8, local=256, use_cache=None, cache_requests=None, check_integrity=False, write_out=False, log_samples=False, show_config=False, include_path=None, gen_kwargs=None, verbosity='INFO', wandb_args='', predict_only=False, seed=[0, 1234, 1234], trust_remote_code=False)
Namespace(model='xhf', tasks='gsm8k', model_args='pretrained=meta-llama/Meta-Llama-3-8B-Instruct,cats=True,spr=0.9,check=True,kernel_size=16,thr=0.1', num_fewshot=None, batch_size='1', max_batch_size=None, device=None, output_path=None, limit=0.5, topp=1.1, topk=64, spr=0.25, sink=8, local=256, use_cache=None, cache_requests=None, check_integrity=False, write_out=False, log_samples=False, show_config=False, include_path=None, gen_kwargs=None, verbosity='INFO', wandb_args='', predict_only=False, seed=[0, 1234, 1234], trust_remote_code=False)
Namespace(model='xhf', tasks='gsm8k', model_args='pretrained=meta-llama/Meta-Llama-3-8B-Instruct,cats=True,spr=0.9,check=True,kernel_size=16,thr=0.1', num_fewshot=None, batch_size='1', max_batch_size=None, device=None, output_path=None, limit=0.5, topp=1.1, topk=64, spr=0.25, sink=8, local=256, use_cache=None, cache_requests=None, check_integrity=False, write_out=False, log_samples=False, show_config=False, include_path=None, gen_kwargs=None, verbosity='INFO', wandb_args='', predict_only=False, seed=[0, 1234, 1234], trust_remote_code=False)
7904 494 16.0
6960 435 16.0
7472 467 16.0
6528 408 16.0
7360 460 16.0
7680 480 16.0
8048 503 16.0
8144 509 16.0
xhf (pretrained=meta-llama/Meta-Llama-3-8B-Instruct,cats=True,spr=0.9,check=True,kernel_size=16,thr=0.1), gen_kwargs: (None), limit: 0.5, num_fewshot: None, batch_size: 1
|Tasks|Version|     Filter     |n-shot|  Metric   |Value |   |Stderr|
|-----|------:|----------------|-----:|-----------|-----:|---|-----:|
|gsm8k|      3|strict-match    |     5|exact_match|0.7530|±  |0.0168|
|     |       |flexible-extract|     5|exact_match|0.7545|±  |0.0168|

