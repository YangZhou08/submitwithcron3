Already on 'yangexp2'
wandb: Currently logged in as: stevenzhou0816100. Use `wandb login --relogin` to force relogin
Traceback (most recent call last):
  File "/private/home/beidic/.conda/envs/griffin/bin/huggingface-cli", line 8, in <module>
    sys.exit(main())
             ^^^^^^
  File "/private/home/beidic/.conda/envs/griffin/lib/python3.12/site-packages/huggingface_hub/commands/huggingface_cli.py", line 51, in main
    service.run()
  File "/private/home/beidic/.conda/envs/griffin/lib/python3.12/site-packages/huggingface_hub/commands/user.py", line 98, in run
    login(token=self.args.token, add_to_git_credential=self.args.add_to_git_credential)
  File "/private/home/beidic/.conda/envs/griffin/lib/python3.12/site-packages/huggingface_hub/_login.py", line 111, in login
    _login(token, add_to_git_credential=add_to_git_credential, write_permission=write_permission)
  File "/private/home/beidic/.conda/envs/griffin/lib/python3.12/site-packages/huggingface_hub/_login.py", line 307, in _login
    raise ValueError("Invalid token passed!")
ValueError: Invalid token passed!
The following values were not passed to `accelerate launch` and had defaults used instead:
		More than one GPU was found, enabling multi-GPU training.
		If this was unintended please pass in `--num_processes=1`.
	`--mixed_precision` was set to a value of `'no'`
	`--dynamo_backend` was set to a value of `'no'`
To avoid this warning pass in values for each of the problematic parameters or run `accelerate config`.
2024-06-03:15:06:58,179 INFO     [main.py:288] Verbosity set to INFO
2024-06-03:15:06:58,180 INFO     [main.py:288] Verbosity set to INFO
2024-06-03:15:06:58,180 INFO     [main.py:288] Verbosity set to INFO
2024-06-03:15:06:58,180 INFO     [main.py:288] Verbosity set to INFO
2024-06-03:15:06:58,229 INFO     [main.py:288] Verbosity set to INFO
2024-06-03:15:06:58,393 INFO     [main.py:288] Verbosity set to INFO
2024-06-03:15:06:58,404 INFO     [main.py:288] Verbosity set to INFO
2024-06-03:15:06:58,586 INFO     [main.py:288] Verbosity set to INFO
2024-06-03:15:07:03,361 INFO     [main.py:378] Selected Tasks: ['gsm8k']
2024-06-03:15:07:03,367 INFO     [xevaluator.py:137] Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234
2024-06-03:15:07:03,367 INFO     [xevaluator.py:184] Initializing xhf model, with arguments: {'pretrained': 'meta-llama/Meta-Llama-3-8B', 'griffin': True, 'check': True, 'kernel_size': 16, 'spr': 0.5, 'thr': 0.1}
2024-06-03:15:07:03,420 INFO     [main.py:378] Selected Tasks: ['gsm8k']
2024-06-03:15:07:03,424 INFO     [xevaluator.py:137] Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234
2024-06-03:15:07:03,425 INFO     [xevaluator.py:184] Initializing xhf model, with arguments: {'pretrained': 'meta-llama/Meta-Llama-3-8B', 'griffin': True, 'check': True, 'kernel_size': 16, 'spr': 0.5, 'thr': 0.1}
2024-06-03:15:07:03,557 INFO     [main.py:378] Selected Tasks: ['gsm8k']
2024-06-03:15:07:03,562 INFO     [xevaluator.py:137] Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234
2024-06-03:15:07:03,562 INFO     [xevaluator.py:184] Initializing xhf model, with arguments: {'pretrained': 'meta-llama/Meta-Llama-3-8B', 'griffin': True, 'check': True, 'kernel_size': 16, 'spr': 0.5, 'thr': 0.1}
2024-06-03:15:07:04,839 INFO     [main.py:378] Selected Tasks: ['gsm8k']
2024-06-03:15:07:04,844 INFO     [xevaluator.py:137] Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234
2024-06-03:15:07:04,844 INFO     [xevaluator.py:184] Initializing xhf model, with arguments: {'pretrained': 'meta-llama/Meta-Llama-3-8B', 'griffin': True, 'check': True, 'kernel_size': 16, 'spr': 0.5, 'thr': 0.1}
2024-06-03:15:07:04,965 INFO     [main.py:378] Selected Tasks: ['gsm8k']
2024-06-03:15:07:04,971 INFO     [xevaluator.py:137] Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234
2024-06-03:15:07:04,971 INFO     [xevaluator.py:184] Initializing xhf model, with arguments: {'pretrained': 'meta-llama/Meta-Llama-3-8B', 'griffin': True, 'check': True, 'kernel_size': 16, 'spr': 0.5, 'thr': 0.1}
2024-06-03:15:07:05,088 INFO     [main.py:378] Selected Tasks: ['gsm8k']
2024-06-03:15:07:05,094 INFO     [xevaluator.py:137] Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234
2024-06-03:15:07:05,094 INFO     [xevaluator.py:184] Initializing xhf model, with arguments: {'pretrained': 'meta-llama/Meta-Llama-3-8B', 'griffin': True, 'check': True, 'kernel_size': 16, 'spr': 0.5, 'thr': 0.1}
2024-06-03:15:07:05,278 INFO     [main.py:378] Selected Tasks: ['gsm8k']
2024-06-03:15:07:05,282 INFO     [xevaluator.py:137] Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234
2024-06-03:15:07:05,283 INFO     [xevaluator.py:184] Initializing xhf model, with arguments: {'pretrained': 'meta-llama/Meta-Llama-3-8B', 'griffin': True, 'check': True, 'kernel_size': 16, 'spr': 0.5, 'thr': 0.1}
2024-06-03:15:07:05,418 INFO     [main.py:378] Selected Tasks: ['gsm8k']
2024-06-03:15:07:05,422 INFO     [xevaluator.py:137] Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234
2024-06-03:15:07:05,422 INFO     [xevaluator.py:184] Initializing xhf model, with arguments: {'pretrained': 'meta-llama/Meta-Llama-3-8B', 'griffin': True, 'check': True, 'kernel_size': 16, 'spr': 0.5, 'thr': 0.1}
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:  25%|██▌       | 1/4 [00:23<01:09, 23.16s/it]Loading checkpoint shards:  25%|██▌       | 1/4 [00:26<01:19, 26.39s/it]Loading checkpoint shards:  25%|██▌       | 1/4 [00:24<01:13, 24.59s/it]Loading checkpoint shards:  25%|██▌       | 1/4 [00:26<01:19, 26.44s/it]Loading checkpoint shards:  25%|██▌       | 1/4 [00:26<01:19, 26.43s/it]Loading checkpoint shards:  25%|██▌       | 1/4 [00:24<01:14, 24.97s/it]Loading checkpoint shards:  25%|██▌       | 1/4 [00:25<01:15, 25.14s/it]Loading checkpoint shards:  25%|██▌       | 1/4 [00:25<01:16, 25.40s/it]Loading checkpoint shards:  50%|█████     | 2/4 [00:50<00:50, 25.15s/it]Loading checkpoint shards:  50%|█████     | 2/4 [00:53<00:53, 26.63s/it]Loading checkpoint shards:  50%|█████     | 2/4 [00:53<00:53, 26.65s/it]Loading checkpoint shards:  50%|█████     | 2/4 [00:53<00:53, 26.64s/it]Loading checkpoint shards:  50%|█████     | 2/4 [00:51<00:51, 25.92s/it]Loading checkpoint shards:  50%|█████     | 2/4 [00:51<00:52, 26.09s/it]Loading checkpoint shards:  50%|█████     | 2/4 [00:52<00:52, 26.16s/it]Loading checkpoint shards:  50%|█████     | 2/4 [00:51<00:52, 26.16s/it]Loading checkpoint shards:  75%|███████▌  | 3/4 [01:15<00:24, 24.67s/it]Loading checkpoint shards:  75%|███████▌  | 3/4 [01:16<00:25, 25.17s/it]Loading checkpoint shards:  75%|███████▌  | 3/4 [01:16<00:25, 25.15s/it]Loading checkpoint shards:  75%|███████▌  | 3/4 [01:15<00:24, 24.89s/it]Loading checkpoint shards:  75%|███████▌  | 3/4 [01:14<00:24, 24.90s/it]Loading checkpoint shards:  75%|███████▌  | 3/4 [01:15<00:25, 25.08s/it]Loading checkpoint shards:  75%|███████▌  | 3/4 [01:14<00:24, 24.79s/it]Loading checkpoint shards:  75%|███████▌  | 3/4 [01:15<00:24, 24.91s/it]Loading checkpoint shards: 100%|██████████| 4/4 [01:19<00:00, 16.76s/it]Loading checkpoint shards: 100%|██████████| 4/4 [01:19<00:00, 19.82s/it]
Loading checkpoint shards: 100%|██████████| 4/4 [01:20<00:00, 16.91s/it]Loading checkpoint shards: 100%|██████████| 4/4 [01:20<00:00, 20.23s/it]
Loading checkpoint shards: 100%|██████████| 4/4 [01:20<00:00, 16.91s/it]Loading checkpoint shards: 100%|██████████| 4/4 [01:20<00:00, 20.22s/it]
Loading checkpoint shards: 100%|██████████| 4/4 [01:19<00:00, 16.73s/it]Loading checkpoint shards: 100%|██████████| 4/4 [01:19<00:00, 19.76s/it]
Loading checkpoint shards: 100%|██████████| 4/4 [01:19<00:00, 16.75s/it]Loading checkpoint shards: 100%|██████████| 4/4 [01:19<00:00, 19.94s/it]
Loading checkpoint shards: 100%|██████████| 4/4 [01:19<00:00, 16.72s/it]Loading checkpoint shards: 100%|██████████| 4/4 [01:19<00:00, 19.89s/it]
Loading checkpoint shards: 100%|██████████| 4/4 [01:19<00:00, 16.67s/it]Loading checkpoint shards: 100%|██████████| 4/4 [01:19<00:00, 19.78s/it]
Loading checkpoint shards: 100%|██████████| 4/4 [01:20<00:00, 17.06s/it]Loading checkpoint shards: 100%|██████████| 4/4 [01:20<00:00, 20.23s/it]
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
Using the latest cached version of the dataset since gsm8k couldn't be found on the Hugging Face Hub
2024-06-03:15:09:04,657 WARNING  [load.py:1631] Using the latest cached version of the dataset since gsm8k couldn't be found on the Hugging Face Hub
Found the latest cached dataset configuration 'main' at /private/home/beidic/.cache/huggingface/datasets/gsm8k/main/0.0.0/e53f048856ff4f594e959d75785d2c2d37b678ee (last modified on Thu May 16 07:01:08 2024).
2024-06-03:15:09:04,659 WARNING  [cache.py:95] Found the latest cached dataset configuration 'main' at /private/home/beidic/.cache/huggingface/datasets/gsm8k/main/0.0.0/e53f048856ff4f594e959d75785d2c2d37b678ee (last modified on Thu May 16 07:01:08 2024).
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
2024-06-03:15:09:04,929 INFO     [task.py:395] Building contexts for gsm8k on rank 3...
  0%|          | 0/165 [00:00<?, ?it/s] 13%|█▎        | 21/165 [00:00<00:00, 207.64it/s]Using the latest cached version of the dataset since gsm8k couldn't be found on the Hugging Face Hub
2024-06-03:15:09:05,077 WARNING  [load.py:1631] Using the latest cached version of the dataset since gsm8k couldn't be found on the Hugging Face Hub
Found the latest cached dataset configuration 'main' at /private/home/beidic/.cache/huggingface/datasets/gsm8k/main/0.0.0/e53f048856ff4f594e959d75785d2c2d37b678ee (last modified on Thu May 16 07:01:08 2024).
2024-06-03:15:09:05,079 WARNING  [cache.py:95] Found the latest cached dataset configuration 'main' at /private/home/beidic/.cache/huggingface/datasets/gsm8k/main/0.0.0/e53f048856ff4f594e959d75785d2c2d37b678ee (last modified on Thu May 16 07:01:08 2024).
 25%|██▌       | 42/165 [00:00<00:00, 171.76it/s] 36%|███▋      | 60/165 [00:00<00:00, 156.01it/s] 46%|████▌     | 76/165 [00:00<00:00, 149.46it/s]2024-06-03:15:09:05,446 INFO     [task.py:395] Building contexts for gsm8k on rank 4...
  0%|          | 0/165 [00:00<?, ?it/s] 56%|█████▌    | 92/165 [00:00<00:00, 145.00it/s]  8%|▊         | 14/165 [00:00<00:01, 134.84it/s] 65%|██████▍   | 107/165 [00:00<00:00, 142.01it/s] 17%|█▋        | 28/165 [00:00<00:01, 135.14it/s] 74%|███████▍  | 122/165 [00:00<00:00, 139.92it/s] 25%|██▌       | 42/165 [00:00<00:00, 135.39it/s] 83%|████████▎ | 137/165 [00:00<00:00, 138.30it/s] 34%|███▍      | 56/165 [00:00<00:00, 135.25it/s] 92%|█████████▏| 151/165 [00:01<00:00, 137.42it/s] 42%|████▏     | 70/165 [00:00<00:00, 135.19it/s]100%|██████████| 165/165 [00:01<00:00, 137.00it/s]100%|██████████| 165/165 [00:01<00:00, 144.73it/s]
 52%|█████▏    | 86/165 [00:00<00:00, 141.27it/s] 65%|██████▍   | 107/165 [00:00<00:00, 162.48it/s] 78%|███████▊  | 128/165 [00:00<00:00, 176.59it/s] 90%|████████▉ | 148/165 [00:00<00:00, 182.76it/s]100%|██████████| 165/165 [00:01<00:00, 162.68it/s]
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
Using the latest cached version of the dataset since gsm8k couldn't be found on the Hugging Face Hub
2024-06-03:15:09:19,343 WARNING  [load.py:1631] Using the latest cached version of the dataset since gsm8k couldn't be found on the Hugging Face Hub
Found the latest cached dataset configuration 'main' at /private/home/beidic/.cache/huggingface/datasets/gsm8k/main/0.0.0/e53f048856ff4f594e959d75785d2c2d37b678ee (last modified on Thu May 16 07:01:08 2024).
2024-06-03:15:09:19,345 WARNING  [cache.py:95] Found the latest cached dataset configuration 'main' at /private/home/beidic/.cache/huggingface/datasets/gsm8k/main/0.0.0/e53f048856ff4f594e959d75785d2c2d37b678ee (last modified on Thu May 16 07:01:08 2024).
Using the latest cached version of the dataset since gsm8k couldn't be found on the Hugging Face Hub
2024-06-03:15:09:19,363 WARNING  [load.py:1631] Using the latest cached version of the dataset since gsm8k couldn't be found on the Hugging Face Hub
Found the latest cached dataset configuration 'main' at /private/home/beidic/.cache/huggingface/datasets/gsm8k/main/0.0.0/e53f048856ff4f594e959d75785d2c2d37b678ee (last modified on Thu May 16 07:01:08 2024).
2024-06-03:15:09:19,365 WARNING  [cache.py:95] Found the latest cached dataset configuration 'main' at /private/home/beidic/.cache/huggingface/datasets/gsm8k/main/0.0.0/e53f048856ff4f594e959d75785d2c2d37b678ee (last modified on Thu May 16 07:01:08 2024).
2024-06-03:15:09:19,509 INFO     [task.py:395] Building contexts for gsm8k on rank 6...
  0%|          | 0/165 [00:00<?, ?it/s]2024-06-03:15:09:19,552 INFO     [task.py:395] Building contexts for gsm8k on rank 1...
  0%|          | 0/165 [00:00<?, ?it/s] 13%|█▎        | 22/165 [00:00<00:00, 213.83it/s] 13%|█▎        | 22/165 [00:00<00:00, 215.63it/s] 27%|██▋       | 44/165 [00:00<00:00, 215.25it/s] 27%|██▋       | 44/165 [00:00<00:00, 215.85it/s] 40%|████      | 66/165 [00:00<00:00, 215.61it/s] 40%|████      | 66/165 [00:00<00:00, 216.23it/s] 53%|█████▎    | 88/165 [00:00<00:00, 215.98it/s] 53%|█████▎    | 88/165 [00:00<00:00, 216.38it/s] 67%|██████▋   | 110/165 [00:00<00:00, 216.12it/s] 67%|██████▋   | 110/165 [00:00<00:00, 215.78it/s] 80%|████████  | 132/165 [00:00<00:00, 215.86it/s] 80%|████████  | 132/165 [00:00<00:00, 216.04it/s] 93%|█████████▎| 154/165 [00:00<00:00, 216.63it/s] 93%|█████████▎| 154/165 [00:00<00:00, 216.39it/s]100%|██████████| 165/165 [00:00<00:00, 216.21it/s]
100%|██████████| 165/165 [00:00<00:00, 216.22it/s]
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
2024-06-03:15:09:28,169 INFO     [xhuggingface.py:314] Using 8 devices with data parallelism
Using the latest cached version of the dataset since gsm8k couldn't be found on the Hugging Face Hub
2024-06-03:15:09:28,276 WARNING  [load.py:1631] Using the latest cached version of the dataset since gsm8k couldn't be found on the Hugging Face Hub
Found the latest cached dataset configuration 'main' at /private/home/beidic/.cache/huggingface/datasets/gsm8k/main/0.0.0/e53f048856ff4f594e959d75785d2c2d37b678ee (last modified on Thu May 16 07:01:08 2024).
2024-06-03:15:09:28,278 WARNING  [cache.py:95] Found the latest cached dataset configuration 'main' at /private/home/beidic/.cache/huggingface/datasets/gsm8k/main/0.0.0/e53f048856ff4f594e959d75785d2c2d37b678ee (last modified on Thu May 16 07:01:08 2024).
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
Using the latest cached version of the dataset since gsm8k couldn't be found on the Hugging Face Hub
2024-06-03:15:09:28,408 WARNING  [load.py:1631] Using the latest cached version of the dataset since gsm8k couldn't be found on the Hugging Face Hub
Found the latest cached dataset configuration 'main' at /private/home/beidic/.cache/huggingface/datasets/gsm8k/main/0.0.0/e53f048856ff4f594e959d75785d2c2d37b678ee (last modified on Thu May 16 07:01:08 2024).
2024-06-03:15:09:28,409 WARNING  [cache.py:95] Found the latest cached dataset configuration 'main' at /private/home/beidic/.cache/huggingface/datasets/gsm8k/main/0.0.0/e53f048856ff4f594e959d75785d2c2d37b678ee (last modified on Thu May 16 07:01:08 2024).
2024-06-03:15:09:28,436 INFO     [task.py:395] Building contexts for gsm8k on rank 7...
  0%|          | 0/164 [00:00<?, ?it/s]Using the latest cached version of the dataset since gsm8k couldn't be found on the Hugging Face Hub
2024-06-03:15:09:28,543 WARNING  [load.py:1631] Using the latest cached version of the dataset since gsm8k couldn't be found on the Hugging Face Hub
Found the latest cached dataset configuration 'main' at /private/home/beidic/.cache/huggingface/datasets/gsm8k/main/0.0.0/e53f048856ff4f594e959d75785d2c2d37b678ee (last modified on Thu May 16 07:01:08 2024).
2024-06-03:15:09:28,545 WARNING  [cache.py:95] Found the latest cached dataset configuration 'main' at /private/home/beidic/.cache/huggingface/datasets/gsm8k/main/0.0.0/e53f048856ff4f594e959d75785d2c2d37b678ee (last modified on Thu May 16 07:01:08 2024).
 13%|█▎        | 21/164 [00:00<00:00, 205.90it/s]2024-06-03:15:09:28,561 INFO     [task.py:395] Building contexts for gsm8k on rank 0...
Using the latest cached version of the dataset since gsm8k couldn't be found on the Hugging Face Hub
2024-06-03:15:09:28,569 WARNING  [load.py:1631] Using the latest cached version of the dataset since gsm8k couldn't be found on the Hugging Face Hub
Found the latest cached dataset configuration 'main' at /private/home/beidic/.cache/huggingface/datasets/gsm8k/main/0.0.0/e53f048856ff4f594e959d75785d2c2d37b678ee (last modified on Thu May 16 07:01:08 2024).
2024-06-03:15:09:28,571 WARNING  [cache.py:95] Found the latest cached dataset configuration 'main' at /private/home/beidic/.cache/huggingface/datasets/gsm8k/main/0.0.0/e53f048856ff4f594e959d75785d2c2d37b678ee (last modified on Thu May 16 07:01:08 2024).
  0%|          | 0/165 [00:00<?, ?it/s]  8%|▊         | 14/165 [00:00<00:01, 137.89it/s] 26%|██▌       | 42/164 [00:00<00:00, 160.30it/s] 17%|█▋        | 28/165 [00:00<00:00, 137.63it/s]2024-06-03:15:09:28,828 INFO     [task.py:395] Building contexts for gsm8k on rank 2...
 36%|███▌      | 59/164 [00:00<00:00, 150.53it/s]2024-06-03:15:09:28,854 INFO     [task.py:395] Building contexts for gsm8k on rank 5...
  0%|          | 0/165 [00:00<?, ?it/s]  0%|          | 0/165 [00:00<?, ?it/s] 25%|██▌       | 42/165 [00:00<00:00, 137.72it/s] 46%|████▌     | 75/164 [00:00<00:00, 146.77it/s]  9%|▉         | 15/165 [00:00<00:01, 140.36it/s]  9%|▉         | 15/165 [00:00<00:01, 142.92it/s] 35%|███▍      | 57/165 [00:00<00:00, 140.07it/s] 55%|█████▍    | 90/164 [00:00<00:00, 144.98it/s] 18%|█▊        | 30/165 [00:00<00:00, 141.18it/s] 44%|████▎     | 72/165 [00:00<00:00, 140.89it/s] 18%|█▊        | 30/165 [00:00<00:00, 142.20it/s] 64%|██████▍   | 105/164 [00:00<00:00, 144.27it/s] 27%|██▋       | 45/165 [00:00<00:00, 142.14it/s] 27%|██▋       | 45/165 [00:00<00:00, 141.09it/s] 53%|█████▎    | 87/165 [00:00<00:00, 140.51it/s] 73%|███████▎  | 120/164 [00:00<00:00, 143.13it/s] 36%|███▋      | 60/165 [00:00<00:00, 141.72it/s] 36%|███▋      | 60/165 [00:00<00:00, 140.51it/s] 62%|██████▏   | 102/165 [00:00<00:00, 140.16it/s] 82%|████████▏ | 135/164 [00:00<00:00, 142.17it/s] 45%|████▌     | 75/165 [00:00<00:00, 141.05it/s] 45%|████▌     | 75/165 [00:00<00:00, 140.26it/s] 71%|███████   | 117/165 [00:00<00:00, 140.11it/s] 91%|█████████▏| 150/164 [00:01<00:00, 141.36it/s] 55%|█████▍    | 90/165 [00:00<00:00, 140.56it/s] 55%|█████▍    | 90/165 [00:00<00:00, 139.93it/s] 80%|████████  | 132/165 [00:00<00:00, 139.85it/s]100%|██████████| 164/164 [00:01<00:00, 145.99it/s]
 65%|██████▍   | 107/165 [00:00<00:00, 147.82it/s] 64%|██████▎   | 105/165 [00:00<00:00, 140.91it/s] 89%|████████▉ | 147/165 [00:01<00:00, 140.43it/s] 78%|███████▊  | 129/165 [00:00<00:00, 169.87it/s] 73%|███████▎  | 120/165 [00:00<00:00, 142.05it/s] 98%|█████████▊| 162/165 [00:01<00:00, 141.67it/s]100%|██████████| 165/165 [00:01<00:00, 140.45it/s]
 90%|█████████ | 149/165 [00:00<00:00, 176.87it/s] 82%|████████▏ | 136/165 [00:00<00:00, 144.99it/s]100%|██████████| 165/165 [00:01<00:00, 155.31it/s]
 92%|█████████▏| 151/165 [00:01<00:00, 142.32it/s]100%|██████████| 165/165 [00:01<00:00, 141.43it/s]
2024-06-03:15:09:34,496 INFO     [xevaluator.py:395] Running generate_until requests
2024-06-03:15:09:34,496 INFO     [xevaluator.py:395] Running generate_until requests
2024-06-03:15:09:34,496 INFO     [xevaluator.py:395] Running generate_until requests
2024-06-03:15:09:34,496 INFO     [xevaluator.py:395] Running generate_until requests
2024-06-03:15:09:34,496 INFO     [xevaluator.py:395] Running generate_until requests
2024-06-03:15:09:34,496 INFO     [xevaluator.py:395] Running generate_until requests
2024-06-03:15:09:34,496 INFO     [xevaluator.py:395] Running generate_until requests
Running generate_until requests:   0%|          | 0/165 [00:00<?, ?it/s]2024-06-03:15:09:34,496 INFO     [xevaluator.py:395] Running generate_until requests
Running generate_until requests:   1%|          | 1/165 [00:13<37:51, 13.85s/it]Running generate_until requests:   1%|          | 2/165 [00:22<28:58, 10.66s/it]Running generate_until requests:   2%|▏         | 3/165 [00:33<29:12, 10.82s/it]Running generate_until requests:   2%|▏         | 4/165 [00:45<30:26, 11.34s/it]Running generate_until requests:   3%|▎         | 5/165 [00:51<25:19,  9.49s/it]Running generate_until requests:   4%|▎         | 6/165 [01:02<26:39, 10.06s/it]Running generate_until requests:   4%|▍         | 7/165 [01:08<22:44,  8.63s/it]Running generate_until requests:   5%|▍         | 8/165 [01:16<22:00,  8.41s/it]Running generate_until requests:   5%|▌         | 9/165 [01:21<19:00,  7.31s/it]Running generate_until requests:   6%|▌         | 10/165 [01:28<18:46,  7.27s/it]Running generate_until requests:   7%|▋         | 11/165 [01:35<18:35,  7.24s/it]Running generate_until requests:   7%|▋         | 12/165 [01:45<20:23,  8.00s/it]Running generate_until requests:   8%|▊         | 13/165 [01:54<21:24,  8.45s/it]Running generate_until requests:   8%|▊         | 14/165 [02:09<25:51, 10.28s/it]Running generate_until requests:   9%|▉         | 15/165 [02:19<25:25, 10.17s/it]Running generate_until requests:  10%|▉         | 16/165 [02:27<23:49,  9.59s/it]Running generate_until requests:  10%|█         | 17/165 [02:45<29:42, 12.05s/it]Running generate_until requests:  11%|█         | 18/165 [02:56<28:59, 11.84s/it]Running generate_until requests:  12%|█▏        | 19/165 [03:03<25:29, 10.48s/it]Running generate_until requests:  12%|█▏        | 20/165 [03:10<22:06,  9.15s/it]Running generate_until requests:  13%|█▎        | 21/165 [03:23<25:24, 10.58s/it]Running generate_until requests:  13%|█▎        | 22/165 [03:32<23:53, 10.03s/it]Running generate_until requests:  14%|█▍        | 23/165 [03:37<20:15,  8.56s/it]Running generate_until requests:  15%|█▍        | 24/165 [03:50<22:58,  9.78s/it]Running generate_until requests:  15%|█▌        | 25/165 [03:59<22:26,  9.62s/it]Running generate_until requests:  16%|█▌        | 26/165 [04:07<21:07,  9.12s/it]Running generate_until requests:  16%|█▋        | 27/165 [04:16<21:01,  9.14s/it]Running generate_until requests:  17%|█▋        | 28/165 [04:21<17:45,  7.78s/it]Running generate_until requests:  18%|█▊        | 29/165 [04:32<19:41,  8.69s/it]Running generate_until requests:  18%|█▊        | 30/165 [04:38<17:36,  7.83s/it]Running generate_until requests:  19%|█▉        | 31/165 [04:45<17:18,  7.75s/it]Running generate_until requests:  19%|█▉        | 32/165 [04:55<18:42,  8.44s/it]Running generate_until requests:  20%|██        | 33/165 [05:01<16:49,  7.65s/it]Running generate_until requests:  21%|██        | 34/165 [05:18<22:55, 10.50s/it]Running generate_until requests:  21%|██        | 35/165 [05:31<24:03, 11.10s/it]Running generate_until requests:  22%|██▏       | 36/165 [05:36<19:57,  9.29s/it]Running generate_until requests:  22%|██▏       | 37/165 [05:44<18:51,  8.84s/it]Running generate_until requests:  23%|██▎       | 38/165 [05:52<18:41,  8.83s/it]Running generate_until requests:  24%|██▎       | 39/165 [06:02<19:14,  9.16s/it]Running generate_until requests:  24%|██▍       | 40/165 [06:10<18:12,  8.74s/it]Running generate_until requests:  25%|██▍       | 41/165 [06:16<16:24,  7.94s/it]Running generate_until requests:  25%|██▌       | 42/165 [06:26<17:17,  8.43s/it]Running generate_until requests:  26%|██▌       | 43/165 [06:37<18:43,  9.21s/it]Running generate_until requests:  27%|██▋       | 44/165 [06:51<21:32, 10.68s/it]Running generate_until requests:  27%|██▋       | 45/165 [06:57<18:46,  9.39s/it]Running generate_until requests:  28%|██▊       | 46/165 [07:16<23:56, 12.07s/it]Running generate_until requests:  28%|██▊       | 47/165 [07:21<20:08, 10.24s/it]Running generate_until requests:  29%|██▉       | 48/165 [07:32<20:06, 10.31s/it]Running generate_until requests:  30%|██▉       | 49/165 [07:42<19:50, 10.26s/it]Running generate_until requests:  30%|███       | 50/165 [07:50<18:16,  9.53s/it]Running generate_until requests:  31%|███       | 51/165 [08:01<18:59, 10.00s/it]Running generate_until requests:  32%|███▏      | 52/165 [08:05<15:27,  8.21s/it]Running generate_until requests:  32%|███▏      | 53/165 [08:20<19:08, 10.25s/it]Running generate_until requests:  33%|███▎      | 54/165 [08:28<17:26,  9.42s/it]Running generate_until requests:  33%|███▎      | 55/165 [08:35<16:17,  8.88s/it]Running generate_until requests:  34%|███▍      | 56/165 [08:41<14:24,  7.93s/it]Running generate_until requests:  35%|███▍      | 57/165 [08:49<14:17,  7.94s/it]Running generate_until requests:  35%|███▌      | 58/165 [08:55<13:21,  7.50s/it]Running generate_until requests:  36%|███▌      | 59/165 [09:12<18:06, 10.25s/it]Running generate_until requests:  36%|███▋      | 60/165 [09:17<15:04,  8.62s/it]Running generate_until requests:  37%|███▋      | 61/165 [09:32<18:16, 10.54s/it]Running generate_until requests:  38%|███▊      | 62/165 [09:41<17:22, 10.13s/it]Running generate_until requests:  38%|███▊      | 63/165 [09:51<17:05, 10.05s/it]Running generate_until requests:  39%|███▉      | 64/165 [09:58<15:19,  9.11s/it]Running generate_until requests:  39%|███▉      | 65/165 [10:04<13:34,  8.14s/it]Running generate_until requests:  40%|████      | 66/165 [10:09<12:02,  7.30s/it]Running generate_until requests:  41%|████      | 67/165 [10:17<12:27,  7.63s/it]Running generate_until requests:  41%|████      | 68/165 [10:24<11:58,  7.40s/it]Running generate_until requests:  42%|████▏     | 69/165 [10:38<14:57,  9.35s/it]Running generate_until requests:  42%|████▏     | 70/165 [10:43<12:42,  8.03s/it]Running generate_until requests:  43%|████▎     | 71/165 [10:50<12:07,  7.73s/it]Running generate_until requests:  44%|████▎     | 72/165 [11:00<12:56,  8.35s/it]Running generate_until requests:  44%|████▍     | 73/165 [11:18<17:27, 11.39s/it]Running generate_until requests:  45%|████▍     | 74/165 [11:39<21:14, 14.00s/it]Running generate_until requests:  45%|████▌     | 75/165 [11:46<18:06, 12.07s/it]Running generate_until requests:  46%|████▌     | 76/165 [11:53<15:31, 10.47s/it]Running generate_until requests:  47%|████▋     | 77/165 [12:02<14:47, 10.09s/it]Running generate_until requests:  47%|████▋     | 78/165 [12:13<15:05, 10.41s/it]Running generate_until requests:  48%|████▊     | 79/165 [12:20<13:14,  9.24s/it]Running generate_until requests:  48%|████▊     | 80/165 [12:25<11:32,  8.15s/it]Running generate_until requests:  49%|████▉     | 81/165 [12:33<11:19,  8.09s/it]Running generate_until requests:  50%|████▉     | 82/165 [12:45<12:31,  9.05s/it]Running generate_until requests:  50%|█████     | 83/165 [12:53<12:13,  8.94s/it]Running generate_until requests:  51%|█████     | 84/165 [13:12<15:58, 11.83s/it]Running generate_until requests:  52%|█████▏    | 85/165 [13:16<12:50,  9.63s/it]Running generate_until requests:  52%|█████▏    | 86/165 [13:21<10:51,  8.25s/it]Running generate_until requests:  53%|█████▎    | 87/165 [13:40<14:58, 11.52s/it]Running generate_until requests:  53%|█████▎    | 88/165 [13:45<12:01,  9.37s/it]Running generate_until requests:  54%|█████▍    | 89/165 [13:57<12:59, 10.26s/it]Running generate_until requests:  55%|█████▍    | 90/165 [14:04<11:28,  9.18s/it]Running generate_until requests:  55%|█████▌    | 91/165 [14:10<10:11,  8.26s/it]Running generate_until requests:  56%|█████▌    | 92/165 [14:18<10:06,  8.30s/it]Running generate_until requests:  56%|█████▋    | 93/165 [14:31<11:32,  9.62s/it]Running generate_until requests:  57%|█████▋    | 94/165 [14:37<10:03,  8.50s/it]Running generate_until requests:  58%|█████▊    | 95/165 [14:41<08:15,  7.08s/it]Running generate_until requests:  58%|█████▊    | 96/165 [14:46<07:39,  6.66s/it]Running generate_until requests:  59%|█████▉    | 97/165 [14:49<06:15,  5.53s/it]Running generate_until requests:  59%|█████▉    | 98/165 [14:58<07:10,  6.42s/it]Running generate_until requests:  60%|██████    | 99/165 [15:06<07:50,  7.13s/it]Running generate_until requests:  61%|██████    | 100/165 [15:15<08:03,  7.43s/it]Running generate_until requests:  61%|██████    | 101/165 [15:21<07:43,  7.24s/it]Running generate_until requests:  62%|██████▏   | 102/165 [15:39<10:48, 10.30s/it]Running generate_until requests:  62%|██████▏   | 103/165 [15:51<11:17, 10.93s/it]Running generate_until requests:  63%|██████▎   | 104/165 [15:57<09:32,  9.39s/it]Running generate_until requests:  64%|██████▎   | 105/165 [16:04<08:37,  8.63s/it]Running generate_until requests:  64%|██████▍   | 106/165 [16:10<07:37,  7.76s/it]Running generate_until requests:  65%|██████▍   | 107/165 [16:16<07:08,  7.39s/it]Running generate_until requests:  65%|██████▌   | 108/165 [16:22<06:36,  6.95s/it]Running generate_until requests:  66%|██████▌   | 109/165 [16:28<06:13,  6.67s/it]Running generate_until requests:  67%|██████▋   | 110/165 [16:38<06:55,  7.56s/it]Running generate_until requests:  67%|██████▋   | 111/165 [16:46<07:03,  7.84s/it]Running generate_until requests:  68%|██████▊   | 112/165 [16:53<06:34,  7.44s/it]Running generate_until requests:  68%|██████▊   | 113/165 [17:05<07:41,  8.87s/it]Running generate_until requests:  69%|██████▉   | 114/165 [17:10<06:33,  7.71s/it]Running generate_until requests:  70%|██████▉   | 115/165 [17:25<08:21, 10.04s/it]Running generate_until requests:  70%|███████   | 116/165 [17:34<07:55,  9.71s/it]Running generate_until requests:  71%|███████   | 117/165 [17:41<06:59,  8.75s/it]Running generate_until requests:  72%|███████▏  | 118/165 [17:48<06:31,  8.33s/it]Running generate_until requests:  72%|███████▏  | 119/165 [17:55<06:00,  7.84s/it]Running generate_until requests:  73%|███████▎  | 120/165 [18:01<05:34,  7.42s/it]Running generate_until requests:  73%|███████▎  | 121/165 [18:11<05:57,  8.11s/it]Running generate_until requests:  74%|███████▍  | 122/165 [18:23<06:42,  9.36s/it]Running generate_until requests:  75%|███████▍  | 123/165 [18:32<06:21,  9.09s/it]Running generate_until requests:  75%|███████▌  | 124/165 [18:36<05:08,  7.51s/it]Running generate_until requests:  76%|███████▌  | 125/165 [18:45<05:23,  8.08s/it]Running generate_until requests:  76%|███████▋  | 126/165 [18:50<04:38,  7.14s/it]Running generate_until requests:  77%|███████▋  | 127/165 [18:55<04:11,  6.61s/it]Running generate_until requests:  78%|███████▊  | 128/165 [19:01<03:54,  6.33s/it]Running generate_until requests:  78%|███████▊  | 129/165 [19:19<05:54,  9.85s/it]Running generate_until requests:  79%|███████▉  | 130/165 [19:28<05:34,  9.55s/it]Running generate_until requests:  79%|███████▉  | 131/165 [19:36<05:11,  9.15s/it]Running generate_until requests:  80%|████████  | 132/165 [19:43<04:36,  8.39s/it]Running generate_until requests:  81%|████████  | 133/165 [19:48<03:54,  7.32s/it]Running generate_until requests:  81%|████████  | 134/165 [19:58<04:14,  8.21s/it]Running generate_until requests:  82%|████████▏ | 135/165 [20:06<04:08,  8.30s/it]Running generate_until requests:  82%|████████▏ | 136/165 [20:11<03:28,  7.18s/it]Running generate_until requests:  83%|████████▎ | 137/165 [20:15<02:58,  6.36s/it]Running generate_until requests:  84%|████████▎ | 138/165 [20:26<03:23,  7.55s/it]Running generate_until requests:  84%|████████▍ | 139/165 [20:30<02:52,  6.65s/it]Running generate_until requests:  85%|████████▍ | 140/165 [20:40<03:06,  7.46s/it]Running generate_until requests:  85%|████████▌ | 141/165 [20:47<02:58,  7.43s/it]Running generate_until requests:  86%|████████▌ | 142/165 [20:57<03:05,  8.06s/it]Running generate_until requests:  87%|████████▋ | 143/165 [21:00<02:29,  6.78s/it]Running generate_until requests:  87%|████████▋ | 144/165 [21:11<02:44,  7.85s/it]Running generate_until requests:  88%|████████▊ | 145/165 [21:17<02:29,  7.46s/it]Running generate_until requests:  88%|████████▊ | 146/165 [21:21<02:00,  6.35s/it]Running generate_until requests:  89%|████████▉ | 147/165 [21:24<01:38,  5.45s/it]Running generate_until requests:  90%|████████▉ | 148/165 [21:31<01:38,  5.78s/it]Running generate_until requests:  90%|█████████ | 149/165 [21:39<01:45,  6.61s/it]Running generate_until requests:  91%|█████████ | 150/165 [21:44<01:30,  6.06s/it]Running generate_until requests:  92%|█████████▏| 151/165 [21:50<01:25,  6.11s/it]Running generate_until requests:  92%|█████████▏| 152/165 [21:55<01:13,  5.62s/it]Running generate_until requests:  93%|█████████▎| 153/165 [22:03<01:14,  6.25s/it]Running generate_until requests:  93%|█████████▎| 154/165 [22:24<01:57, 10.64s/it]Running generate_until requests:  94%|█████████▍| 155/165 [22:26<01:22,  8.27s/it]Running generate_until requests:  95%|█████████▍| 156/165 [22:30<01:01,  6.87s/it]Running generate_until requests:  95%|█████████▌| 157/165 [22:36<00:52,  6.53s/it]Running generate_until requests:  96%|█████████▌| 158/165 [22:43<00:47,  6.84s/it]Running generate_until requests:  96%|█████████▋| 159/165 [22:54<00:48,  8.01s/it]Running generate_until requests:  97%|█████████▋| 160/165 [22:58<00:34,  6.91s/it]Running generate_until requests:  98%|█████████▊| 161/165 [23:06<00:28,  7.04s/it]Running generate_until requests:  98%|█████████▊| 162/165 [23:22<00:29,  9.98s/it]Running generate_until requests:  99%|█████████▉| 163/165 [23:27<00:16,  8.39s/it]Running generate_until requests:  99%|█████████▉| 164/165 [23:32<00:07,  7.20s/it]Running generate_until requests: 100%|██████████| 165/165 [23:37<00:00,  6.64s/it]Running generate_until requests: 100%|██████████| 165/165 [23:37<00:00,  8.59s/it]
