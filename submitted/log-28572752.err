Already on 'yangexp2'
wandb: Currently logged in as: stevenzhou0816100. Use `wandb login --relogin` to force relogin
Traceback (most recent call last):
  File "/private/home/beidic/.conda/envs/griffin/bin/huggingface-cli", line 8, in <module>
    sys.exit(main())
             ^^^^^^
  File "/private/home/beidic/.conda/envs/griffin/lib/python3.12/site-packages/huggingface_hub/commands/huggingface_cli.py", line 51, in main
    service.run()
  File "/private/home/beidic/.conda/envs/griffin/lib/python3.12/site-packages/huggingface_hub/commands/user.py", line 98, in run
    login(token=self.args.token, add_to_git_credential=self.args.add_to_git_credential)
  File "/private/home/beidic/.conda/envs/griffin/lib/python3.12/site-packages/huggingface_hub/_login.py", line 111, in login
    _login(token, add_to_git_credential=add_to_git_credential, write_permission=write_permission)
  File "/private/home/beidic/.conda/envs/griffin/lib/python3.12/site-packages/huggingface_hub/_login.py", line 307, in _login
    raise ValueError("Invalid token passed!")
ValueError: Invalid token passed!
The following values were not passed to `accelerate launch` and had defaults used instead:
		More than one GPU was found, enabling multi-GPU training.
		If this was unintended please pass in `--num_processes=1`.
	`--mixed_precision` was set to a value of `'no'`
	`--dynamo_backend` was set to a value of `'no'`
To avoid this warning pass in values for each of the problematic parameters or run `accelerate config`.
2024-06-04:06:35:22,657 INFO     [main.py:288] Verbosity set to INFO
2024-06-04:06:35:22,658 INFO     [main.py:288] Verbosity set to INFO
2024-06-04:06:35:22,658 INFO     [main.py:288] Verbosity set to INFO
2024-06-04:06:35:22,658 INFO     [main.py:288] Verbosity set to INFO
2024-06-04:06:35:22,919 INFO     [main.py:288] Verbosity set to INFO
2024-06-04:06:35:23,256 INFO     [main.py:288] Verbosity set to INFO
2024-06-04:06:35:23,497 INFO     [main.py:288] Verbosity set to INFO
2024-06-04:06:35:24,190 INFO     [main.py:288] Verbosity set to INFO
2024-06-04:06:35:29,481 INFO     [main.py:378] Selected Tasks: ['gsm8k']
2024-06-04:06:35:29,485 INFO     [main.py:378] Selected Tasks: ['gsm8k']
2024-06-04:06:35:29,491 INFO     [xevaluator.py:137] Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234
2024-06-04:06:35:29,491 INFO     [xevaluator.py:184] Initializing xhf model, with arguments: {'pretrained': 'meta-llama/Llama-2-7b-hf', 'griffin': True, 'check': True, 'kernel_size': 16, 'spr': 0.5, 'thr': 0.1}
2024-06-04:06:35:29,491 INFO     [xevaluator.py:137] Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234
2024-06-04:06:35:29,491 INFO     [xevaluator.py:184] Initializing xhf model, with arguments: {'pretrained': 'meta-llama/Llama-2-7b-hf', 'griffin': True, 'check': True, 'kernel_size': 16, 'spr': 0.5, 'thr': 0.1}
2024-06-04:06:35:29,511 INFO     [main.py:378] Selected Tasks: ['gsm8k']
2024-06-04:06:35:29,516 INFO     [xevaluator.py:137] Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234
2024-06-04:06:35:29,516 INFO     [xevaluator.py:184] Initializing xhf model, with arguments: {'pretrained': 'meta-llama/Llama-2-7b-hf', 'griffin': True, 'check': True, 'kernel_size': 16, 'spr': 0.5, 'thr': 0.1}
2024-06-04:06:35:29,529 INFO     [main.py:378] Selected Tasks: ['gsm8k']
2024-06-04:06:35:29,533 INFO     [xevaluator.py:137] Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234
2024-06-04:06:35:29,533 INFO     [xevaluator.py:184] Initializing xhf model, with arguments: {'pretrained': 'meta-llama/Llama-2-7b-hf', 'griffin': True, 'check': True, 'kernel_size': 16, 'spr': 0.5, 'thr': 0.1}
2024-06-04:06:35:29,700 INFO     [main.py:378] Selected Tasks: ['gsm8k']
2024-06-04:06:35:29,706 INFO     [xevaluator.py:137] Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234
2024-06-04:06:35:29,706 INFO     [xevaluator.py:184] Initializing xhf model, with arguments: {'pretrained': 'meta-llama/Llama-2-7b-hf', 'griffin': True, 'check': True, 'kernel_size': 16, 'spr': 0.5, 'thr': 0.1}
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]2024-06-04:06:35:33,832 INFO     [main.py:378] Selected Tasks: ['gsm8k']
2024-06-04:06:35:33,837 INFO     [xevaluator.py:137] Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234
2024-06-04:06:35:33,838 INFO     [xevaluator.py:184] Initializing xhf model, with arguments: {'pretrained': 'meta-llama/Llama-2-7b-hf', 'griffin': True, 'check': True, 'kernel_size': 16, 'spr': 0.5, 'thr': 0.1}
2024-06-04:06:35:34,542 INFO     [main.py:378] Selected Tasks: ['gsm8k']
2024-06-04:06:35:34,546 INFO     [xevaluator.py:137] Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234
2024-06-04:06:35:34,546 INFO     [xevaluator.py:184] Initializing xhf model, with arguments: {'pretrained': 'meta-llama/Llama-2-7b-hf', 'griffin': True, 'check': True, 'kernel_size': 16, 'spr': 0.5, 'thr': 0.1}
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]2024-06-04:06:35:36,530 INFO     [main.py:378] Selected Tasks: ['gsm8k']
2024-06-04:06:35:36,541 INFO     [xevaluator.py:137] Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234
2024-06-04:06:35:36,541 INFO     [xevaluator.py:184] Initializing xhf model, with arguments: {'pretrained': 'meta-llama/Llama-2-7b-hf', 'griffin': True, 'check': True, 'kernel_size': 16, 'spr': 0.5, 'thr': 0.1}
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:57<00:57, 57.41s/it]Loading checkpoint shards:  50%|█████     | 1/2 [00:59<00:59, 59.66s/it]Loading checkpoint shards:  50%|█████     | 1/2 [00:59<00:59, 59.43s/it]Loading checkpoint shards:  50%|█████     | 1/2 [00:55<00:55, 55.02s/it]Loading checkpoint shards:  50%|█████     | 1/2 [00:59<00:59, 59.48s/it]Loading checkpoint shards:  50%|█████     | 1/2 [00:59<00:59, 59.50s/it]Loading checkpoint shards:  50%|█████     | 1/2 [00:52<00:52, 52.40s/it]Loading checkpoint shards:  50%|█████     | 1/2 [00:56<00:56, 56.44s/it]Loading checkpoint shards: 100%|██████████| 2/2 [01:11<00:00, 32.22s/it]Loading checkpoint shards: 100%|██████████| 2/2 [01:11<00:00, 35.64s/it]
Loading checkpoint shards: 100%|██████████| 2/2 [01:16<00:00, 34.40s/it]Loading checkpoint shards: 100%|██████████| 2/2 [01:16<00:00, 38.16s/it]
Loading checkpoint shards: 100%|██████████| 2/2 [01:16<00:00, 34.82s/it]Loading checkpoint shards: 100%|██████████| 2/2 [01:16<00:00, 34.43s/it]Loading checkpoint shards: 100%|██████████| 2/2 [01:16<00:00, 38.21s/it]Loading checkpoint shards: 100%|██████████| 2/2 [01:16<00:00, 38.19s/it]

Loading checkpoint shards: 100%|██████████| 2/2 [01:16<00:00, 34.46s/it]Loading checkpoint shards: 100%|██████████| 2/2 [01:16<00:00, 38.21s/it]
Loading checkpoint shards: 100%|██████████| 2/2 [01:12<00:00, 32.83s/it]Loading checkpoint shards: 100%|██████████| 2/2 [01:12<00:00, 36.37s/it]
Loading checkpoint shards: 100%|██████████| 2/2 [01:16<00:00, 34.58s/it]Loading checkpoint shards: 100%|██████████| 2/2 [01:16<00:00, 38.34s/it]
Loading checkpoint shards: 100%|██████████| 2/2 [01:09<00:00, 31.84s/it]Loading checkpoint shards: 100%|██████████| 2/2 [01:09<00:00, 34.92s/it]
Using the latest cached version of the dataset since gsm8k couldn't be found on the Hugging Face Hub
2024-06-04:06:37:20,205 WARNING  [load.py:1631] Using the latest cached version of the dataset since gsm8k couldn't be found on the Hugging Face Hub
Found the latest cached dataset configuration 'main' at /private/home/beidic/.cache/huggingface/datasets/gsm8k/main/0.0.0/e53f048856ff4f594e959d75785d2c2d37b678ee (last modified on Thu May 16 07:01:08 2024).
2024-06-04:06:37:20,208 WARNING  [cache.py:95] Found the latest cached dataset configuration 'main' at /private/home/beidic/.cache/huggingface/datasets/gsm8k/main/0.0.0/e53f048856ff4f594e959d75785d2c2d37b678ee (last modified on Thu May 16 07:01:08 2024).
2024-06-04:06:37:20,498 INFO     [task.py:395] Building contexts for gsm8k on rank 5...
  0%|          | 0/165 [00:00<?, ?it/s] 12%|█▏        | 20/165 [00:00<00:00, 196.21it/s] 24%|██▍       | 40/165 [00:00<00:00, 196.27it/s] 36%|███▋      | 60/165 [00:00<00:00, 196.97it/s] 48%|████▊     | 80/165 [00:00<00:00, 197.32it/s] 61%|██████    | 100/165 [00:00<00:00, 198.01it/s] 73%|███████▎  | 120/165 [00:00<00:00, 198.13it/s] 85%|████████▍ | 140/165 [00:00<00:00, 198.23it/s] 97%|█████████▋| 160/165 [00:00<00:00, 198.37it/s]100%|██████████| 165/165 [00:00<00:00, 197.85it/s]
Using the latest cached version of the dataset since gsm8k couldn't be found on the Hugging Face Hub
2024-06-04:06:37:35,663 WARNING  [load.py:1631] Using the latest cached version of the dataset since gsm8k couldn't be found on the Hugging Face Hub
Found the latest cached dataset configuration 'main' at /private/home/beidic/.cache/huggingface/datasets/gsm8k/main/0.0.0/e53f048856ff4f594e959d75785d2c2d37b678ee (last modified on Thu May 16 07:01:08 2024).
2024-06-04:06:37:35,665 WARNING  [cache.py:95] Found the latest cached dataset configuration 'main' at /private/home/beidic/.cache/huggingface/datasets/gsm8k/main/0.0.0/e53f048856ff4f594e959d75785d2c2d37b678ee (last modified on Thu May 16 07:01:08 2024).
Using the latest cached version of the dataset since gsm8k couldn't be found on the Hugging Face Hub
2024-06-04:06:37:35,703 WARNING  [load.py:1631] Using the latest cached version of the dataset since gsm8k couldn't be found on the Hugging Face Hub
Found the latest cached dataset configuration 'main' at /private/home/beidic/.cache/huggingface/datasets/gsm8k/main/0.0.0/e53f048856ff4f594e959d75785d2c2d37b678ee (last modified on Thu May 16 07:01:08 2024).
2024-06-04:06:37:35,705 WARNING  [cache.py:95] Found the latest cached dataset configuration 'main' at /private/home/beidic/.cache/huggingface/datasets/gsm8k/main/0.0.0/e53f048856ff4f594e959d75785d2c2d37b678ee (last modified on Thu May 16 07:01:08 2024).
2024-06-04:06:37:35,840 INFO     [task.py:395] Building contexts for gsm8k on rank 6...
  0%|          | 0/165 [00:00<?, ?it/s] 12%|█▏        | 20/165 [00:00<00:00, 196.67it/s] 24%|██▍       | 40/165 [00:00<00:00, 197.52it/s]2024-06-04:06:37:36,066 INFO     [task.py:395] Building contexts for gsm8k on rank 4...
  0%|          | 0/165 [00:00<?, ?it/s] 36%|███▋      | 60/165 [00:00<00:00, 198.13it/s]  8%|▊         | 14/165 [00:00<00:01, 132.65it/s] 48%|████▊     | 80/165 [00:00<00:00, 198.45it/s] 17%|█▋        | 28/165 [00:00<00:01, 127.63it/s] 61%|██████    | 100/165 [00:00<00:00, 198.60it/s] 25%|██▌       | 42/165 [00:00<00:00, 130.42it/s] 73%|███████▎  | 120/165 [00:00<00:00, 198.64it/s] 34%|███▍      | 56/165 [00:00<00:00, 131.80it/s] 85%|████████▍ | 140/165 [00:00<00:00, 198.64it/s] 42%|████▏     | 70/165 [00:00<00:00, 132.57it/s] 97%|█████████▋| 160/165 [00:00<00:00, 198.54it/s]100%|██████████| 165/165 [00:00<00:00, 198.42it/s]
 51%|█████     | 84/165 [00:00<00:00, 133.64it/s] 59%|█████▉    | 98/165 [00:00<00:00, 135.25it/s] 68%|██████▊   | 112/165 [00:00<00:00, 136.04it/s] 76%|███████▋  | 126/165 [00:00<00:00, 136.79it/s] 85%|████████▍ | 140/165 [00:01<00:00, 137.19it/s] 95%|█████████▌| 157/165 [00:01<00:00, 145.89it/s]100%|██████████| 165/165 [00:01<00:00, 139.47it/s]
Using the latest cached version of the dataset since gsm8k couldn't be found on the Hugging Face Hub
2024-06-04:06:37:42,077 WARNING  [load.py:1631] Using the latest cached version of the dataset since gsm8k couldn't be found on the Hugging Face Hub
Found the latest cached dataset configuration 'main' at /private/home/beidic/.cache/huggingface/datasets/gsm8k/main/0.0.0/e53f048856ff4f594e959d75785d2c2d37b678ee (last modified on Thu May 16 07:01:08 2024).
2024-06-04:06:37:42,079 WARNING  [cache.py:95] Found the latest cached dataset configuration 'main' at /private/home/beidic/.cache/huggingface/datasets/gsm8k/main/0.0.0/e53f048856ff4f594e959d75785d2c2d37b678ee (last modified on Thu May 16 07:01:08 2024).
2024-06-04:06:37:42,250 INFO     [task.py:395] Building contexts for gsm8k on rank 2...
  0%|          | 0/165 [00:00<?, ?it/s] 13%|█▎        | 21/165 [00:00<00:00, 203.39it/s] 25%|██▌       | 42/165 [00:00<00:00, 203.80it/s] 38%|███▊      | 63/165 [00:00<00:00, 203.62it/s]Using the latest cached version of the dataset since gsm8k couldn't be found on the Hugging Face Hub
2024-06-04:06:37:42,659 WARNING  [load.py:1631] Using the latest cached version of the dataset since gsm8k couldn't be found on the Hugging Face Hub
Found the latest cached dataset configuration 'main' at /private/home/beidic/.cache/huggingface/datasets/gsm8k/main/0.0.0/e53f048856ff4f594e959d75785d2c2d37b678ee (last modified on Thu May 16 07:01:08 2024).
2024-06-04:06:37:42,661 WARNING  [cache.py:95] Found the latest cached dataset configuration 'main' at /private/home/beidic/.cache/huggingface/datasets/gsm8k/main/0.0.0/e53f048856ff4f594e959d75785d2c2d37b678ee (last modified on Thu May 16 07:01:08 2024).
 51%|█████     | 84/165 [00:00<00:00, 204.04it/s] 64%|██████▎   | 105/165 [00:00<00:00, 203.59it/s]2024-06-04:06:37:42,818 INFO     [task.py:395] Building contexts for gsm8k on rank 3...
  0%|          | 0/165 [00:00<?, ?it/s] 76%|███████▋  | 126/165 [00:00<00:00, 203.89it/s] 13%|█▎        | 21/165 [00:00<00:00, 204.56it/s] 89%|████████▉ | 147/165 [00:00<00:00, 204.17it/s] 25%|██▌       | 42/165 [00:00<00:00, 205.60it/s]100%|██████████| 165/165 [00:00<00:00, 204.11it/s]
 38%|███▊      | 63/165 [00:00<00:00, 206.45it/s] 51%|█████     | 84/165 [00:00<00:00, 207.32it/s] 64%|██████▎   | 105/165 [00:00<00:00, 208.11it/s] 76%|███████▋  | 126/165 [00:00<00:00, 208.48it/s] 89%|████████▉ | 147/165 [00:00<00:00, 208.66it/s]100%|██████████| 165/165 [00:00<00:00, 207.97it/s]
Using the latest cached version of the dataset since gsm8k couldn't be found on the Hugging Face Hub
2024-06-04:06:37:45,894 WARNING  [load.py:1631] Using the latest cached version of the dataset since gsm8k couldn't be found on the Hugging Face Hub
Found the latest cached dataset configuration 'main' at /private/home/beidic/.cache/huggingface/datasets/gsm8k/main/0.0.0/e53f048856ff4f594e959d75785d2c2d37b678ee (last modified on Thu May 16 07:01:08 2024).
2024-06-04:06:37:45,897 WARNING  [cache.py:95] Found the latest cached dataset configuration 'main' at /private/home/beidic/.cache/huggingface/datasets/gsm8k/main/0.0.0/e53f048856ff4f594e959d75785d2c2d37b678ee (last modified on Thu May 16 07:01:08 2024).
2024-06-04:06:37:46,285 INFO     [task.py:395] Building contexts for gsm8k on rank 1...
  0%|          | 0/165 [00:00<?, ?it/s]  7%|▋         | 12/165 [00:00<00:01, 119.72it/s] 15%|█▌        | 25/165 [00:00<00:01, 120.68it/s] 23%|██▎       | 38/165 [00:00<00:01, 119.87it/s] 30%|███       | 50/165 [00:00<00:00, 117.73it/s] 38%|███▊      | 63/165 [00:00<00:00, 119.02it/s] 46%|████▌     | 76/165 [00:00<00:00, 119.81it/s] 54%|█████▍    | 89/165 [00:00<00:00, 120.35it/s] 62%|██████▏   | 102/165 [00:00<00:00, 120.68it/s] 70%|██████▉   | 115/165 [00:00<00:00, 120.84it/s] 78%|███████▊  | 128/165 [00:01<00:00, 120.98it/s] 85%|████████▌ | 141/165 [00:01<00:00, 121.11it/s] 93%|█████████▎| 154/165 [00:01<00:00, 121.08it/s]100%|██████████| 165/165 [00:01<00:00, 120.49it/s]
Using the latest cached version of the dataset since gsm8k couldn't be found on the Hugging Face Hub
2024-06-04:06:38:12,727 WARNING  [load.py:1631] Using the latest cached version of the dataset since gsm8k couldn't be found on the Hugging Face Hub
Found the latest cached dataset configuration 'main' at /private/home/beidic/.cache/huggingface/datasets/gsm8k/main/0.0.0/e53f048856ff4f594e959d75785d2c2d37b678ee (last modified on Thu May 16 07:01:08 2024).
2024-06-04:06:38:12,730 WARNING  [cache.py:95] Found the latest cached dataset configuration 'main' at /private/home/beidic/.cache/huggingface/datasets/gsm8k/main/0.0.0/e53f048856ff4f594e959d75785d2c2d37b678ee (last modified on Thu May 16 07:01:08 2024).
2024-06-04:06:38:13,096 INFO     [task.py:395] Building contexts for gsm8k on rank 7...
  0%|          | 0/164 [00:00<?, ?it/s]  8%|▊         | 13/164 [00:00<00:01, 127.56it/s] 16%|█▌        | 26/164 [00:00<00:01, 127.93it/s] 24%|██▍       | 39/164 [00:00<00:00, 128.16it/s] 32%|███▏      | 52/164 [00:00<00:00, 128.43it/s] 40%|███▉      | 65/164 [00:00<00:00, 128.35it/s] 48%|████▊     | 78/164 [00:00<00:00, 128.59it/s] 55%|█████▌    | 91/164 [00:00<00:00, 128.63it/s] 63%|██████▎   | 104/164 [00:00<00:00, 128.52it/s] 71%|███████▏  | 117/164 [00:00<00:00, 128.33it/s] 79%|███████▉  | 130/164 [00:01<00:00, 128.48it/s] 87%|████████▋ | 143/164 [00:01<00:00, 128.76it/s] 95%|█████████▌| 156/164 [00:01<00:00, 128.63it/s]100%|██████████| 164/164 [00:01<00:00, 128.48it/s]
2024-06-04:06:38:39,974 INFO     [xhuggingface.py:314] Using 8 devices with data parallelism
Using the latest cached version of the dataset since gsm8k couldn't be found on the Hugging Face Hub
2024-06-04:06:38:40,059 WARNING  [load.py:1631] Using the latest cached version of the dataset since gsm8k couldn't be found on the Hugging Face Hub
Found the latest cached dataset configuration 'main' at /private/home/beidic/.cache/huggingface/datasets/gsm8k/main/0.0.0/e53f048856ff4f594e959d75785d2c2d37b678ee (last modified on Thu May 16 07:01:08 2024).
2024-06-04:06:38:40,062 WARNING  [cache.py:95] Found the latest cached dataset configuration 'main' at /private/home/beidic/.cache/huggingface/datasets/gsm8k/main/0.0.0/e53f048856ff4f594e959d75785d2c2d37b678ee (last modified on Thu May 16 07:01:08 2024).
2024-06-04:06:38:40,534 INFO     [task.py:395] Building contexts for gsm8k on rank 0...
  0%|          | 0/165 [00:00<?, ?it/s]  4%|▍         | 7/165 [00:00<00:02, 66.15it/s]  8%|▊         | 14/165 [00:00<00:02, 66.63it/s] 13%|█▎        | 21/165 [00:00<00:02, 66.75it/s] 17%|█▋        | 28/165 [00:00<00:02, 67.07it/s] 21%|██        | 35/165 [00:00<00:01, 66.99it/s] 25%|██▌       | 42/165 [00:00<00:01, 67.08it/s] 30%|██▉       | 49/165 [00:00<00:01, 67.03it/s] 34%|███▍      | 56/165 [00:00<00:01, 67.03it/s] 38%|███▊      | 63/165 [00:00<00:01, 66.95it/s] 42%|████▏     | 70/165 [00:01<00:01, 67.08it/s] 47%|████▋     | 77/165 [00:01<00:01, 67.19it/s] 51%|█████     | 84/165 [00:01<00:01, 67.08it/s] 55%|█████▌    | 91/165 [00:01<00:01, 67.09it/s] 59%|█████▉    | 98/165 [00:01<00:00, 67.18it/s] 64%|██████▎   | 105/165 [00:01<00:00, 67.26it/s] 68%|██████▊   | 112/165 [00:01<00:00, 67.27it/s] 72%|███████▏  | 119/165 [00:01<00:00, 67.14it/s] 76%|███████▋  | 126/165 [00:01<00:00, 67.18it/s] 81%|████████  | 133/165 [00:01<00:00, 67.17it/s] 85%|████████▍ | 140/165 [00:02<00:00, 67.16it/s] 89%|████████▉ | 147/165 [00:02<00:00, 67.14it/s] 93%|█████████▎| 154/165 [00:02<00:00, 67.00it/s] 98%|█████████▊| 161/165 [00:02<00:00, 67.13it/s]100%|██████████| 165/165 [00:02<00:00, 67.08it/s]
2024-06-04:06:38:55,193 INFO     [xevaluator.py:395] Running generate_until requests
2024-06-04:06:38:55,193 INFO     [xevaluator.py:395] Running generate_until requests
2024-06-04:06:38:55,193 INFO     [xevaluator.py:395] Running generate_until requests
2024-06-04:06:38:55,194 INFO     [xevaluator.py:395] Running generate_until requests
2024-06-04:06:38:55,194 INFO     [xevaluator.py:395] Running generate_until requests
2024-06-04:06:38:55,194 INFO     [xevaluator.py:395] Running generate_until requests
2024-06-04:06:38:55,195 INFO     [xevaluator.py:395] Running generate_until requests
2024-06-04:06:38:55,197 INFO     [xevaluator.py:395] Running generate_until requests
Running generate_until requests:   0%|          | 0/165 [00:00<?, ?it/s]Running generate_until requests:   1%|          | 1/165 [00:16<46:04, 16.86s/it]Running generate_until requests:   1%|          | 2/165 [00:24<30:50, 11.35s/it]Running generate_until requests:   2%|▏         | 3/165 [00:28<21:58,  8.14s/it]Running generate_until requests:   2%|▏         | 4/165 [00:41<26:19,  9.81s/it]Running generate_until requests:   3%|▎         | 5/165 [00:51<26:49, 10.06s/it]Running generate_until requests:   4%|▎         | 6/165 [01:01<26:28,  9.99s/it]Running generate_until requests:   4%|▍         | 7/165 [01:03<19:42,  7.49s/it]Running generate_until requests:   5%|▍         | 8/165 [01:11<19:35,  7.49s/it]Running generate_until requests:   5%|▌         | 9/165 [01:15<16:59,  6.54s/it]Running generate_until requests:   6%|▌         | 10/165 [01:20<15:33,  6.02s/it]Running generate_until requests:   7%|▋         | 11/165 [01:28<16:57,  6.61s/it]Running generate_until requests:   7%|▋         | 12/165 [01:32<14:28,  5.68s/it]Running generate_until requests:   8%|▊         | 13/165 [01:44<19:33,  7.72s/it]Running generate_until requests:   8%|▊         | 14/165 [01:59<25:04,  9.96s/it]Running generate_until requests:   9%|▉         | 15/165 [02:03<20:08,  8.06s/it]Running generate_until requests:  10%|▉         | 16/165 [02:09<18:57,  7.63s/it]Running generate_until requests:  10%|█         | 17/165 [02:15<17:20,  7.03s/it]Running generate_until requests:  11%|█         | 18/165 [02:20<16:05,  6.57s/it]Running generate_until requests:  12%|█▏        | 19/165 [02:25<14:36,  6.01s/it]Running generate_until requests:  12%|█▏        | 20/165 [02:40<20:40,  8.56s/it]Running generate_until requests:  13%|█▎        | 21/165 [02:47<19:57,  8.32s/it]Running generate_until requests:  13%|█▎        | 22/165 [02:53<17:34,  7.37s/it]Running generate_until requests:  14%|█▍        | 23/165 [03:07<22:44,  9.61s/it]Running generate_until requests:  15%|█▍        | 24/165 [03:12<18:41,  7.96s/it]Running generate_until requests:  15%|█▌        | 25/165 [03:22<20:10,  8.65s/it]Running generate_until requests:  16%|█▌        | 26/165 [03:30<19:55,  8.60s/it]Running generate_until requests:  16%|█▋        | 27/165 [03:36<17:54,  7.79s/it]Running generate_until requests:  17%|█▋        | 28/165 [03:52<23:01, 10.08s/it]Running generate_until requests:  18%|█▊        | 29/165 [04:00<22:00,  9.71s/it]Running generate_until requests:  18%|█▊        | 30/165 [04:07<19:49,  8.81s/it]Running generate_until requests:  19%|█▉        | 31/165 [04:13<17:49,  7.98s/it]Running generate_until requests:  19%|█▉        | 32/165 [04:18<15:41,  7.08s/it]Running generate_until requests:  20%|██        | 33/165 [04:21<13:01,  5.92s/it]Running generate_until requests:  21%|██        | 34/165 [04:27<12:30,  5.73s/it]Running generate_until requests:  21%|██        | 35/165 [04:33<12:29,  5.77s/it]Running generate_until requests:  22%|██▏       | 36/165 [04:38<12:28,  5.80s/it]Running generate_until requests:  22%|██▏       | 37/165 [04:42<10:55,  5.12s/it]Running generate_until requests:  23%|██▎       | 38/165 [04:50<12:24,  5.86s/it]Running generate_until requests:  24%|██▎       | 39/165 [05:04<17:43,  8.44s/it]Running generate_until requests:  24%|██▍       | 40/165 [05:09<15:23,  7.39s/it]Running generate_until requests:  25%|██▍       | 41/165 [05:15<14:39,  7.09s/it]Running generate_until requests:  25%|██▌       | 42/165 [05:31<19:53,  9.70s/it]Running generate_until requests:  26%|██▌       | 43/165 [05:35<15:55,  7.83s/it]Running generate_until requests:  27%|██▋       | 44/165 [05:40<14:36,  7.25s/it]Running generate_until requests:  27%|██▋       | 45/165 [05:48<14:21,  7.18s/it]Running generate_until requests:  28%|██▊       | 46/165 [06:02<18:33,  9.36s/it]Running generate_until requests:  28%|██▊       | 47/165 [06:10<17:35,  8.94s/it]Running generate_until requests:  29%|██▉       | 48/165 [06:14<14:49,  7.60s/it]Running generate_until requests:  30%|██▉       | 49/165 [06:18<12:34,  6.51s/it]Running generate_until requests:  30%|███       | 50/165 [06:23<11:20,  5.92s/it]Running generate_until requests:  31%|███       | 51/165 [06:30<11:57,  6.29s/it]Running generate_until requests:  32%|███▏      | 52/165 [06:45<16:48,  8.93s/it]Running generate_until requests:  32%|███▏      | 53/165 [06:47<12:58,  6.95s/it]Running generate_until requests:  33%|███▎      | 54/165 [07:03<17:47,  9.62s/it]Running generate_until requests:  33%|███▎      | 55/165 [07:13<17:26,  9.51s/it]Running generate_until requests:  34%|███▍      | 56/165 [07:20<15:56,  8.77s/it]Running generate_until requests:  35%|███▍      | 57/165 [07:25<13:48,  7.67s/it]Running generate_until requests:  35%|███▌      | 58/165 [07:36<15:44,  8.82s/it]Running generate_until requests:  36%|███▌      | 59/165 [07:41<13:35,  7.69s/it]Running generate_until requests:  36%|███▋      | 60/165 [07:49<13:15,  7.57s/it]Running generate_until requests:  37%|███▋      | 61/165 [07:55<12:17,  7.09s/it]Running generate_until requests:  38%|███▊      | 62/165 [08:03<12:52,  7.50s/it]Running generate_until requests:  38%|███▊      | 63/165 [08:14<14:26,  8.49s/it]Running generate_until requests:  39%|███▉      | 64/165 [08:17<11:40,  6.94s/it]Running generate_until requests:  39%|███▉      | 65/165 [08:20<09:46,  5.86s/it]Running generate_until requests:  40%|████      | 66/165 [08:35<14:06,  8.55s/it]Running generate_until requests:  41%|████      | 67/165 [08:38<11:03,  6.77s/it]Running generate_until requests:  41%|████      | 68/165 [08:53<15:10,  9.39s/it]Running generate_until requests:  42%|████▏     | 69/165 [09:02<14:50,  9.28s/it]Running generate_until requests:  42%|████▏     | 70/165 [09:17<17:07, 10.82s/it]Running generate_until requests:  43%|████▎     | 71/165 [09:28<16:55, 10.80s/it]Running generate_until requests:  44%|████▎     | 72/165 [09:39<16:53, 10.90s/it]Running generate_until requests:  44%|████▍     | 73/165 [09:46<15:15,  9.95s/it]Running generate_until requests:  45%|████▍     | 74/165 [09:52<13:01,  8.59s/it]Running generate_until requests:  45%|████▌     | 75/165 [10:08<16:03, 10.71s/it]Running generate_until requests:  46%|████▌     | 76/165 [10:16<14:59, 10.10s/it]Running generate_until requests:  47%|████▋     | 77/165 [10:25<14:19,  9.77s/it]Running generate_until requests:  47%|████▋     | 78/165 [10:33<13:27,  9.28s/it]Running generate_until requests:  48%|████▊     | 79/165 [10:41<12:28,  8.70s/it]Running generate_until requests:  48%|████▊     | 80/165 [10:50<12:25,  8.77s/it]Running generate_until requests:  49%|████▉     | 81/165 [10:59<12:24,  8.86s/it]Running generate_until requests:  50%|████▉     | 82/165 [11:03<10:24,  7.52s/it]Running generate_until requests:  50%|█████     | 83/165 [11:13<11:04,  8.10s/it]Running generate_until requests:  51%|█████     | 84/165 [11:16<08:54,  6.59s/it]Running generate_until requests:  52%|█████▏    | 85/165 [11:22<08:33,  6.42s/it]Running generate_until requests:  52%|█████▏    | 86/165 [11:30<09:02,  6.86s/it]Running generate_until requests:  53%|█████▎    | 87/165 [11:32<07:12,  5.54s/it]Running generate_until requests:  53%|█████▎    | 88/165 [11:36<06:40,  5.20s/it]Running generate_until requests:  54%|█████▍    | 89/165 [11:42<06:53,  5.45s/it]Running generate_until requests:  55%|█████▍    | 90/165 [11:46<06:00,  4.80s/it]Running generate_until requests:  55%|█████▌    | 91/165 [11:52<06:18,  5.12s/it]Running generate_until requests:  56%|█████▌    | 92/165 [11:56<05:52,  4.83s/it]Running generate_until requests:  56%|█████▋    | 93/165 [12:02<06:12,  5.17s/it]Running generate_until requests:  57%|█████▋    | 94/165 [12:11<07:39,  6.47s/it]Running generate_until requests:  58%|█████▊    | 95/165 [12:20<08:20,  7.15s/it]Running generate_until requests:  58%|█████▊    | 96/165 [12:30<09:04,  7.89s/it]Running generate_until requests:  59%|█████▉    | 97/165 [12:34<07:49,  6.90s/it]Running generate_until requests:  59%|█████▉    | 98/165 [12:41<07:36,  6.82s/it]Running generate_until requests:  60%|██████    | 99/165 [12:51<08:34,  7.79s/it]Running generate_until requests:  61%|██████    | 100/165 [12:56<07:27,  6.89s/it]Running generate_until requests:  61%|██████    | 101/165 [13:03<07:21,  6.91s/it]Running generate_until requests:  62%|██████▏   | 102/165 [13:06<06:01,  5.74s/it]Running generate_until requests:  62%|██████▏   | 103/165 [13:11<05:47,  5.60s/it]Running generate_until requests:  63%|██████▎   | 104/165 [13:26<08:38,  8.50s/it]Running generate_until requests:  64%|██████▎   | 105/165 [13:41<10:16, 10.27s/it]Running generate_until requests:  64%|██████▍   | 106/165 [13:44<08:12,  8.35s/it]Running generate_until requests:  65%|██████▍   | 107/165 [13:47<06:30,  6.73s/it]Running generate_until requests:  65%|██████▌   | 108/165 [13:52<05:40,  5.97s/it]Running generate_until requests:  66%|██████▌   | 109/165 [13:56<05:14,  5.61s/it]Running generate_until requests:  67%|██████▋   | 110/165 [14:04<05:37,  6.15s/it]Running generate_until requests:  67%|██████▋   | 111/165 [14:12<06:13,  6.91s/it]Running generate_until requests:  68%|██████▊   | 112/165 [14:17<05:26,  6.17s/it]Running generate_until requests:  68%|██████▊   | 113/165 [14:25<05:55,  6.83s/it]Running generate_until requests:  69%|██████▉   | 114/165 [14:33<06:00,  7.08s/it]Running generate_until requests:  70%|██████▉   | 115/165 [14:40<05:58,  7.17s/it]Running generate_until requests:  70%|███████   | 116/165 [14:44<04:54,  6.01s/it]Running generate_until requests:  71%|███████   | 117/165 [14:46<04:00,  5.01s/it]Running generate_until requests:  72%|███████▏  | 118/165 [14:50<03:31,  4.50s/it]Running generate_until requests:  72%|███████▏  | 119/165 [14:55<03:43,  4.87s/it]Running generate_until requests:  73%|███████▎  | 120/165 [14:58<03:13,  4.29s/it]Running generate_until requests:  73%|███████▎  | 121/165 [15:13<05:27,  7.45s/it]Running generate_until requests:  74%|███████▍  | 122/165 [15:21<05:29,  7.67s/it]Running generate_until requests:  75%|███████▍  | 123/165 [15:30<05:34,  7.97s/it]Running generate_until requests:  75%|███████▌  | 124/165 [15:35<04:51,  7.12s/it]Running generate_until requests:  76%|███████▌  | 125/165 [15:40<04:23,  6.59s/it]Running generate_until requests:  76%|███████▋  | 126/165 [15:48<04:29,  6.91s/it]Running generate_until requests:  77%|███████▋  | 127/165 [15:55<04:20,  6.85s/it]Running generate_until requests:  78%|███████▊  | 128/165 [16:00<03:54,  6.35s/it]Running generate_until requests:  78%|███████▊  | 129/165 [16:06<03:47,  6.32s/it]Running generate_until requests:  79%|███████▉  | 130/165 [16:12<03:37,  6.22s/it]Running generate_until requests:  79%|███████▉  | 131/165 [16:20<03:49,  6.75s/it]Running generate_until requests:  80%|████████  | 132/165 [16:25<03:23,  6.18s/it]Running generate_until requests:  81%|████████  | 133/165 [16:31<03:17,  6.17s/it]Running generate_until requests:  81%|████████  | 134/165 [16:48<04:46,  9.25s/it]Running generate_until requests:  82%|████████▏ | 135/165 [16:50<03:33,  7.11s/it]Running generate_until requests:  82%|████████▏ | 136/165 [16:58<03:33,  7.36s/it]Running generate_until requests:  83%|████████▎ | 137/165 [17:03<03:10,  6.79s/it]Running generate_until requests:  84%|████████▎ | 138/165 [17:10<03:06,  6.92s/it]Running generate_until requests:  84%|████████▍ | 139/165 [17:15<02:40,  6.17s/it]Running generate_until requests:  85%|████████▍ | 140/165 [17:19<02:17,  5.52s/it]Running generate_until requests:  85%|████████▌ | 141/165 [17:26<02:24,  6.04s/it]Running generate_until requests:  86%|████████▌ | 142/165 [17:31<02:08,  5.61s/it]Running generate_until requests:  87%|████████▋ | 143/165 [17:35<01:54,  5.20s/it]Running generate_until requests:  87%|████████▋ | 144/165 [17:41<01:52,  5.37s/it]Running generate_until requests:  88%|████████▊ | 145/165 [17:56<02:49,  8.48s/it]Running generate_until requests:  88%|████████▊ | 146/165 [18:11<03:14, 10.24s/it]Running generate_until requests:  89%|████████▉ | 147/165 [18:25<03:28, 11.59s/it]Running generate_until requests:  90%|████████▉ | 148/165 [18:36<03:10, 11.23s/it]Running generate_until requests:  90%|█████████ | 149/165 [18:43<02:41, 10.08s/it]Running generate_until requests:  91%|█████████ | 150/165 [18:49<02:13,  8.90s/it]Running generate_until requests:  92%|█████████▏| 151/165 [18:55<01:51,  7.97s/it]Running generate_until requests:  92%|█████████▏| 152/165 [19:02<01:39,  7.63s/it]Running generate_until requests:  93%|█████████▎| 153/165 [19:17<01:58,  9.83s/it]Running generate_until requests:  93%|█████████▎| 154/165 [19:26<01:43,  9.44s/it]Running generate_until requests:  94%|█████████▍| 155/165 [19:28<01:14,  7.42s/it]Running generate_until requests:  95%|█████████▍| 156/165 [19:34<01:03,  7.04s/it]Running generate_until requests:  95%|█████████▌| 157/165 [19:39<00:50,  6.28s/it]Running generate_until requests:  96%|█████████▌| 158/165 [19:53<01:00,  8.70s/it]Running generate_until requests:  96%|█████████▋| 159/165 [20:00<00:48,  8.11s/it]Running generate_until requests:  97%|█████████▋| 160/165 [20:08<00:40,  8.01s/it]Running generate_until requests:  98%|█████████▊| 161/165 [20:12<00:27,  6.81s/it]Running generate_until requests:  98%|█████████▊| 162/165 [20:16<00:18,  6.10s/it]Running generate_until requests:  99%|█████████▉| 163/165 [20:21<00:11,  5.82s/it]Running generate_until requests:  99%|█████████▉| 164/165 [20:25<00:05,  5.14s/it]Running generate_until requests: 100%|██████████| 165/165 [20:31<00:00,  5.38s/it]Running generate_until requests: 100%|██████████| 165/165 [20:31<00:00,  7.46s/it]
[2024-06-04 07:20:30,091] torch.distributed.elastic.multiprocessing.api: [WARNING] Sending process 3824433 closing signal SIGTERM
[2024-06-04 07:20:33,667] torch.distributed.elastic.multiprocessing.api: [ERROR] failed (exitcode: -7) local_rank: 1 (pid: 3824434) of binary: /private/home/beidic/.conda/envs/griffin/bin/python
Traceback (most recent call last):
  File "/private/home/beidic/.conda/envs/griffin/bin/accelerate", line 8, in <module>
    sys.exit(main())
             ^^^^^^
  File "/private/home/beidic/.conda/envs/griffin/lib/python3.12/site-packages/accelerate/commands/accelerate_cli.py", line 47, in main
    args.func(args)
  File "/private/home/beidic/.conda/envs/griffin/lib/python3.12/site-packages/accelerate/commands/launch.py", line 985, in launch_command
    multi_gpu_launcher(args)
  File "/private/home/beidic/.conda/envs/griffin/lib/python3.12/site-packages/accelerate/commands/launch.py", line 654, in multi_gpu_launcher
    distrib_run.run(args)
  File "/private/home/beidic/.conda/envs/griffin/lib/python3.12/site-packages/torch/distributed/run.py", line 803, in run
    elastic_launch(
  File "/private/home/beidic/.conda/envs/griffin/lib/python3.12/site-packages/torch/distributed/launcher/api.py", line 135, in __call__
    return launch_agent(self._config, self._entrypoint, list(args))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/private/home/beidic/.conda/envs/griffin/lib/python3.12/site-packages/torch/distributed/launcher/api.py", line 268, in launch_agent
    raise ChildFailedError(
torch.distributed.elastic.multiprocessing.errors.ChildFailedError: 
=======================================================
main.py FAILED
-------------------------------------------------------
Failures:
[1]:
  time      : 2024-06-04_07:20:30
  host      : learnfair5277.h2.fair
  rank      : 4 (local_rank: 4)
  exitcode  : -7 (pid: 3824437)
  error_file: <N/A>
  traceback : Signal 7 (SIGBUS) received by PID 3824437
-------------------------------------------------------
Root Cause (first observed failure):
[0]:
  time      : 2024-06-04_07:20:30
  host      : learnfair5277.h2.fair
  rank      : 1 (local_rank: 1)
  exitcode  : -7 (pid: 3824434)
  error_file: <N/A>
  traceback : Signal 7 (SIGBUS) received by PID 3824434
=======================================================
/var/spool/slurm//job28572752/slurm_script: line 59: 3824407 Bus error               (core dumped) accelerate launch --main_process_port 29510 --num_processes 8 --num_machines 1 main.py --model xhf --model_args pretrained=meta-llama/Llama-2-7b-hf,griffin=True,check=True,kernel_size=16,spr=0.5,thr=0.1 --tasks gsm8k --batch_size 1
