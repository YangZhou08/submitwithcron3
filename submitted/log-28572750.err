Already on 'yangexp2'
wandb: Currently logged in as: stevenzhou0816100. Use `wandb login --relogin` to force relogin
Traceback (most recent call last):
  File "/private/home/beidic/.conda/envs/griffin/bin/huggingface-cli", line 8, in <module>
    sys.exit(main())
             ^^^^^^
  File "/private/home/beidic/.conda/envs/griffin/lib/python3.12/site-packages/huggingface_hub/commands/huggingface_cli.py", line 51, in main
    service.run()
  File "/private/home/beidic/.conda/envs/griffin/lib/python3.12/site-packages/huggingface_hub/commands/user.py", line 98, in run
    login(token=self.args.token, add_to_git_credential=self.args.add_to_git_credential)
  File "/private/home/beidic/.conda/envs/griffin/lib/python3.12/site-packages/huggingface_hub/_login.py", line 111, in login
    _login(token, add_to_git_credential=add_to_git_credential, write_permission=write_permission)
  File "/private/home/beidic/.conda/envs/griffin/lib/python3.12/site-packages/huggingface_hub/_login.py", line 307, in _login
    raise ValueError("Invalid token passed!")
ValueError: Invalid token passed!
The following values were not passed to `accelerate launch` and had defaults used instead:
		More than one GPU was found, enabling multi-GPU training.
		If this was unintended please pass in `--num_processes=1`.
	`--mixed_precision` was set to a value of `'no'`
	`--dynamo_backend` was set to a value of `'no'`
To avoid this warning pass in values for each of the problematic parameters or run `accelerate config`.
2024-06-04:06:30:40,803 INFO     [main.py:288] Verbosity set to INFO
2024-06-04:06:30:40,804 INFO     [main.py:288] Verbosity set to INFO
2024-06-04:06:30:40,804 INFO     [main.py:288] Verbosity set to INFO
2024-06-04:06:30:40,804 INFO     [main.py:288] Verbosity set to INFO
2024-06-04:06:30:40,804 INFO     [main.py:288] Verbosity set to INFO
2024-06-04:06:30:40,804 INFO     [main.py:288] Verbosity set to INFO
2024-06-04:06:30:40,804 INFO     [main.py:288] Verbosity set to INFO
2024-06-04:06:30:40,805 INFO     [main.py:288] Verbosity set to INFO
2024-06-04:06:30:47,445 INFO     [main.py:378] Selected Tasks: ['gsm8k']
2024-06-04:06:30:47,445 INFO     [main.py:378] Selected Tasks: ['gsm8k']
2024-06-04:06:30:47,449 INFO     [main.py:378] Selected Tasks: ['gsm8k']
2024-06-04:06:30:47,450 INFO     [main.py:378] Selected Tasks: ['gsm8k']
2024-06-04:06:30:47,456 INFO     [xevaluator.py:137] Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234
2024-06-04:06:30:47,456 INFO     [xevaluator.py:137] Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234
2024-06-04:06:30:47,456 INFO     [xevaluator.py:137] Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234
2024-06-04:06:30:47,456 INFO     [xevaluator.py:184] Initializing xhf model, with arguments: {'pretrained': 'meta-llama/Llama-2-7b-hf', 'cats': True, 'check': False}
2024-06-04:06:30:47,456 INFO     [xevaluator.py:184] Initializing xhf model, with arguments: {'pretrained': 'meta-llama/Llama-2-7b-hf', 'cats': True, 'check': False}
2024-06-04:06:30:47,456 INFO     [xevaluator.py:184] Initializing xhf model, with arguments: {'pretrained': 'meta-llama/Llama-2-7b-hf', 'cats': True, 'check': False}
2024-06-04:06:30:47,456 INFO     [xevaluator.py:137] Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234
2024-06-04:06:30:47,457 INFO     [xevaluator.py:184] Initializing xhf model, with arguments: {'pretrained': 'meta-llama/Llama-2-7b-hf', 'cats': True, 'check': False}
2024-06-04:06:30:47,627 INFO     [main.py:378] Selected Tasks: ['gsm8k']
2024-06-04:06:30:47,632 INFO     [xevaluator.py:137] Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234
2024-06-04:06:30:47,632 INFO     [xevaluator.py:184] Initializing xhf model, with arguments: {'pretrained': 'meta-llama/Llama-2-7b-hf', 'cats': True, 'check': False}
2024-06-04:06:30:47,652 INFO     [main.py:378] Selected Tasks: ['gsm8k']
2024-06-04:06:30:47,658 INFO     [xevaluator.py:137] Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234
2024-06-04:06:30:47,658 INFO     [xevaluator.py:184] Initializing xhf model, with arguments: {'pretrained': 'meta-llama/Llama-2-7b-hf', 'cats': True, 'check': False}
2024-06-04:06:30:47,696 INFO     [main.py:378] Selected Tasks: ['gsm8k']
2024-06-04:06:30:47,699 INFO     [xevaluator.py:137] Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234
2024-06-04:06:30:47,699 INFO     [xevaluator.py:184] Initializing xhf model, with arguments: {'pretrained': 'meta-llama/Llama-2-7b-hf', 'cats': True, 'check': False}
2024-06-04:06:30:47,703 INFO     [main.py:378] Selected Tasks: ['gsm8k']
2024-06-04:06:30:47,707 INFO     [xevaluator.py:137] Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234
2024-06-04:06:30:47,707 INFO     [xevaluator.py:184] Initializing xhf model, with arguments: {'pretrained': 'meta-llama/Llama-2-7b-hf', 'cats': True, 'check': False}
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [01:20<01:20, 80.87s/it]Loading checkpoint shards:  50%|█████     | 1/2 [01:22<01:22, 82.15s/it]Loading checkpoint shards:  50%|█████     | 1/2 [01:22<01:22, 82.10s/it]Loading checkpoint shards:  50%|█████     | 1/2 [01:22<01:22, 82.43s/it]Loading checkpoint shards:  50%|█████     | 1/2 [01:22<01:22, 82.12s/it]Loading checkpoint shards:  50%|█████     | 1/2 [01:22<01:22, 82.22s/it]Loading checkpoint shards:  50%|█████     | 1/2 [01:22<01:22, 82.65s/it]Loading checkpoint shards:  50%|█████     | 1/2 [01:22<01:22, 82.27s/it]Loading checkpoint shards: 100%|██████████| 2/2 [01:47<00:00, 48.59s/it]Loading checkpoint shards: 100%|██████████| 2/2 [01:47<00:00, 53.63s/it]
Loading checkpoint shards: 100%|██████████| 2/2 [01:48<00:00, 49.07s/it]Loading checkpoint shards: 100%|██████████| 2/2 [01:48<00:00, 54.03s/it]
Loading checkpoint shards: 100%|██████████| 2/2 [01:48<00:00, 49.41s/it]Loading checkpoint shards: 100%|██████████| 2/2 [01:48<00:00, 54.13s/it]
Loading checkpoint shards: 100%|██████████| 2/2 [01:47<00:00, 49.02s/it]Loading checkpoint shards: 100%|██████████| 2/2 [01:47<00:00, 53.98s/it]
Loading checkpoint shards: 100%|██████████| 2/2 [01:48<00:00, 49.06s/it]Loading checkpoint shards: 100%|██████████| 2/2 [01:48<00:00, 54.03s/it]
Loading checkpoint shards: 100%|██████████| 2/2 [01:48<00:00, 49.07s/it]Loading checkpoint shards: 100%|██████████| 2/2 [01:48<00:00, 54.05s/it]
Loading checkpoint shards: 100%|██████████| 2/2 [01:48<00:00, 49.16s/it]Loading checkpoint shards: 100%|██████████| 2/2 [01:48<00:00, 54.15s/it]
Loading checkpoint shards: 100%|██████████| 2/2 [01:48<00:00, 49.23s/it]Loading checkpoint shards: 100%|██████████| 2/2 [01:48<00:00, 54.24s/it]
Using the latest cached version of the dataset since gsm8k couldn't be found on the Hugging Face Hub
2024-06-04:06:33:06,055 WARNING  [load.py:1631] Using the latest cached version of the dataset since gsm8k couldn't be found on the Hugging Face Hub
Found the latest cached dataset configuration 'main' at /private/home/beidic/.cache/huggingface/datasets/gsm8k/main/0.0.0/e53f048856ff4f594e959d75785d2c2d37b678ee (last modified on Thu May 16 07:01:08 2024).
2024-06-04:06:33:06,058 WARNING  [cache.py:95] Found the latest cached dataset configuration 'main' at /private/home/beidic/.cache/huggingface/datasets/gsm8k/main/0.0.0/e53f048856ff4f594e959d75785d2c2d37b678ee (last modified on Thu May 16 07:01:08 2024).
Using the latest cached version of the dataset since gsm8k couldn't be found on the Hugging Face Hub
2024-06-04:06:33:06,078 WARNING  [load.py:1631] Using the latest cached version of the dataset since gsm8k couldn't be found on the Hugging Face Hub
Found the latest cached dataset configuration 'main' at /private/home/beidic/.cache/huggingface/datasets/gsm8k/main/0.0.0/e53f048856ff4f594e959d75785d2c2d37b678ee (last modified on Thu May 16 07:01:08 2024).
2024-06-04:06:33:06,080 WARNING  [cache.py:95] Found the latest cached dataset configuration 'main' at /private/home/beidic/.cache/huggingface/datasets/gsm8k/main/0.0.0/e53f048856ff4f594e959d75785d2c2d37b678ee (last modified on Thu May 16 07:01:08 2024).
2024-06-04:06:33:06,303 INFO     [task.py:395] Building contexts for gsm8k on rank 2...
  0%|          | 0/165 [00:00<?, ?it/s] 13%|█▎        | 21/165 [00:00<00:00, 206.23it/s]2024-06-04:06:33:06,444 INFO     [task.py:395] Building contexts for gsm8k on rank 6...
  0%|          | 0/165 [00:00<?, ?it/s] 25%|██▌       | 42/165 [00:00<00:00, 207.23it/s]  9%|▉         | 15/165 [00:00<00:01, 144.94it/s] 38%|███▊      | 63/165 [00:00<00:00, 207.38it/s] 18%|█▊        | 30/165 [00:00<00:00, 145.71it/s] 51%|█████     | 84/165 [00:00<00:00, 207.53it/s] 27%|██▋       | 45/165 [00:00<00:00, 146.06it/s] 64%|██████▎   | 105/165 [00:00<00:00, 207.76it/s] 36%|███▋      | 60/165 [00:00<00:00, 146.35it/s] 76%|███████▋  | 126/165 [00:00<00:00, 207.64it/s] 45%|████▌     | 75/165 [00:00<00:00, 146.53it/s] 89%|████████▉ | 147/165 [00:00<00:00, 207.65it/s] 55%|█████▍    | 90/165 [00:00<00:00, 146.52it/s]100%|██████████| 165/165 [00:00<00:00, 207.50it/s]
 64%|██████▍   | 106/165 [00:00<00:00, 147.94it/s] 74%|███████▍  | 122/165 [00:00<00:00, 149.44it/s] 84%|████████▎ | 138/165 [00:00<00:00, 150.25it/s] 93%|█████████▎| 154/165 [00:01<00:00, 150.56it/s]100%|██████████| 165/165 [00:01<00:00, 148.67it/s]
Using the latest cached version of the dataset since gsm8k couldn't be found on the Hugging Face Hub
2024-06-04:06:33:17,529 WARNING  [load.py:1631] Using the latest cached version of the dataset since gsm8k couldn't be found on the Hugging Face Hub
Found the latest cached dataset configuration 'main' at /private/home/beidic/.cache/huggingface/datasets/gsm8k/main/0.0.0/e53f048856ff4f594e959d75785d2c2d37b678ee (last modified on Thu May 16 07:01:08 2024).
2024-06-04:06:33:17,530 WARNING  [cache.py:95] Found the latest cached dataset configuration 'main' at /private/home/beidic/.cache/huggingface/datasets/gsm8k/main/0.0.0/e53f048856ff4f594e959d75785d2c2d37b678ee (last modified on Thu May 16 07:01:08 2024).
2024-06-04:06:33:17,692 INFO     [task.py:395] Building contexts for gsm8k on rank 1...
  0%|          | 0/165 [00:00<?, ?it/s] 13%|█▎        | 22/165 [00:00<00:00, 211.24it/s] 27%|██▋       | 44/165 [00:00<00:00, 212.96it/s]Using the latest cached version of the dataset since gsm8k couldn't be found on the Hugging Face Hub
2024-06-04:06:33:17,952 WARNING  [load.py:1631] Using the latest cached version of the dataset since gsm8k couldn't be found on the Hugging Face Hub
Found the latest cached dataset configuration 'main' at /private/home/beidic/.cache/huggingface/datasets/gsm8k/main/0.0.0/e53f048856ff4f594e959d75785d2c2d37b678ee (last modified on Thu May 16 07:01:08 2024).
2024-06-04:06:33:17,954 WARNING  [cache.py:95] Found the latest cached dataset configuration 'main' at /private/home/beidic/.cache/huggingface/datasets/gsm8k/main/0.0.0/e53f048856ff4f594e959d75785d2c2d37b678ee (last modified on Thu May 16 07:01:08 2024).
 40%|████      | 66/165 [00:00<00:00, 213.33it/s] 53%|█████▎    | 88/165 [00:00<00:00, 213.74it/s]2024-06-04:06:33:18,137 INFO     [task.py:395] Building contexts for gsm8k on rank 5...
  0%|          | 0/165 [00:00<?, ?it/s] 67%|██████▋   | 110/165 [00:00<00:00, 213.76it/s] 13%|█▎        | 22/165 [00:00<00:00, 211.96it/s] 80%|████████  | 132/165 [00:00<00:00, 213.66it/s] 27%|██▋       | 44/165 [00:00<00:00, 211.56it/s] 93%|█████████▎| 154/165 [00:00<00:00, 214.12it/s] 40%|████      | 66/165 [00:00<00:00, 211.80it/s]100%|██████████| 165/165 [00:00<00:00, 213.75it/s]
 53%|█████▎    | 88/165 [00:00<00:00, 208.30it/s] 66%|██████▌   | 109/165 [00:00<00:00, 205.90it/s] 79%|███████▉  | 131/165 [00:00<00:00, 207.35it/s] 93%|█████████▎| 153/165 [00:00<00:00, 209.98it/s]100%|██████████| 165/165 [00:00<00:00, 209.88it/s]
Using the latest cached version of the dataset since gsm8k couldn't be found on the Hugging Face Hub
2024-06-04:06:33:22,813 WARNING  [load.py:1631] Using the latest cached version of the dataset since gsm8k couldn't be found on the Hugging Face Hub
Found the latest cached dataset configuration 'main' at /private/home/beidic/.cache/huggingface/datasets/gsm8k/main/0.0.0/e53f048856ff4f594e959d75785d2c2d37b678ee (last modified on Thu May 16 07:01:08 2024).
2024-06-04:06:33:22,815 WARNING  [cache.py:95] Found the latest cached dataset configuration 'main' at /private/home/beidic/.cache/huggingface/datasets/gsm8k/main/0.0.0/e53f048856ff4f594e959d75785d2c2d37b678ee (last modified on Thu May 16 07:01:08 2024).
2024-06-04:06:33:23,046 INFO     [task.py:395] Building contexts for gsm8k on rank 3...
  0%|          | 0/165 [00:00<?, ?it/s] 10%|▉         | 16/165 [00:00<00:00, 151.77it/s] 21%|██        | 35/165 [00:00<00:00, 169.80it/s] 32%|███▏      | 52/165 [00:00<00:00, 158.73it/s]Using the latest cached version of the dataset since gsm8k couldn't be found on the Hugging Face Hub
2024-06-04:06:33:23,481 WARNING  [load.py:1631] Using the latest cached version of the dataset since gsm8k couldn't be found on the Hugging Face Hub
Found the latest cached dataset configuration 'main' at /private/home/beidic/.cache/huggingface/datasets/gsm8k/main/0.0.0/e53f048856ff4f594e959d75785d2c2d37b678ee (last modified on Thu May 16 07:01:08 2024).
2024-06-04:06:33:23,483 WARNING  [cache.py:95] Found the latest cached dataset configuration 'main' at /private/home/beidic/.cache/huggingface/datasets/gsm8k/main/0.0.0/e53f048856ff4f594e959d75785d2c2d37b678ee (last modified on Thu May 16 07:01:08 2024).
 43%|████▎     | 71/165 [00:00<00:00, 168.00it/s]Using the latest cached version of the dataset since gsm8k couldn't be found on the Hugging Face Hub
2024-06-04:06:33:23,528 WARNING  [load.py:1631] Using the latest cached version of the dataset since gsm8k couldn't be found on the Hugging Face Hub
Found the latest cached dataset configuration 'main' at /private/home/beidic/.cache/huggingface/datasets/gsm8k/main/0.0.0/e53f048856ff4f594e959d75785d2c2d37b678ee (last modified on Thu May 16 07:01:08 2024).
2024-06-04:06:33:23,530 WARNING  [cache.py:95] Found the latest cached dataset configuration 'main' at /private/home/beidic/.cache/huggingface/datasets/gsm8k/main/0.0.0/e53f048856ff4f594e959d75785d2c2d37b678ee (last modified on Thu May 16 07:01:08 2024).
2024-06-04:06:33:23,612 INFO     [xhuggingface.py:314] Using 8 devices with data parallelism
 53%|█████▎    | 88/165 [00:00<00:00, 163.70it/s]2024-06-04:06:33:23,684 INFO     [task.py:395] Building contexts for gsm8k on rank 7...
Using the latest cached version of the dataset since gsm8k couldn't be found on the Hugging Face Hub
2024-06-04:06:33:23,685 WARNING  [load.py:1631] Using the latest cached version of the dataset since gsm8k couldn't be found on the Hugging Face Hub
Found the latest cached dataset configuration 'main' at /private/home/beidic/.cache/huggingface/datasets/gsm8k/main/0.0.0/e53f048856ff4f594e959d75785d2c2d37b678ee (last modified on Thu May 16 07:01:08 2024).
2024-06-04:06:33:23,687 WARNING  [cache.py:95] Found the latest cached dataset configuration 'main' at /private/home/beidic/.cache/huggingface/datasets/gsm8k/main/0.0.0/e53f048856ff4f594e959d75785d2c2d37b678ee (last modified on Thu May 16 07:01:08 2024).
  0%|          | 0/164 [00:00<?, ?it/s] 64%|██████▎   | 105/165 [00:00<00:00, 153.30it/s]  9%|▉         | 15/164 [00:00<00:01, 141.93it/s]2024-06-04:06:33:23,826 INFO     [task.py:395] Building contexts for gsm8k on rank 4...
 73%|███████▎  | 121/165 [00:00<00:00, 148.30it/s]  0%|          | 0/165 [00:00<?, ?it/s] 18%|█▊        | 30/164 [00:00<00:00, 140.90it/s] 82%|████████▏ | 136/165 [00:00<00:00, 146.60it/s]  9%|▉         | 15/165 [00:00<00:01, 142.24it/s]2024-06-04:06:33:23,974 INFO     [task.py:395] Building contexts for gsm8k on rank 0...
  0%|          | 0/165 [00:00<?, ?it/s] 27%|██▋       | 45/164 [00:00<00:00, 141.11it/s] 92%|█████████▏| 151/165 [00:00<00:00, 145.02it/s] 18%|█▊        | 30/165 [00:00<00:00, 142.22it/s]  9%|▉         | 15/165 [00:00<00:01, 141.77it/s] 37%|███▋      | 60/164 [00:00<00:00, 141.58it/s]100%|██████████| 165/165 [00:01<00:00, 151.60it/s]
 27%|██▋       | 45/165 [00:00<00:00, 144.97it/s] 18%|█▊        | 30/165 [00:00<00:00, 142.06it/s] 46%|████▌     | 75/164 [00:00<00:00, 141.83it/s] 41%|████      | 67/165 [00:00<00:00, 171.63it/s] 27%|██▋       | 45/165 [00:00<00:00, 142.53it/s] 55%|█████▍    | 90/164 [00:00<00:00, 142.04it/s] 54%|█████▍    | 89/165 [00:00<00:00, 186.68it/s] 36%|███▋      | 60/165 [00:00<00:00, 142.66it/s] 64%|██████▍   | 105/164 [00:00<00:00, 142.34it/s] 67%|██████▋   | 111/165 [00:00<00:00, 195.46it/s] 45%|████▌     | 75/165 [00:00<00:00, 142.74it/s] 73%|███████▎  | 120/164 [00:00<00:00, 142.43it/s] 81%|████████  | 133/165 [00:00<00:00, 201.05it/s] 55%|█████▍    | 90/165 [00:00<00:00, 143.12it/s] 82%|████████▏ | 135/164 [00:00<00:00, 142.90it/s] 94%|█████████▍| 155/165 [00:00<00:00, 204.83it/s]100%|██████████| 165/165 [00:00<00:00, 188.34it/s]
 64%|██████▎   | 105/165 [00:00<00:00, 143.29it/s] 91%|█████████▏| 150/164 [00:01<00:00, 142.61it/s] 73%|███████▎  | 120/165 [00:00<00:00, 143.33it/s]100%|██████████| 164/164 [00:01<00:00, 142.36it/s]
 86%|████████▌ | 142/165 [00:00<00:00, 164.49it/s] 99%|█████████▉| 164/165 [00:01<00:00, 180.97it/s]100%|██████████| 165/165 [00:01<00:00, 157.39it/s]
2024-06-04:06:33:29,134 INFO     [xevaluator.py:395] Running generate_until requests
2024-06-04:06:33:29,134 INFO     [xevaluator.py:395] Running generate_until requests
2024-06-04:06:33:29,134 INFO     [xevaluator.py:395] Running generate_until requests
2024-06-04:06:33:29,135 INFO     [xevaluator.py:395] Running generate_until requests
2024-06-04:06:33:29,135 INFO     [xevaluator.py:395] Running generate_until requests
2024-06-04:06:33:29,135 INFO     [xevaluator.py:395] Running generate_until requests
2024-06-04:06:33:29,135 INFO     [xevaluator.py:395] Running generate_until requests
2024-06-04:06:33:29,136 INFO     [xevaluator.py:395] Running generate_until requests
Running generate_until requests:   0%|          | 0/165 [00:00<?, ?it/s]Running generate_until requests:   1%|          | 1/165 [00:12<33:11, 12.14s/it]Running generate_until requests:   1%|          | 2/165 [00:22<30:23, 11.19s/it]Running generate_until requests:   2%|▏         | 3/165 [00:25<19:48,  7.34s/it]Running generate_until requests:   2%|▏         | 4/165 [00:35<22:58,  8.56s/it]Running generate_until requests:   3%|▎         | 5/165 [00:43<21:48,  8.18s/it]Running generate_until requests:   4%|▎         | 6/165 [00:46<17:25,  6.58s/it]Running generate_until requests:   4%|▍         | 7/165 [00:48<13:09,  5.00s/it]Running generate_until requests:   5%|▍         | 8/165 [00:52<12:03,  4.61s/it]Running generate_until requests:   5%|▌         | 9/165 [00:55<10:48,  4.16s/it]Running generate_until requests:   6%|▌         | 10/165 [00:59<10:25,  4.03s/it]Running generate_until requests:   7%|▋         | 11/165 [01:04<11:32,  4.50s/it]Running generate_until requests:   7%|▋         | 12/165 [01:07<09:56,  3.90s/it]Running generate_until requests:   8%|▊         | 13/165 [01:11<09:47,  3.86s/it]Running generate_until requests:   8%|▊         | 14/165 [01:18<12:21,  4.91s/it]Running generate_until requests:   9%|▉         | 15/165 [01:21<10:58,  4.39s/it]Running generate_until requests:  10%|▉         | 16/165 [01:25<10:45,  4.34s/it]Running generate_until requests:  10%|█         | 17/165 [01:30<10:59,  4.45s/it]Running generate_until requests:  11%|█         | 18/165 [01:33<10:07,  4.13s/it]Running generate_until requests:  12%|█▏        | 19/165 [01:40<12:00,  4.94s/it]Running generate_until requests:  12%|█▏        | 20/165 [01:45<11:47,  4.88s/it]Running generate_until requests:  13%|█▎        | 21/165 [01:50<11:36,  4.84s/it]Running generate_until requests:  13%|█▎        | 22/165 [01:53<10:44,  4.51s/it]Running generate_until requests:  14%|█▍        | 23/165 [02:04<14:48,  6.26s/it]Running generate_until requests:  15%|█▍        | 24/165 [02:06<12:05,  5.14s/it]Running generate_until requests:  15%|█▌        | 25/165 [02:11<11:56,  5.12s/it]Running generate_until requests:  16%|█▌        | 26/165 [02:17<12:00,  5.18s/it]Running generate_until requests:  16%|█▋        | 27/165 [02:21<11:02,  4.80s/it]Running generate_until requests:  17%|█▋        | 28/165 [02:29<13:14,  5.80s/it]Running generate_until requests:  18%|█▊        | 29/165 [02:37<14:34,  6.43s/it]Running generate_until requests:  18%|█▊        | 30/165 [02:39<11:31,  5.12s/it]Running generate_until requests:  19%|█▉        | 31/165 [02:43<10:44,  4.81s/it]Running generate_until requests:  19%|█▉        | 32/165 [02:48<11:06,  5.01s/it]Running generate_until requests:  20%|██        | 33/165 [02:50<08:56,  4.06s/it]Running generate_until requests:  21%|██        | 34/165 [02:53<08:20,  3.82s/it]Running generate_until requests:  21%|██        | 35/165 [02:58<08:47,  4.06s/it]Running generate_until requests:  22%|██▏       | 36/165 [03:02<08:54,  4.14s/it]Running generate_until requests:  22%|██▏       | 37/165 [03:04<07:20,  3.44s/it]Running generate_until requests:  23%|██▎       | 38/165 [03:08<07:39,  3.62s/it]Running generate_until requests:  24%|██▎       | 39/165 [03:12<07:30,  3.58s/it]Running generate_until requests:  24%|██▍       | 40/165 [03:15<07:17,  3.50s/it]Running generate_until requests:  25%|██▍       | 41/165 [03:19<07:45,  3.75s/it]Running generate_until requests:  25%|██▌       | 42/165 [03:24<07:57,  3.88s/it]Running generate_until requests:  26%|██▌       | 43/165 [03:27<07:30,  3.69s/it]Running generate_until requests:  27%|██▋       | 44/165 [03:34<09:23,  4.66s/it]Running generate_until requests:  27%|██▋       | 45/165 [03:38<09:19,  4.66s/it]Running generate_until requests:  28%|██▊       | 46/165 [03:42<08:48,  4.44s/it]Running generate_until requests:  28%|██▊       | 47/165 [03:46<08:15,  4.20s/it]Running generate_until requests:  29%|██▉       | 48/165 [03:49<07:20,  3.77s/it]Running generate_until requests:  30%|██▉       | 49/165 [03:53<07:24,  3.83s/it]Running generate_until requests:  30%|███       | 50/165 [03:57<07:31,  3.93s/it]Running generate_until requests:  31%|███       | 51/165 [04:01<07:49,  4.12s/it]Running generate_until requests:  32%|███▏      | 52/165 [04:12<11:14,  5.97s/it]Running generate_until requests:  32%|███▏      | 53/165 [04:20<12:18,  6.59s/it]Running generate_until requests:  33%|███▎      | 54/165 [04:30<14:12,  7.68s/it]Running generate_until requests:  33%|███▎      | 55/165 [04:40<15:29,  8.45s/it]Running generate_until requests:  34%|███▍      | 56/165 [04:44<13:04,  7.20s/it]Running generate_until requests:  35%|███▍      | 57/165 [04:49<11:22,  6.32s/it]Running generate_until requests:  35%|███▌      | 58/165 [04:54<10:45,  6.04s/it]Running generate_until requests:  36%|███▌      | 59/165 [04:58<09:39,  5.47s/it]Running generate_until requests:  36%|███▋      | 60/165 [05:09<12:05,  6.91s/it]Running generate_until requests:  37%|███▋      | 61/165 [05:13<10:26,  6.03s/it]Running generate_until requests:  38%|███▊      | 62/165 [05:16<08:47,  5.12s/it]Running generate_until requests:  38%|███▊      | 63/165 [05:17<06:58,  4.10s/it]Running generate_until requests:  39%|███▉      | 64/165 [05:21<06:31,  3.87s/it]Running generate_until requests:  39%|███▉      | 65/165 [05:23<05:34,  3.35s/it]Running generate_until requests:  40%|████      | 66/165 [05:27<05:53,  3.57s/it]Running generate_until requests:  41%|████      | 67/165 [05:29<05:01,  3.08s/it]Running generate_until requests:  41%|████      | 68/165 [05:35<06:26,  3.99s/it]Running generate_until requests:  42%|████▏     | 69/165 [05:42<07:40,  4.79s/it]Running generate_until requests:  42%|████▏     | 70/165 [05:52<10:11,  6.43s/it]Running generate_until requests:  43%|████▎     | 71/165 [05:59<10:17,  6.57s/it]Running generate_until requests:  44%|████▎     | 72/165 [06:02<08:54,  5.74s/it]Running generate_until requests:  44%|████▍     | 73/165 [06:07<08:26,  5.50s/it]Running generate_until requests:  45%|████▍     | 74/165 [06:11<07:29,  4.94s/it]Running generate_until requests:  45%|████▌     | 75/165 [06:21<09:48,  6.53s/it]Running generate_until requests:  46%|████▌     | 76/165 [06:26<08:51,  5.97s/it]Running generate_until requests:  47%|████▋     | 77/165 [06:36<10:39,  7.27s/it]Running generate_until requests:  47%|████▋     | 78/165 [06:46<11:50,  8.16s/it]Running generate_until requests:  48%|████▊     | 79/165 [06:55<11:46,  8.22s/it]Running generate_until requests:  48%|████▊     | 80/165 [07:00<10:29,  7.40s/it]Running generate_until requests:  49%|████▉     | 81/165 [07:11<11:33,  8.26s/it]Running generate_until requests:  50%|████▉     | 82/165 [07:14<09:16,  6.70s/it]Running generate_until requests:  50%|█████     | 83/165 [07:23<10:04,  7.37s/it]Running generate_until requests:  51%|█████     | 84/165 [07:27<08:38,  6.40s/it]Running generate_until requests:  52%|█████▏    | 85/165 [07:33<08:36,  6.46s/it]Running generate_until requests:  52%|█████▏    | 86/165 [07:42<09:32,  7.25s/it]Running generate_until requests:  53%|█████▎    | 87/165 [07:46<08:03,  6.19s/it]Running generate_until requests:  53%|█████▎    | 88/165 [07:50<06:58,  5.44s/it]Running generate_until requests:  54%|█████▍    | 89/165 [07:55<06:41,  5.29s/it]Running generate_until requests:  55%|█████▍    | 90/165 [07:57<05:31,  4.42s/it]Running generate_until requests:  55%|█████▌    | 91/165 [08:03<05:49,  4.73s/it]Running generate_until requests:  56%|█████▌    | 92/165 [08:05<05:01,  4.13s/it]Running generate_until requests:  56%|█████▋    | 93/165 [08:11<05:31,  4.60s/it]Running generate_until requests:  57%|█████▋    | 94/165 [08:17<05:46,  4.88s/it]Running generate_until requests:  58%|█████▊    | 95/165 [08:22<05:54,  5.06s/it]Running generate_until requests:  58%|█████▊    | 96/165 [08:26<05:25,  4.72s/it]Running generate_until requests:  59%|█████▉    | 97/165 [08:29<04:41,  4.14s/it]Running generate_until requests:  59%|█████▉    | 98/165 [08:32<04:20,  3.88s/it]Running generate_until requests:  60%|██████    | 99/165 [08:36<04:12,  3.82s/it]Running generate_until requests:  61%|██████    | 100/165 [08:39<04:00,  3.70s/it]Running generate_until requests:  61%|██████    | 101/165 [08:43<03:53,  3.65s/it]Running generate_until requests:  62%|██████▏   | 102/165 [08:53<05:54,  5.63s/it]Running generate_until requests:  62%|██████▏   | 103/165 [09:03<07:14,  7.01s/it]Running generate_until requests:  63%|██████▎   | 104/165 [09:05<05:37,  5.53s/it]Running generate_until requests:  64%|██████▎   | 105/165 [09:11<05:32,  5.54s/it]Running generate_until requests:  64%|██████▍   | 106/165 [09:14<04:38,  4.71s/it]Running generate_until requests:  65%|██████▍   | 107/165 [09:24<06:09,  6.37s/it]Running generate_until requests:  65%|██████▌   | 108/165 [09:26<04:59,  5.26s/it]Running generate_until requests:  66%|██████▌   | 109/165 [09:30<04:28,  4.80s/it]Running generate_until requests:  67%|██████▋   | 110/165 [09:35<04:25,  4.83s/it]Running generate_until requests:  67%|██████▋   | 111/165 [09:45<05:48,  6.45s/it]Running generate_until requests:  68%|██████▊   | 112/165 [09:48<04:47,  5.42s/it]Running generate_until requests:  68%|██████▊   | 113/165 [09:53<04:22,  5.05s/it]Running generate_until requests:  69%|██████▉   | 114/165 [09:57<04:13,  4.97s/it]Running generate_until requests:  70%|██████▉   | 115/165 [10:00<03:33,  4.27s/it]Running generate_until requests:  70%|███████   | 116/165 [10:02<03:01,  3.70s/it]Running generate_until requests:  71%|███████   | 117/165 [10:04<02:25,  3.03s/it]Running generate_until requests:  72%|███████▏  | 118/165 [10:07<02:25,  3.10s/it]Running generate_until requests:  72%|███████▏  | 119/165 [10:11<02:30,  3.27s/it]Running generate_until requests:  73%|███████▎  | 120/165 [10:14<02:25,  3.23s/it]Running generate_until requests:  73%|███████▎  | 121/165 [10:16<02:09,  2.95s/it]Running generate_until requests:  74%|███████▍  | 122/165 [10:20<02:24,  3.35s/it]Running generate_until requests:  75%|███████▍  | 123/165 [10:26<02:53,  4.13s/it]Running generate_until requests:  75%|███████▌  | 124/165 [10:32<03:08,  4.60s/it]Running generate_until requests:  76%|███████▌  | 125/165 [10:35<02:44,  4.12s/it]Running generate_until requests:  76%|███████▋  | 126/165 [10:38<02:31,  3.88s/it]Running generate_until requests:  77%|███████▋  | 127/165 [10:45<02:57,  4.68s/it]Running generate_until requests:  78%|███████▊  | 128/165 [10:48<02:38,  4.28s/it]Running generate_until requests:  78%|███████▊  | 129/165 [10:53<02:37,  4.39s/it]Running generate_until requests:  79%|███████▉  | 130/165 [10:59<02:51,  4.91s/it]Running generate_until requests:  79%|███████▉  | 131/165 [11:09<03:40,  6.50s/it]Running generate_until requests:  80%|████████  | 132/165 [11:13<03:06,  5.66s/it]Running generate_until requests:  81%|████████  | 133/165 [11:17<02:42,  5.09s/it]Running generate_until requests:  81%|████████  | 134/165 [11:22<02:34,  5.00s/it]Running generate_until requests:  82%|████████▏ | 135/165 [11:23<02:01,  4.06s/it]Running generate_until requests:  82%|████████▏ | 136/165 [11:26<01:41,  3.52s/it]Running generate_until requests:  83%|████████▎ | 137/165 [11:30<01:43,  3.71s/it]Running generate_until requests:  84%|████████▎ | 138/165 [11:36<01:56,  4.33s/it]Running generate_until requests:  84%|████████▍ | 139/165 [11:38<01:39,  3.84s/it]Running generate_until requests:  85%|████████▍ | 140/165 [11:41<01:28,  3.54s/it]Running generate_until requests:  85%|████████▌ | 141/165 [11:47<01:40,  4.18s/it]Running generate_until requests:  86%|████████▌ | 142/165 [11:49<01:23,  3.62s/it]Running generate_until requests:  87%|████████▋ | 143/165 [11:52<01:13,  3.35s/it]Running generate_until requests:  87%|████████▋ | 144/165 [11:56<01:17,  3.67s/it]Running generate_until requests:  88%|████████▊ | 145/165 [12:01<01:17,  3.86s/it]Running generate_until requests:  88%|████████▊ | 146/165 [12:05<01:16,  4.01s/it]Running generate_until requests:  89%|████████▉ | 147/165 [12:09<01:15,  4.18s/it]Running generate_until requests:  90%|████████▉ | 148/165 [12:15<01:20,  4.72s/it]Running generate_until requests:  90%|█████████ | 149/165 [12:18<01:03,  3.95s/it]Running generate_until requests:  91%|█████████ | 150/165 [12:21<00:55,  3.69s/it]Running generate_until requests:  92%|█████████▏| 151/165 [12:24<00:51,  3.68s/it]Running generate_until requests:  92%|█████████▏| 152/165 [12:27<00:44,  3.45s/it]Running generate_until requests:  93%|█████████▎| 153/165 [12:37<01:05,  5.47s/it]Running generate_until requests:  93%|█████████▎| 154/165 [12:41<00:55,  5.03s/it]Running generate_until requests:  94%|█████████▍| 155/165 [12:43<00:41,  4.11s/it]Running generate_until requests:  95%|█████████▍| 156/165 [12:48<00:38,  4.32s/it]Running generate_until requests:  95%|█████████▌| 157/165 [12:51<00:31,  3.99s/it]Running generate_until requests:  96%|█████████▌| 158/165 [13:02<00:40,  5.85s/it]Running generate_until requests:  96%|█████████▋| 159/165 [13:07<00:33,  5.59s/it]Running generate_until requests:  97%|█████████▋| 160/165 [13:12<00:27,  5.48s/it]Running generate_until requests:  98%|█████████▊| 161/165 [13:15<00:18,  4.74s/it]Running generate_until requests:  98%|█████████▊| 162/165 [13:25<00:19,  6.37s/it]Running generate_until requests:  99%|█████████▉| 163/165 [13:29<00:11,  5.51s/it]Running generate_until requests:  99%|█████████▉| 164/165 [13:32<00:04,  4.76s/it]Running generate_until requests: 100%|██████████| 165/165 [13:36<00:00,  4.79s/it]Running generate_until requests: 100%|██████████| 165/165 [13:36<00:00,  4.95s/it]
[2024-06-04 06:58:19,524] torch.distributed.elastic.multiprocessing.api: [ERROR] failed (exitcode: -7) local_rank: 0 (pid: 1878147) of binary: /private/home/beidic/.conda/envs/griffin/bin/python
Traceback (most recent call last):
  File "/private/home/beidic/.conda/envs/griffin/bin/accelerate", line 8, in <module>
    sys.exit(main())
             ^^^^^^
  File "/private/home/beidic/.conda/envs/griffin/lib/python3.12/site-packages/accelerate/commands/accelerate_cli.py", line 47, in main
    args.func(args)
  File "/private/home/beidic/.conda/envs/griffin/lib/python3.12/site-packages/accelerate/commands/launch.py", line 985, in launch_command
    multi_gpu_launcher(args)
  File "/private/home/beidic/.conda/envs/griffin/lib/python3.12/site-packages/accelerate/commands/launch.py", line 654, in multi_gpu_launcher
    distrib_run.run(args)
  File "/private/home/beidic/.conda/envs/griffin/lib/python3.12/site-packages/torch/distributed/run.py", line 803, in run
    elastic_launch(
  File "/private/home/beidic/.conda/envs/griffin/lib/python3.12/site-packages/torch/distributed/launcher/api.py", line 135, in __call__
    return launch_agent(self._config, self._entrypoint, list(args))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/private/home/beidic/.conda/envs/griffin/lib/python3.12/site-packages/torch/distributed/launcher/api.py", line 268, in launch_agent
    raise ChildFailedError(
torch.distributed.elastic.multiprocessing.errors.ChildFailedError: 
=======================================================
main.py FAILED
-------------------------------------------------------
Failures:
  <NO_OTHER_FAILURES>
-------------------------------------------------------
Root Cause (first observed failure):
[0]:
  time      : 2024-06-04_06:58:19
  host      : learnfair7564.h2.fair
  rank      : 0 (local_rank: 0)
  exitcode  : -7 (pid: 1878147)
  error_file: <N/A>
  traceback : Signal 7 (SIGBUS) received by PID 1878147
=======================================================
/var/spool/slurm//job28572750/slurm_script: line 59: 1878124 Bus error               (core dumped) accelerate launch --main_process_port 29510 --num_processes 8 --num_machines 1 main.py --model xhf --model_args pretrained=meta-llama/Llama-2-7b-hf,cats=True,check=False --tasks gsm8k --batch_size 1
