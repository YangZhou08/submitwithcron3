Already on 'yangexp2'
wandb: Currently logged in as: stevenzhou0816100. Use `wandb login --relogin` to force relogin
Traceback (most recent call last):
  File "/private/home/beidic/.conda/envs/griffin/bin/huggingface-cli", line 8, in <module>
    sys.exit(main())
             ^^^^^^
  File "/private/home/beidic/.conda/envs/griffin/lib/python3.12/site-packages/huggingface_hub/commands/huggingface_cli.py", line 51, in main
    service.run()
  File "/private/home/beidic/.conda/envs/griffin/lib/python3.12/site-packages/huggingface_hub/commands/user.py", line 98, in run
    login(token=self.args.token, add_to_git_credential=self.args.add_to_git_credential)
  File "/private/home/beidic/.conda/envs/griffin/lib/python3.12/site-packages/huggingface_hub/_login.py", line 111, in login
    _login(token, add_to_git_credential=add_to_git_credential, write_permission=write_permission)
  File "/private/home/beidic/.conda/envs/griffin/lib/python3.12/site-packages/huggingface_hub/_login.py", line 307, in _login
    raise ValueError("Invalid token passed!")
ValueError: Invalid token passed!
The following values were not passed to `accelerate launch` and had defaults used instead:
		More than one GPU was found, enabling multi-GPU training.
		If this was unintended please pass in `--num_processes=1`.
	`--mixed_precision` was set to a value of `'no'`
	`--dynamo_backend` was set to a value of `'no'`
To avoid this warning pass in values for each of the problematic parameters or run `accelerate config`.
2024-06-03:14:41:51,446 INFO     [main.py:288] Verbosity set to INFO
2024-06-03:14:41:51,446 INFO     [main.py:288] Verbosity set to INFO
2024-06-03:14:41:51,446 INFO     [main.py:288] Verbosity set to INFO
2024-06-03:14:41:51,449 INFO     [main.py:288] Verbosity set to INFO
2024-06-03:14:41:51,503 INFO     [main.py:288] Verbosity set to INFO
2024-06-03:14:41:51,587 INFO     [main.py:288] Verbosity set to INFO
2024-06-03:14:41:51,601 INFO     [main.py:288] Verbosity set to INFO
2024-06-03:14:41:51,706 INFO     [main.py:288] Verbosity set to INFO
2024-06-03:14:41:57,678 INFO     [main.py:378] Selected Tasks: ['gsm8k']
2024-06-03:14:41:57,679 INFO     [main.py:378] Selected Tasks: ['gsm8k']
2024-06-03:14:41:57,680 INFO     [main.py:378] Selected Tasks: ['gsm8k']
2024-06-03:14:41:57,688 INFO     [xevaluator.py:137] Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234
2024-06-03:14:41:57,688 INFO     [xevaluator.py:137] Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234
2024-06-03:14:41:57,688 INFO     [xevaluator.py:184] Initializing xhf model, with arguments: {'pretrained': 'meta-llama/Llama-2-7b-hf', 'griffin': True, 'check': True, 'kernel_size': 16, 'spr': 0.5, 'thr': 0.1}
2024-06-03:14:41:57,688 INFO     [xevaluator.py:137] Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234
2024-06-03:14:41:57,688 INFO     [xevaluator.py:184] Initializing xhf model, with arguments: {'pretrained': 'meta-llama/Llama-2-7b-hf', 'griffin': True, 'check': True, 'kernel_size': 16, 'spr': 0.5, 'thr': 0.1}
2024-06-03:14:41:57,688 INFO     [xevaluator.py:184] Initializing xhf model, with arguments: {'pretrained': 'meta-llama/Llama-2-7b-hf', 'griffin': True, 'check': True, 'kernel_size': 16, 'spr': 0.5, 'thr': 0.1}
2024-06-03:14:41:58,221 INFO     [main.py:378] Selected Tasks: ['gsm8k']
2024-06-03:14:41:58,227 INFO     [xevaluator.py:137] Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234
2024-06-03:14:41:58,227 INFO     [xevaluator.py:184] Initializing xhf model, with arguments: {'pretrained': 'meta-llama/Llama-2-7b-hf', 'griffin': True, 'check': True, 'kernel_size': 16, 'spr': 0.5, 'thr': 0.1}
2024-06-03:14:41:58,393 INFO     [main.py:378] Selected Tasks: ['gsm8k']
2024-06-03:14:41:58,397 INFO     [xevaluator.py:137] Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234
2024-06-03:14:41:58,398 INFO     [xevaluator.py:184] Initializing xhf model, with arguments: {'pretrained': 'meta-llama/Llama-2-7b-hf', 'griffin': True, 'check': True, 'kernel_size': 16, 'spr': 0.5, 'thr': 0.1}
2024-06-03:14:41:58,613 INFO     [main.py:378] Selected Tasks: ['gsm8k']
2024-06-03:14:41:58,618 INFO     [xevaluator.py:137] Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234
2024-06-03:14:41:58,618 INFO     [xevaluator.py:184] Initializing xhf model, with arguments: {'pretrained': 'meta-llama/Llama-2-7b-hf', 'griffin': True, 'check': True, 'kernel_size': 16, 'spr': 0.5, 'thr': 0.1}
2024-06-03:14:41:58,692 INFO     [main.py:378] Selected Tasks: ['gsm8k']
2024-06-03:14:41:58,697 INFO     [xevaluator.py:137] Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234
2024-06-03:14:41:58,697 INFO     [xevaluator.py:184] Initializing xhf model, with arguments: {'pretrained': 'meta-llama/Llama-2-7b-hf', 'griffin': True, 'check': True, 'kernel_size': 16, 'spr': 0.5, 'thr': 0.1}
2024-06-03:14:41:58,789 INFO     [main.py:378] Selected Tasks: ['gsm8k']
2024-06-03:14:41:58,793 INFO     [xevaluator.py:137] Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234
2024-06-03:14:41:58,793 INFO     [xevaluator.py:184] Initializing xhf model, with arguments: {'pretrained': 'meta-llama/Llama-2-7b-hf', 'griffin': True, 'check': True, 'kernel_size': 16, 'spr': 0.5, 'thr': 0.1}
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:47<00:47, 47.86s/it]Loading checkpoint shards:  50%|█████     | 1/2 [00:50<00:50, 50.39s/it]Loading checkpoint shards:  50%|█████     | 1/2 [00:50<00:50, 50.56s/it]Loading checkpoint shards:  50%|█████     | 1/2 [00:50<00:50, 50.57s/it]Loading checkpoint shards:  50%|█████     | 1/2 [00:49<00:49, 49.82s/it]Loading checkpoint shards:  50%|█████     | 1/2 [00:50<00:50, 50.56s/it]Loading checkpoint shards:  50%|█████     | 1/2 [00:50<00:50, 50.46s/it]Loading checkpoint shards:  50%|█████     | 1/2 [00:50<00:50, 50.03s/it]Loading checkpoint shards: 100%|██████████| 2/2 [01:03<00:00, 28.80s/it]Loading checkpoint shards: 100%|██████████| 2/2 [01:03<00:00, 31.99s/it]
Loading checkpoint shards: 100%|██████████| 2/2 [01:05<00:00, 29.47s/it]Loading checkpoint shards: 100%|██████████| 2/2 [01:05<00:00, 32.64s/it]
Loading checkpoint shards: 100%|██████████| 2/2 [01:04<00:00, 29.54s/it]Loading checkpoint shards: 100%|██████████| 2/2 [01:04<00:00, 32.29s/it]
Loading checkpoint shards: 100%|██████████| 2/2 [01:05<00:00, 29.42s/it]Loading checkpoint shards: 100%|██████████| 2/2 [01:05<00:00, 32.57s/it]
Loading checkpoint shards: 100%|██████████| 2/2 [01:05<00:00, 29.48s/it]Loading checkpoint shards: 100%|██████████| 2/2 [01:05<00:00, 32.64s/it]
Loading checkpoint shards: 100%|██████████| 2/2 [01:05<00:00, 29.49s/it]Loading checkpoint shards: 100%|██████████| 2/2 [01:05<00:00, 32.65s/it]
Loading checkpoint shards: 100%|██████████| 2/2 [01:04<00:00, 29.22s/it]Loading checkpoint shards: 100%|██████████| 2/2 [01:04<00:00, 32.31s/it]
Loading checkpoint shards: 100%|██████████| 2/2 [01:05<00:00, 29.46s/it]Loading checkpoint shards: 100%|██████████| 2/2 [01:05<00:00, 32.61s/it]
Using the latest cached version of the dataset since gsm8k couldn't be found on the Hugging Face Hub
2024-06-03:14:43:41,463 WARNING  [load.py:1631] Using the latest cached version of the dataset since gsm8k couldn't be found on the Hugging Face Hub
Found the latest cached dataset configuration 'main' at /private/home/beidic/.cache/huggingface/datasets/gsm8k/main/0.0.0/e53f048856ff4f594e959d75785d2c2d37b678ee (last modified on Thu May 16 07:01:08 2024).
2024-06-03:14:43:41,466 WARNING  [cache.py:95] Found the latest cached dataset configuration 'main' at /private/home/beidic/.cache/huggingface/datasets/gsm8k/main/0.0.0/e53f048856ff4f594e959d75785d2c2d37b678ee (last modified on Thu May 16 07:01:08 2024).
2024-06-03:14:43:41,760 INFO     [task.py:395] Building contexts for gsm8k on rank 7...
  0%|          | 0/164 [00:00<?, ?it/s] 13%|█▎        | 21/164 [00:00<00:00, 203.13it/s] 26%|██▌       | 42/164 [00:00<00:00, 204.66it/s] 38%|███▊      | 63/164 [00:00<00:00, 205.16it/s] 51%|█████     | 84/164 [00:00<00:00, 205.49it/s] 64%|██████▍   | 105/164 [00:00<00:00, 205.95it/s] 77%|███████▋  | 126/164 [00:00<00:00, 206.26it/s] 90%|████████▉ | 147/164 [00:00<00:00, 206.24it/s]100%|██████████| 164/164 [00:00<00:00, 205.84it/s]
Using the latest cached version of the dataset since gsm8k couldn't be found on the Hugging Face Hub
2024-06-03:14:43:45,820 WARNING  [load.py:1631] Using the latest cached version of the dataset since gsm8k couldn't be found on the Hugging Face Hub
Found the latest cached dataset configuration 'main' at /private/home/beidic/.cache/huggingface/datasets/gsm8k/main/0.0.0/e53f048856ff4f594e959d75785d2c2d37b678ee (last modified on Thu May 16 07:01:08 2024).
2024-06-03:14:43:45,822 WARNING  [cache.py:95] Found the latest cached dataset configuration 'main' at /private/home/beidic/.cache/huggingface/datasets/gsm8k/main/0.0.0/e53f048856ff4f594e959d75785d2c2d37b678ee (last modified on Thu May 16 07:01:08 2024).
2024-06-03:14:43:46,063 INFO     [task.py:395] Building contexts for gsm8k on rank 5...
  0%|          | 0/165 [00:00<?, ?it/s] 10%|▉         | 16/165 [00:00<00:00, 153.31it/s] 19%|█▉        | 32/165 [00:00<00:00, 154.20it/s] 29%|██▉       | 48/165 [00:00<00:00, 155.33it/s] 39%|███▉      | 64/165 [00:00<00:00, 155.33it/s] 48%|████▊     | 80/165 [00:00<00:00, 155.07it/s] 58%|█████▊    | 96/165 [00:00<00:00, 154.84it/s] 68%|██████▊   | 112/165 [00:00<00:00, 154.96it/s] 78%|███████▊  | 128/165 [00:00<00:00, 154.67it/s] 87%|████████▋ | 144/165 [00:00<00:00, 154.49it/s] 97%|█████████▋| 160/165 [00:01<00:00, 154.44it/s]100%|██████████| 165/165 [00:01<00:00, 154.68it/s]
2024-06-03:14:43:49,097 INFO     [xhuggingface.py:314] Using 8 devices with data parallelism
Using the latest cached version of the dataset since gsm8k couldn't be found on the Hugging Face Hub
2024-06-03:14:43:49,339 WARNING  [load.py:1631] Using the latest cached version of the dataset since gsm8k couldn't be found on the Hugging Face Hub
Found the latest cached dataset configuration 'main' at /private/home/beidic/.cache/huggingface/datasets/gsm8k/main/0.0.0/e53f048856ff4f594e959d75785d2c2d37b678ee (last modified on Thu May 16 07:01:08 2024).
2024-06-03:14:43:49,341 WARNING  [cache.py:95] Found the latest cached dataset configuration 'main' at /private/home/beidic/.cache/huggingface/datasets/gsm8k/main/0.0.0/e53f048856ff4f594e959d75785d2c2d37b678ee (last modified on Thu May 16 07:01:08 2024).
2024-06-03:14:43:49,504 INFO     [task.py:395] Building contexts for gsm8k on rank 0...
  0%|          | 0/165 [00:00<?, ?it/s] 13%|█▎        | 21/165 [00:00<00:00, 208.49it/s] 26%|██▌       | 43/165 [00:00<00:00, 209.76it/s] 39%|███▉      | 64/165 [00:00<00:00, 209.59it/s] 52%|█████▏    | 85/165 [00:00<00:00, 209.75it/s] 65%|██████▍   | 107/165 [00:00<00:00, 210.24it/s] 78%|███████▊  | 129/165 [00:00<00:00, 209.98it/s] 92%|█████████▏| 151/165 [00:00<00:00, 210.08it/s]100%|██████████| 165/165 [00:00<00:00, 209.89it/s]
Using the latest cached version of the dataset since gsm8k couldn't be found on the Hugging Face Hub
2024-06-03:14:43:52,500 WARNING  [load.py:1631] Using the latest cached version of the dataset since gsm8k couldn't be found on the Hugging Face Hub
Found the latest cached dataset configuration 'main' at /private/home/beidic/.cache/huggingface/datasets/gsm8k/main/0.0.0/e53f048856ff4f594e959d75785d2c2d37b678ee (last modified on Thu May 16 07:01:08 2024).
2024-06-03:14:43:52,502 WARNING  [cache.py:95] Found the latest cached dataset configuration 'main' at /private/home/beidic/.cache/huggingface/datasets/gsm8k/main/0.0.0/e53f048856ff4f594e959d75785d2c2d37b678ee (last modified on Thu May 16 07:01:08 2024).
2024-06-03:14:43:52,756 INFO     [task.py:395] Building contexts for gsm8k on rank 2...
  0%|          | 0/165 [00:00<?, ?it/s]Using the latest cached version of the dataset since gsm8k couldn't be found on the Hugging Face Hub
2024-06-03:14:43:52,877 WARNING  [load.py:1631] Using the latest cached version of the dataset since gsm8k couldn't be found on the Hugging Face Hub
Found the latest cached dataset configuration 'main' at /private/home/beidic/.cache/huggingface/datasets/gsm8k/main/0.0.0/e53f048856ff4f594e959d75785d2c2d37b678ee (last modified on Thu May 16 07:01:08 2024).
2024-06-03:14:43:52,879 WARNING  [cache.py:95] Found the latest cached dataset configuration 'main' at /private/home/beidic/.cache/huggingface/datasets/gsm8k/main/0.0.0/e53f048856ff4f594e959d75785d2c2d37b678ee (last modified on Thu May 16 07:01:08 2024).
  9%|▉         | 15/165 [00:00<00:01, 149.34it/s] 18%|█▊        | 30/165 [00:00<00:00, 149.27it/s]2024-06-03:14:43:53,049 INFO     [task.py:395] Building contexts for gsm8k on rank 1...
  0%|          | 0/165 [00:00<?, ?it/s] 28%|██▊       | 46/165 [00:00<00:00, 150.07it/s]  9%|▉         | 15/165 [00:00<00:01, 141.22it/s] 38%|███▊      | 62/165 [00:00<00:00, 150.69it/s]Using the latest cached version of the dataset since gsm8k couldn't be found on the Hugging Face Hub
2024-06-03:14:43:53,222 WARNING  [load.py:1631] Using the latest cached version of the dataset since gsm8k couldn't be found on the Hugging Face Hub
Found the latest cached dataset configuration 'main' at /private/home/beidic/.cache/huggingface/datasets/gsm8k/main/0.0.0/e53f048856ff4f594e959d75785d2c2d37b678ee (last modified on Thu May 16 07:01:08 2024).
2024-06-03:14:43:53,224 WARNING  [cache.py:95] Found the latest cached dataset configuration 'main' at /private/home/beidic/.cache/huggingface/datasets/gsm8k/main/0.0.0/e53f048856ff4f594e959d75785d2c2d37b678ee (last modified on Thu May 16 07:01:08 2024).
 19%|█▉        | 31/165 [00:00<00:00, 151.97it/s] 47%|████▋     | 78/165 [00:00<00:00, 150.20it/s] 31%|███       | 51/165 [00:00<00:00, 173.11it/s] 57%|█████▋    | 94/165 [00:00<00:00, 150.46it/s]2024-06-03:14:43:53,437 INFO     [task.py:395] Building contexts for gsm8k on rank 4...
  0%|          | 0/165 [00:00<?, ?it/s]Using the latest cached version of the dataset since gsm8k couldn't be found on the Hugging Face Hub
2024-06-03:14:43:53,481 WARNING  [load.py:1631] Using the latest cached version of the dataset since gsm8k couldn't be found on the Hugging Face Hub
 43%|████▎     | 71/165 [00:00<00:00, 182.44it/s]Found the latest cached dataset configuration 'main' at /private/home/beidic/.cache/huggingface/datasets/gsm8k/main/0.0.0/e53f048856ff4f594e959d75785d2c2d37b678ee (last modified on Thu May 16 07:01:08 2024).
2024-06-03:14:43:53,483 WARNING  [cache.py:95] Found the latest cached dataset configuration 'main' at /private/home/beidic/.cache/huggingface/datasets/gsm8k/main/0.0.0/e53f048856ff4f594e959d75785d2c2d37b678ee (last modified on Thu May 16 07:01:08 2024).
 67%|██████▋   | 110/165 [00:00<00:00, 149.96it/s] 12%|█▏        | 20/165 [00:00<00:00, 192.21it/s]Using the latest cached version of the dataset since gsm8k couldn't be found on the Hugging Face Hub
2024-06-03:14:43:53,613 WARNING  [load.py:1631] Using the latest cached version of the dataset since gsm8k couldn't be found on the Hugging Face Hub
Found the latest cached dataset configuration 'main' at /private/home/beidic/.cache/huggingface/datasets/gsm8k/main/0.0.0/e53f048856ff4f594e959d75785d2c2d37b678ee (last modified on Thu May 16 07:01:08 2024).
2024-06-03:14:43:53,615 WARNING  [cache.py:95] Found the latest cached dataset configuration 'main' at /private/home/beidic/.cache/huggingface/datasets/gsm8k/main/0.0.0/e53f048856ff4f594e959d75785d2c2d37b678ee (last modified on Thu May 16 07:01:08 2024).
 55%|█████▍    | 90/165 [00:00<00:00, 164.96it/s] 76%|███████▌  | 125/165 [00:00<00:00, 148.48it/s] 24%|██▍       | 40/165 [00:00<00:00, 188.70it/s] 65%|██████▍   | 107/165 [00:00<00:00, 154.56it/s] 85%|████████▍ | 140/165 [00:00<00:00, 132.54it/s] 36%|███▌      | 59/165 [00:00<00:00, 187.75it/s]2024-06-03:14:43:53,809 INFO     [task.py:395] Building contexts for gsm8k on rank 3...
  0%|          | 0/165 [00:00<?, ?it/s]2024-06-03:14:43:53,854 INFO     [task.py:395] Building contexts for gsm8k on rank 6...
 75%|███████▍  | 123/165 [00:00<00:00, 149.49it/s] 47%|████▋     | 78/165 [00:00<00:00, 187.25it/s]  0%|          | 0/165 [00:00<?, ?it/s] 93%|█████████▎| 154/165 [00:01<00:00, 119.39it/s]  9%|▉         | 15/165 [00:00<00:01, 141.90it/s] 84%|████████▍ | 139/165 [00:00<00:00, 147.34it/s]100%|██████████| 165/165 [00:01<00:00, 139.70it/s]
 59%|█████▉    | 97/165 [00:00<00:00, 186.60it/s]  9%|▉         | 15/165 [00:00<00:01, 143.16it/s] 18%|█▊        | 30/165 [00:00<00:00, 142.06it/s] 93%|█████████▎| 154/165 [00:01<00:00, 145.66it/s] 70%|███████   | 116/165 [00:00<00:00, 186.21it/s] 18%|█▊        | 30/165 [00:00<00:00, 144.00it/s]100%|██████████| 165/165 [00:01<00:00, 153.02it/s]
 27%|██▋       | 45/165 [00:00<00:00, 143.79it/s] 82%|████████▏ | 135/165 [00:00<00:00, 185.96it/s] 28%|██▊       | 46/165 [00:00<00:00, 147.59it/s] 37%|███▋      | 61/165 [00:00<00:00, 149.21it/s] 93%|█████████▎| 154/165 [00:00<00:00, 185.77it/s] 37%|███▋      | 61/165 [00:00<00:00, 146.77it/s]100%|██████████| 165/165 [00:00<00:00, 186.65it/s]
 46%|████▌     | 76/165 [00:00<00:00, 138.64it/s] 46%|████▌     | 76/165 [00:00<00:00, 146.23it/s] 55%|█████▌    | 91/165 [00:00<00:00, 142.25it/s] 55%|█████▌    | 91/165 [00:00<00:00, 146.26it/s] 65%|██████▍   | 107/165 [00:00<00:00, 145.13it/s] 64%|██████▍   | 106/165 [00:00<00:00, 146.16it/s] 75%|███████▍  | 123/165 [00:00<00:00, 147.45it/s] 73%|███████▎  | 121/165 [00:00<00:00, 146.21it/s] 86%|████████▌ | 142/165 [00:00<00:00, 158.25it/s] 82%|████████▏ | 136/165 [00:00<00:00, 146.46it/s] 96%|█████████▌| 158/165 [00:01<00:00, 152.99it/s] 92%|█████████▏| 151/165 [00:01<00:00, 146.28it/s]100%|██████████| 165/165 [00:01<00:00, 146.31it/s]
100%|██████████| 165/165 [00:01<00:00, 146.27it/s]
2024-06-03:14:43:58,656 INFO     [xevaluator.py:395] Running generate_until requests
2024-06-03:14:43:58,657 INFO     [xevaluator.py:395] Running generate_until requests
2024-06-03:14:43:58,657 INFO     [xevaluator.py:395] Running generate_until requests
2024-06-03:14:43:58,657 INFO     [xevaluator.py:395] Running generate_until requests
2024-06-03:14:43:58,657 INFO     [xevaluator.py:395] Running generate_until requests
2024-06-03:14:43:58,657 INFO     [xevaluator.py:395] Running generate_until requests
2024-06-03:14:43:58,657 INFO     [xevaluator.py:395] Running generate_until requests
Running generate_until requests:   0%|          | 0/165 [00:00<?, ?it/s]2024-06-03:14:43:58,657 INFO     [xevaluator.py:395] Running generate_until requests
Running generate_until requests:   1%|          | 1/165 [00:13<38:15, 13.99s/it]Running generate_until requests:   1%|          | 2/165 [00:20<25:36,  9.43s/it]Running generate_until requests:   2%|▏         | 3/165 [00:23<18:16,  6.77s/it]Running generate_until requests:   2%|▏         | 4/165 [00:34<21:55,  8.17s/it]Running generate_until requests:   3%|▎         | 5/165 [00:43<22:29,  8.43s/it]Running generate_until requests:   4%|▎         | 6/165 [00:51<22:19,  8.42s/it]Running generate_until requests:   4%|▍         | 7/165 [00:53<16:39,  6.32s/it]Running generate_until requests:   5%|▍         | 8/165 [00:59<16:32,  6.32s/it]Running generate_until requests:   5%|▌         | 9/165 [01:03<14:23,  5.54s/it]Running generate_until requests:   6%|▌         | 10/165 [01:07<13:09,  5.10s/it]Running generate_until requests:   7%|▋         | 11/165 [01:14<14:19,  5.58s/it]Running generate_until requests:   7%|▋         | 12/165 [01:17<12:18,  4.82s/it]Running generate_until requests:   8%|▊         | 13/165 [01:27<16:33,  6.54s/it]Running generate_until requests:   8%|▊         | 14/165 [01:40<21:09,  8.41s/it]Running generate_until requests:   9%|▉         | 15/165 [01:43<16:59,  6.79s/it]Running generate_until requests:  10%|▉         | 16/165 [01:49<16:01,  6.46s/it]Running generate_until requests:  10%|█         | 17/165 [01:54<14:39,  5.94s/it]Running generate_until requests:  11%|█         | 18/165 [01:58<13:35,  5.55s/it]Running generate_until requests:  12%|█▏        | 19/165 [02:02<12:22,  5.09s/it]Running generate_until requests:  12%|█▏        | 20/165 [02:14<17:25,  7.21s/it]Running generate_until requests:  13%|█▎        | 21/165 [02:21<16:53,  7.04s/it]Running generate_until requests:  13%|█▎        | 22/165 [02:26<15:03,  6.32s/it]Running generate_until requests:  14%|█▍        | 23/165 [02:39<19:43,  8.34s/it]Running generate_until requests:  15%|█▍        | 24/165 [02:42<16:12,  6.90s/it]Running generate_until requests:  15%|█▌        | 25/165 [02:51<17:29,  7.50s/it]Running generate_until requests:  16%|█▌        | 26/165 [02:58<17:12,  7.43s/it]Running generate_until requests:  16%|█▋        | 27/165 [03:04<15:39,  6.81s/it]Running generate_until requests:  17%|█▋        | 28/165 [03:18<20:26,  8.95s/it]Running generate_until requests:  18%|█▊        | 29/165 [03:26<19:59,  8.82s/it]Running generate_until requests:  18%|█▊        | 30/165 [03:32<17:52,  7.94s/it]Running generate_until requests:  19%|█▉        | 31/165 [03:37<15:53,  7.11s/it]Running generate_until requests:  19%|█▉        | 32/165 [03:42<13:48,  6.23s/it]Running generate_until requests:  20%|██        | 33/165 [03:44<11:25,  5.19s/it]Running generate_until requests:  21%|██        | 34/165 [03:49<10:48,  4.95s/it]Running generate_until requests:  21%|██        | 35/165 [03:54<10:43,  4.95s/it]Running generate_until requests:  22%|██▏       | 36/165 [03:59<10:38,  4.95s/it]Running generate_until requests:  22%|██▏       | 37/165 [04:02<09:17,  4.35s/it]Running generate_until requests:  23%|██▎       | 38/165 [04:08<10:31,  4.97s/it]Running generate_until requests:  24%|██▎       | 39/165 [04:20<14:56,  7.12s/it]Running generate_until requests:  24%|██▍       | 40/165 [04:24<13:00,  6.25s/it]Running generate_until requests:  25%|██▍       | 41/165 [04:30<12:25,  6.01s/it]Running generate_until requests:  25%|██▌       | 42/165 [04:43<16:40,  8.14s/it]Running generate_until requests:  26%|██▌       | 43/165 [04:46<13:24,  6.59s/it]Running generate_until requests:  27%|██▋       | 44/165 [04:51<12:23,  6.15s/it]Running generate_until requests:  27%|██▋       | 45/165 [04:57<12:09,  6.08s/it]Running generate_until requests:  28%|██▊       | 46/165 [05:09<15:40,  7.91s/it]Running generate_until requests:  28%|██▊       | 47/165 [05:16<14:53,  7.57s/it]Running generate_until requests:  29%|██▉       | 48/165 [05:20<12:31,  6.43s/it]Running generate_until requests:  30%|██▉       | 49/165 [05:23<10:39,  5.51s/it]Running generate_until requests:  30%|███       | 50/165 [05:27<09:37,  5.02s/it]Running generate_until requests:  31%|███       | 51/165 [05:33<10:07,  5.33s/it]Running generate_until requests:  32%|███▏      | 52/165 [05:46<14:12,  7.54s/it]Running generate_until requests:  32%|███▏      | 53/165 [05:48<10:59,  5.89s/it]Running generate_until requests:  33%|███▎      | 54/165 [06:01<14:58,  8.10s/it]Running generate_until requests:  33%|███▎      | 55/165 [06:09<14:42,  8.03s/it]Running generate_until requests:  34%|███▍      | 56/165 [06:15<13:28,  7.42s/it]Running generate_until requests:  35%|███▍      | 57/165 [06:19<11:40,  6.48s/it]Running generate_until requests:  35%|███▌      | 58/165 [06:29<13:17,  7.45s/it]Running generate_until requests:  36%|███▌      | 59/165 [06:33<11:27,  6.49s/it]Running generate_until requests:  36%|███▋      | 60/165 [06:39<11:12,  6.41s/it]Running generate_until requests:  37%|███▋      | 61/165 [06:44<10:25,  6.01s/it]Running generate_until requests:  38%|███▊      | 62/165 [06:51<10:54,  6.35s/it]Running generate_until requests:  38%|███▊      | 63/165 [07:00<12:10,  7.16s/it]Running generate_until requests:  39%|███▉      | 64/165 [07:03<09:52,  5.87s/it]Running generate_until requests:  39%|███▉      | 65/165 [07:06<08:15,  4.95s/it]Running generate_until requests:  40%|████      | 66/165 [07:19<11:55,  7.22s/it]Running generate_until requests:  41%|████      | 67/165 [07:21<09:22,  5.74s/it]Running generate_until requests:  41%|████      | 68/165 [07:34<12:49,  7.93s/it]Running generate_until requests:  42%|████▏     | 69/165 [07:42<12:31,  7.83s/it]Running generate_until requests:  42%|████▏     | 70/165 [07:54<14:27,  9.13s/it]Running generate_until requests:  43%|████▎     | 71/165 [08:03<14:17,  9.12s/it]Running generate_until requests:  44%|████▎     | 72/165 [08:12<14:14,  9.19s/it]Running generate_until requests:  44%|████▍     | 73/165 [08:19<12:52,  8.40s/it]Running generate_until requests:  45%|████▍     | 74/165 [08:23<11:02,  7.28s/it]Running generate_until requests:  45%|████▌     | 75/165 [08:37<13:41,  9.13s/it]Running generate_until requests:  46%|████▌     | 76/165 [08:44<12:49,  8.64s/it]Running generate_until requests:  47%|████▋     | 77/165 [08:52<12:15,  8.36s/it]Running generate_until requests:  47%|████▋     | 78/165 [08:59<11:30,  7.94s/it]Running generate_until requests:  48%|████▊     | 79/165 [09:05<10:37,  7.41s/it]Running generate_until requests:  48%|████▊     | 80/165 [09:13<10:35,  7.47s/it]Running generate_until requests:  49%|████▉     | 81/165 [09:20<10:31,  7.52s/it]Running generate_until requests:  50%|████▉     | 82/165 [09:24<08:52,  6.41s/it]Running generate_until requests:  50%|█████     | 83/165 [09:32<09:23,  6.87s/it]Running generate_until requests:  51%|█████     | 84/165 [09:35<07:34,  5.61s/it]Running generate_until requests:  52%|█████▏    | 85/165 [09:40<07:15,  5.45s/it]Running generate_until requests:  52%|█████▏    | 86/165 [09:47<07:39,  5.82s/it]Running generate_until requests:  53%|█████▎    | 87/165 [09:49<06:07,  4.72s/it]Running generate_until requests:  53%|█████▎    | 88/165 [09:53<05:39,  4.41s/it]Running generate_until requests:  54%|█████▍    | 89/165 [09:58<05:50,  4.61s/it]Running generate_until requests:  55%|█████▍    | 90/165 [10:00<05:04,  4.07s/it]Running generate_until requests:  55%|█████▌    | 91/165 [10:05<05:20,  4.33s/it]Running generate_until requests:  56%|█████▌    | 92/165 [10:09<04:59,  4.11s/it]Running generate_until requests:  56%|█████▋    | 93/165 [10:14<05:15,  4.38s/it]Running generate_until requests:  57%|█████▋    | 94/165 [10:22<06:28,  5.47s/it]Running generate_until requests:  58%|█████▊    | 95/165 [10:29<07:03,  6.04s/it]Running generate_until requests:  58%|█████▊    | 96/165 [10:37<07:40,  6.68s/it]Running generate_until requests:  59%|█████▉    | 97/165 [10:41<06:38,  5.85s/it]Running generate_until requests:  59%|█████▉    | 98/165 [10:47<06:26,  5.77s/it]Running generate_until requests:  60%|██████    | 99/165 [10:56<07:16,  6.61s/it]Running generate_until requests:  61%|██████    | 100/165 [11:00<06:20,  5.85s/it]Running generate_until requests:  61%|██████    | 101/165 [11:05<06:13,  5.84s/it]Running generate_until requests:  62%|██████▏   | 102/165 [11:08<05:05,  4.85s/it]Running generate_until requests:  62%|██████▏   | 103/165 [11:12<04:53,  4.73s/it]Running generate_until requests:  63%|██████▎   | 104/165 [11:25<07:16,  7.15s/it]Running generate_until requests:  64%|██████▎   | 105/165 [11:37<08:37,  8.62s/it]Running generate_until requests:  64%|██████▍   | 106/165 [11:41<06:54,  7.03s/it]Running generate_until requests:  65%|██████▍   | 107/165 [11:43<05:29,  5.68s/it]Running generate_until requests:  65%|██████▌   | 108/165 [11:47<04:47,  5.04s/it]Running generate_until requests:  66%|██████▌   | 109/165 [11:51<04:25,  4.74s/it]Running generate_until requests:  67%|██████▋   | 110/165 [11:57<04:45,  5.19s/it]Running generate_until requests:  67%|██████▋   | 111/165 [12:04<05:15,  5.84s/it]Running generate_until requests:  68%|██████▊   | 112/165 [12:08<04:36,  5.21s/it]Running generate_until requests:  68%|██████▊   | 113/165 [12:15<05:00,  5.78s/it]Running generate_until requests:  69%|██████▉   | 114/165 [12:22<05:05,  6.00s/it]Running generate_until requests:  70%|██████▉   | 115/165 [12:28<05:03,  6.07s/it]Running generate_until requests:  70%|███████   | 116/165 [12:31<04:10,  5.10s/it]Running generate_until requests:  71%|███████   | 117/165 [12:33<03:24,  4.26s/it]Running generate_until requests:  72%|███████▏  | 118/165 [12:36<03:00,  3.84s/it]Running generate_until requests:  72%|███████▏  | 119/165 [12:41<03:10,  4.14s/it]Running generate_until requests:  73%|███████▎  | 120/165 [12:43<02:43,  3.64s/it]Running generate_until requests:  73%|███████▎  | 121/165 [12:56<04:37,  6.32s/it]Running generate_until requests:  74%|███████▍  | 122/165 [13:03<04:40,  6.51s/it]Running generate_until requests:  75%|███████▍  | 123/165 [13:10<04:42,  6.73s/it]Running generate_until requests:  75%|███████▌  | 124/165 [13:14<04:06,  6.02s/it]Running generate_until requests:  76%|███████▌  | 125/165 [13:19<03:42,  5.57s/it]Running generate_until requests:  76%|███████▋  | 126/165 [13:25<03:47,  5.83s/it]Running generate_until requests:  77%|███████▋  | 127/165 [13:31<03:41,  5.82s/it]Running generate_until requests:  78%|███████▊  | 128/165 [13:36<03:20,  5.42s/it]Running generate_until requests:  78%|███████▊  | 129/165 [13:41<03:14,  5.42s/it]Running generate_until requests:  79%|███████▉  | 130/165 [13:46<03:05,  5.30s/it]Running generate_until requests:  79%|███████▉  | 131/165 [13:53<03:15,  5.76s/it]Running generate_until requests:  80%|████████  | 132/165 [13:57<02:53,  5.25s/it]Running generate_until requests:  81%|████████  | 133/165 [14:02<02:48,  5.26s/it]Running generate_until requests:  81%|████████  | 134/165 [14:16<04:02,  7.83s/it]Running generate_until requests:  82%|████████▏ | 135/165 [14:18<03:01,  6.03s/it]Running generate_until requests:  82%|████████▏ | 136/165 [14:25<03:00,  6.24s/it]Running generate_until requests:  83%|████████▎ | 137/165 [14:29<02:40,  5.75s/it]Running generate_until requests:  84%|████████▎ | 138/165 [14:35<02:38,  5.87s/it]Running generate_until requests:  84%|████████▍ | 139/165 [14:39<02:16,  5.24s/it]Running generate_until requests:  85%|████████▍ | 140/165 [14:43<01:56,  4.68s/it]Running generate_until requests:  85%|████████▌ | 141/165 [14:49<02:02,  5.10s/it]Running generate_until requests:  86%|████████▌ | 142/165 [14:53<01:49,  4.74s/it]Running generate_until requests:  87%|████████▋ | 143/165 [14:56<01:36,  4.39s/it]Running generate_until requests:  87%|████████▋ | 144/165 [15:01<01:35,  4.55s/it]Running generate_until requests:  88%|████████▊ | 145/165 [15:14<02:23,  7.17s/it]Running generate_until requests:  88%|████████▊ | 146/165 [15:26<02:44,  8.66s/it]Running generate_until requests:  89%|████████▉ | 147/165 [15:39<02:56,  9.80s/it]Running generate_until requests:  90%|████████▉ | 148/165 [15:48<02:41,  9.48s/it]Running generate_until requests:  90%|█████████ | 149/165 [15:54<02:16,  8.52s/it]Running generate_until requests:  91%|█████████ | 150/165 [15:59<01:52,  7.51s/it]Running generate_until requests:  92%|█████████▏| 151/165 [16:04<01:34,  6.74s/it]Running generate_until requests:  92%|█████████▏| 152/165 [16:10<01:23,  6.46s/it]Running generate_until requests:  93%|█████████▎| 153/165 [16:22<01:39,  8.32s/it]Running generate_until requests:  93%|█████████▎| 154/165 [16:30<01:27,  7.99s/it]Running generate_until requests:  94%|█████████▍| 155/165 [16:32<01:02,  6.29s/it]Running generate_until requests:  95%|█████████▍| 156/165 [16:37<00:53,  5.96s/it]Running generate_until requests:  95%|█████████▌| 157/165 [16:41<00:42,  5.32s/it]Running generate_until requests:  96%|█████████▌| 158/165 [16:53<00:51,  7.35s/it]Running generate_until requests:  96%|█████████▋| 159/165 [16:59<00:41,  6.90s/it]Running generate_until requests:  97%|█████████▋| 160/165 [17:06<00:34,  6.83s/it]Running generate_until requests:  98%|█████████▊| 161/165 [17:09<00:23,  5.82s/it]Running generate_until requests:  98%|█████████▊| 162/165 [17:13<00:15,  5.22s/it]Running generate_until requests:  99%|█████████▉| 163/165 [17:17<00:10,  5.00s/it]Running generate_until requests:  99%|█████████▉| 164/165 [17:21<00:04,  4.43s/it]Running generate_until requests: 100%|██████████| 165/165 [17:26<00:00,  4.63s/it]Running generate_until requests: 100%|██████████| 165/165 [17:26<00:00,  6.34s/it]
[2024-06-03 15:03:54,616] torch.distributed.elastic.multiprocessing.api: [WARNING] Sending process 3391172 closing signal SIGTERM
[2024-06-03 15:03:56,469] torch.distributed.elastic.multiprocessing.api: [ERROR] failed (exitcode: -7) local_rank: 3 (pid: 3391175) of binary: /private/home/beidic/.conda/envs/griffin/bin/python
Traceback (most recent call last):
  File "/private/home/beidic/.conda/envs/griffin/bin/accelerate", line 8, in <module>
    sys.exit(main())
             ^^^^^^
  File "/private/home/beidic/.conda/envs/griffin/lib/python3.12/site-packages/accelerate/commands/accelerate_cli.py", line 47, in main
    args.func(args)
  File "/private/home/beidic/.conda/envs/griffin/lib/python3.12/site-packages/accelerate/commands/launch.py", line 985, in launch_command
    multi_gpu_launcher(args)
  File "/private/home/beidic/.conda/envs/griffin/lib/python3.12/site-packages/accelerate/commands/launch.py", line 654, in multi_gpu_launcher
    distrib_run.run(args)
  File "/private/home/beidic/.conda/envs/griffin/lib/python3.12/site-packages/torch/distributed/run.py", line 803, in run
    elastic_launch(
  File "/private/home/beidic/.conda/envs/griffin/lib/python3.12/site-packages/torch/distributed/launcher/api.py", line 135, in __call__
    return launch_agent(self._config, self._entrypoint, list(args))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/private/home/beidic/.conda/envs/griffin/lib/python3.12/site-packages/torch/distributed/launcher/api.py", line 268, in launch_agent
    raise ChildFailedError(
torch.distributed.elastic.multiprocessing.errors.ChildFailedError: 
=======================================================
main.py FAILED
-------------------------------------------------------
Failures:
  <NO_OTHER_FAILURES>
-------------------------------------------------------
Root Cause (first observed failure):
[0]:
  time      : 2024-06-03_15:03:54
  host      : learnfair7474.h2.fair
  rank      : 3 (local_rank: 3)
  exitcode  : -7 (pid: 3391175)
  error_file: <N/A>
  traceback : Signal 7 (SIGBUS) received by PID 3391175
=======================================================
/var/spool/slurm//job28548889/slurm_script: line 63: 3391149 Bus error               (core dumped) accelerate launch --main_process_port 29510 --num_processes 8 --num_machines 1 main.py --model xhf --model_args pretrained=meta-llama/Llama-2-7b-hf,griffin=True,check=True,kernel_size=16,spr=0.5,thr=0.1 --tasks gsm8k --batch_size 1
