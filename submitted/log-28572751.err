Already on 'yangexp2'
wandb: Currently logged in as: stevenzhou0816100. Use `wandb login --relogin` to force relogin
Traceback (most recent call last):
  File "/private/home/beidic/.conda/envs/griffin/bin/huggingface-cli", line 8, in <module>
    sys.exit(main())
             ^^^^^^
  File "/private/home/beidic/.conda/envs/griffin/lib/python3.12/site-packages/huggingface_hub/commands/huggingface_cli.py", line 51, in main
    service.run()
  File "/private/home/beidic/.conda/envs/griffin/lib/python3.12/site-packages/huggingface_hub/commands/user.py", line 98, in run
    login(token=self.args.token, add_to_git_credential=self.args.add_to_git_credential)
  File "/private/home/beidic/.conda/envs/griffin/lib/python3.12/site-packages/huggingface_hub/_login.py", line 111, in login
    _login(token, add_to_git_credential=add_to_git_credential, write_permission=write_permission)
  File "/private/home/beidic/.conda/envs/griffin/lib/python3.12/site-packages/huggingface_hub/_login.py", line 307, in _login
    raise ValueError("Invalid token passed!")
ValueError: Invalid token passed!
The following values were not passed to `accelerate launch` and had defaults used instead:
		More than one GPU was found, enabling multi-GPU training.
		If this was unintended please pass in `--num_processes=1`.
	`--mixed_precision` was set to a value of `'no'`
	`--dynamo_backend` was set to a value of `'no'`
To avoid this warning pass in values for each of the problematic parameters or run `accelerate config`.
2024-06-04:06:33:32,909 INFO     [main.py:288] Verbosity set to INFO
2024-06-04:06:33:32,970 INFO     [main.py:288] Verbosity set to INFO
2024-06-04:06:33:33,527 INFO     [main.py:288] Verbosity set to INFO
2024-06-04:06:33:33,659 INFO     [main.py:288] Verbosity set to INFO
2024-06-04:06:33:33,725 INFO     [main.py:288] Verbosity set to INFO
2024-06-04:06:33:33,754 INFO     [main.py:288] Verbosity set to INFO
2024-06-04:06:33:33,793 INFO     [main.py:288] Verbosity set to INFO
2024-06-04:06:33:33,844 INFO     [main.py:288] Verbosity set to INFO
2024-06-04:06:33:38,793 INFO     [main.py:378] Selected Tasks: ['gsm8k']
2024-06-04:06:33:38,793 INFO     [main.py:378] Selected Tasks: ['gsm8k']
2024-06-04:06:33:38,800 INFO     [xevaluator.py:137] Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234
2024-06-04:06:33:38,800 INFO     [xevaluator.py:137] Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234
2024-06-04:06:33:38,800 INFO     [xevaluator.py:184] Initializing xhf model, with arguments: {'pretrained': 'meta-llama/Llama-2-7b-hf', 'cats': True, 'check': True, 'kernel_size': 16, 'spr': 0.5, 'thr': 0.1}
2024-06-04:06:33:38,800 INFO     [xevaluator.py:184] Initializing xhf model, with arguments: {'pretrained': 'meta-llama/Llama-2-7b-hf', 'cats': True, 'check': True, 'kernel_size': 16, 'spr': 0.5, 'thr': 0.1}
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]2024-06-04:06:33:40,327 INFO     [main.py:378] Selected Tasks: ['gsm8k']
2024-06-04:06:33:40,332 INFO     [xevaluator.py:137] Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234
2024-06-04:06:33:40,332 INFO     [xevaluator.py:184] Initializing xhf model, with arguments: {'pretrained': 'meta-llama/Llama-2-7b-hf', 'cats': True, 'check': True, 'kernel_size': 16, 'spr': 0.5, 'thr': 0.1}
2024-06-04:06:33:40,491 INFO     [main.py:378] Selected Tasks: ['gsm8k']
2024-06-04:06:33:40,496 INFO     [xevaluator.py:137] Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234
2024-06-04:06:33:40,496 INFO     [xevaluator.py:184] Initializing xhf model, with arguments: {'pretrained': 'meta-llama/Llama-2-7b-hf', 'cats': True, 'check': True, 'kernel_size': 16, 'spr': 0.5, 'thr': 0.1}
2024-06-04:06:33:40,625 INFO     [main.py:378] Selected Tasks: ['gsm8k']
2024-06-04:06:33:40,631 INFO     [xevaluator.py:137] Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234
2024-06-04:06:33:40,631 INFO     [xevaluator.py:184] Initializing xhf model, with arguments: {'pretrained': 'meta-llama/Llama-2-7b-hf', 'cats': True, 'check': True, 'kernel_size': 16, 'spr': 0.5, 'thr': 0.1}
2024-06-04:06:33:40,653 INFO     [main.py:378] Selected Tasks: ['gsm8k']
2024-06-04:06:33:40,658 INFO     [xevaluator.py:137] Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234
2024-06-04:06:33:40,658 INFO     [xevaluator.py:184] Initializing xhf model, with arguments: {'pretrained': 'meta-llama/Llama-2-7b-hf', 'cats': True, 'check': True, 'kernel_size': 16, 'spr': 0.5, 'thr': 0.1}
2024-06-04:06:33:40,690 INFO     [main.py:378] Selected Tasks: ['gsm8k']
2024-06-04:06:33:40,695 INFO     [xevaluator.py:137] Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234
2024-06-04:06:33:40,695 INFO     [xevaluator.py:184] Initializing xhf model, with arguments: {'pretrained': 'meta-llama/Llama-2-7b-hf', 'cats': True, 'check': True, 'kernel_size': 16, 'spr': 0.5, 'thr': 0.1}
2024-06-04:06:33:40,711 INFO     [main.py:378] Selected Tasks: ['gsm8k']
2024-06-04:06:33:40,717 INFO     [xevaluator.py:137] Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234
2024-06-04:06:33:40,717 INFO     [xevaluator.py:184] Initializing xhf model, with arguments: {'pretrained': 'meta-llama/Llama-2-7b-hf', 'cats': True, 'check': True, 'kernel_size': 16, 'spr': 0.5, 'thr': 0.1}
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [01:04<01:04, 64.08s/it]Loading checkpoint shards:  50%|█████     | 1/2 [01:05<01:05, 65.68s/it]Loading checkpoint shards:  50%|█████     | 1/2 [01:06<01:06, 66.06s/it]Loading checkpoint shards:  50%|█████     | 1/2 [01:07<01:07, 67.63s/it]Loading checkpoint shards:  50%|█████     | 1/2 [01:06<01:06, 66.07s/it]Loading checkpoint shards:  50%|█████     | 1/2 [01:06<01:06, 66.37s/it]Loading checkpoint shards:  50%|█████     | 1/2 [01:05<01:05, 65.85s/it]Loading checkpoint shards:  50%|█████     | 1/2 [01:07<01:07, 67.76s/it]Loading checkpoint shards: 100%|██████████| 2/2 [01:26<00:00, 39.23s/it]Loading checkpoint shards: 100%|██████████| 2/2 [01:26<00:00, 43.49s/it]
Loading checkpoint shards: 100%|██████████| 2/2 [01:26<00:00, 38.97s/it]Loading checkpoint shards: 100%|██████████| 2/2 [01:26<00:00, 43.03s/it]
Loading checkpoint shards: 100%|██████████| 2/2 [01:25<00:00, 39.18s/it]Loading checkpoint shards: 100%|██████████| 2/2 [01:25<00:00, 42.91s/it]
Loading checkpoint shards: 100%|██████████| 2/2 [01:25<00:00, 38.86s/it]Loading checkpoint shards: 100%|██████████| 2/2 [01:25<00:00, 42.91s/it]
Loading checkpoint shards: 100%|██████████| 2/2 [01:26<00:00, 38.98s/it]Loading checkpoint shards: 100%|██████████| 2/2 [01:26<00:00, 43.04s/it]
Loading checkpoint shards: 100%|██████████| 2/2 [01:25<00:00, 38.90s/it]Loading checkpoint shards: 100%|██████████| 2/2 [01:25<00:00, 42.92s/it]
Loading checkpoint shards: 100%|██████████| 2/2 [01:26<00:00, 39.09s/it]Loading checkpoint shards: 100%|██████████| 2/2 [01:26<00:00, 43.18s/it]
Loading checkpoint shards: 100%|██████████| 2/2 [01:27<00:00, 39.64s/it]Loading checkpoint shards: 100%|██████████| 2/2 [01:27<00:00, 43.86s/it]
Using the latest cached version of the dataset since gsm8k couldn't be found on the Hugging Face Hub
2024-06-04:06:35:39,514 WARNING  [load.py:1631] Using the latest cached version of the dataset since gsm8k couldn't be found on the Hugging Face Hub
Found the latest cached dataset configuration 'main' at /private/home/beidic/.cache/huggingface/datasets/gsm8k/main/0.0.0/e53f048856ff4f594e959d75785d2c2d37b678ee (last modified on Thu May 16 07:01:08 2024).
2024-06-04:06:35:39,517 WARNING  [cache.py:95] Found the latest cached dataset configuration 'main' at /private/home/beidic/.cache/huggingface/datasets/gsm8k/main/0.0.0/e53f048856ff4f594e959d75785d2c2d37b678ee (last modified on Thu May 16 07:01:08 2024).
2024-06-04:06:35:39,819 INFO     [task.py:395] Building contexts for gsm8k on rank 1...
  0%|          | 0/165 [00:00<?, ?it/s]  9%|▉         | 15/165 [00:00<00:01, 140.64it/s] 18%|█▊        | 30/165 [00:00<00:00, 141.23it/s] 27%|██▋       | 45/165 [00:00<00:00, 141.09it/s] 36%|███▋      | 60/165 [00:00<00:00, 141.25it/s] 45%|████▌     | 75/165 [00:00<00:00, 141.31it/s] 55%|█████▍    | 90/165 [00:00<00:00, 141.48it/s] 64%|██████▎   | 105/165 [00:00<00:00, 141.68it/s] 73%|███████▎  | 120/165 [00:00<00:00, 141.71it/s] 82%|████████▏ | 135/165 [00:00<00:00, 141.68it/s] 91%|█████████ | 150/165 [00:01<00:00, 140.94it/s]2024-06-04:06:35:41,017 INFO     [xhuggingface.py:314] Using 8 devices with data parallelism
100%|██████████| 165/165 [00:01<00:00, 136.53it/s]100%|██████████| 165/165 [00:01<00:00, 139.86it/s]
Using the latest cached version of the dataset since gsm8k couldn't be found on the Hugging Face Hub
2024-06-04:06:35:41,098 WARNING  [load.py:1631] Using the latest cached version of the dataset since gsm8k couldn't be found on the Hugging Face Hub
Found the latest cached dataset configuration 'main' at /private/home/beidic/.cache/huggingface/datasets/gsm8k/main/0.0.0/e53f048856ff4f594e959d75785d2c2d37b678ee (last modified on Thu May 16 07:01:08 2024).
2024-06-04:06:35:41,100 WARNING  [cache.py:95] Found the latest cached dataset configuration 'main' at /private/home/beidic/.cache/huggingface/datasets/gsm8k/main/0.0.0/e53f048856ff4f594e959d75785d2c2d37b678ee (last modified on Thu May 16 07:01:08 2024).
2024-06-04:06:35:41,305 INFO     [task.py:395] Building contexts for gsm8k on rank 0...
  0%|          | 0/165 [00:00<?, ?it/s] 12%|█▏        | 20/165 [00:00<00:00, 192.26it/s] 24%|██▍       | 40/165 [00:00<00:00, 192.32it/s] 36%|███▋      | 60/165 [00:00<00:00, 193.81it/s] 48%|████▊     | 80/165 [00:00<00:00, 194.68it/s] 61%|██████    | 100/165 [00:00<00:00, 195.49it/s] 73%|███████▎  | 120/165 [00:00<00:00, 195.67it/s] 85%|████████▍ | 140/165 [00:00<00:00, 195.89it/s] 97%|█████████▋| 160/165 [00:00<00:00, 193.88it/s]100%|██████████| 165/165 [00:00<00:00, 194.33it/s]
Using the latest cached version of the dataset since gsm8k couldn't be found on the Hugging Face Hub
2024-06-04:06:36:08,729 WARNING  [load.py:1631] Using the latest cached version of the dataset since gsm8k couldn't be found on the Hugging Face Hub
Found the latest cached dataset configuration 'main' at /private/home/beidic/.cache/huggingface/datasets/gsm8k/main/0.0.0/e53f048856ff4f594e959d75785d2c2d37b678ee (last modified on Thu May 16 07:01:08 2024).
2024-06-04:06:36:08,731 WARNING  [cache.py:95] Found the latest cached dataset configuration 'main' at /private/home/beidic/.cache/huggingface/datasets/gsm8k/main/0.0.0/e53f048856ff4f594e959d75785d2c2d37b678ee (last modified on Thu May 16 07:01:08 2024).
Using the latest cached version of the dataset since gsm8k couldn't be found on the Hugging Face Hub
2024-06-04:06:36:08,775 WARNING  [load.py:1631] Using the latest cached version of the dataset since gsm8k couldn't be found on the Hugging Face Hub
Found the latest cached dataset configuration 'main' at /private/home/beidic/.cache/huggingface/datasets/gsm8k/main/0.0.0/e53f048856ff4f594e959d75785d2c2d37b678ee (last modified on Thu May 16 07:01:08 2024).
2024-06-04:06:36:08,778 WARNING  [cache.py:95] Found the latest cached dataset configuration 'main' at /private/home/beidic/.cache/huggingface/datasets/gsm8k/main/0.0.0/e53f048856ff4f594e959d75785d2c2d37b678ee (last modified on Thu May 16 07:01:08 2024).
2024-06-04:06:36:09,126 INFO     [task.py:395] Building contexts for gsm8k on rank 5...
  0%|          | 0/165 [00:00<?, ?it/s]Using the latest cached version of the dataset since gsm8k couldn't be found on the Hugging Face Hub
2024-06-04:06:36:09,188 WARNING  [load.py:1631] Using the latest cached version of the dataset since gsm8k couldn't be found on the Hugging Face Hub
Found the latest cached dataset configuration 'main' at /private/home/beidic/.cache/huggingface/datasets/gsm8k/main/0.0.0/e53f048856ff4f594e959d75785d2c2d37b678ee (last modified on Thu May 16 07:01:08 2024).
2024-06-04:06:36:09,191 WARNING  [cache.py:95] Found the latest cached dataset configuration 'main' at /private/home/beidic/.cache/huggingface/datasets/gsm8k/main/0.0.0/e53f048856ff4f594e959d75785d2c2d37b678ee (last modified on Thu May 16 07:01:08 2024).
2024-06-04:06:36:09,231 INFO     [task.py:395] Building contexts for gsm8k on rank 3...
  8%|▊         | 14/165 [00:00<00:01, 138.29it/s]  0%|          | 0/165 [00:00<?, ?it/s] 17%|█▋        | 28/165 [00:00<00:01, 135.74it/s]  6%|▌         | 10/165 [00:00<00:01, 99.03it/s]2024-06-04:06:36:09,459 INFO     [task.py:395] Building contexts for gsm8k on rank 4...
 25%|██▌       | 42/165 [00:00<00:00, 131.88it/s]  0%|          | 0/165 [00:00<?, ?it/s] 13%|█▎        | 21/165 [00:00<00:01, 99.74it/s] 35%|███▍      | 57/165 [00:00<00:00, 136.76it/s]  8%|▊         | 14/165 [00:00<00:01, 138.78it/s] 19%|█▉        | 32/165 [00:00<00:01, 100.01it/s]Using the latest cached version of the dataset since gsm8k couldn't be found on the Hugging Face Hub
2024-06-04:06:36:09,646 WARNING  [load.py:1631] Using the latest cached version of the dataset since gsm8k couldn't be found on the Hugging Face Hub
Found the latest cached dataset configuration 'main' at /private/home/beidic/.cache/huggingface/datasets/gsm8k/main/0.0.0/e53f048856ff4f594e959d75785d2c2d37b678ee (last modified on Thu May 16 07:01:08 2024).
2024-06-04:06:36:09,648 WARNING  [cache.py:95] Found the latest cached dataset configuration 'main' at /private/home/beidic/.cache/huggingface/datasets/gsm8k/main/0.0.0/e53f048856ff4f594e959d75785d2c2d37b678ee (last modified on Thu May 16 07:01:08 2024).
 43%|████▎     | 71/165 [00:00<00:00, 133.94it/s] 18%|█▊        | 30/165 [00:00<00:00, 145.88it/s] 25%|██▌       | 42/165 [00:00<00:01, 98.59it/s]  52%|█████▏    | 85/165 [00:00<00:00, 130.95it/s] 27%|██▋       | 45/165 [00:00<00:00, 141.31it/s] 32%|███▏      | 52/165 [00:00<00:01, 98.91it/s] 60%|██████    | 99/165 [00:00<00:00, 129.57it/s] 38%|███▊      | 62/165 [00:00<00:01, 99.16it/s] 36%|███▋      | 60/165 [00:00<00:00, 139.71it/s]2024-06-04:06:36:09,959 INFO     [task.py:395] Building contexts for gsm8k on rank 2...
  0%|          | 0/165 [00:00<?, ?it/s] 68%|██████▊   | 112/165 [00:00<00:00, 129.34it/s] 45%|████▍     | 74/165 [00:00<00:00, 139.12it/s] 44%|████▍     | 73/165 [00:00<00:00, 99.67it/s]  8%|▊         | 14/165 [00:00<00:01, 132.75it/s] 76%|███████▋  | 126/165 [00:00<00:00, 130.45it/s] 53%|█████▎    | 88/165 [00:00<00:00, 138.55it/s] 51%|█████     | 84/165 [00:00<00:00, 99.67it/s] 17%|█▋        | 28/165 [00:00<00:01, 132.90it/s] 85%|████████▍ | 140/165 [00:01<00:00, 131.23it/s] 62%|██████▏   | 102/165 [00:00<00:00, 138.12it/s] 58%|█████▊    | 95/165 [00:00<00:00, 100.02it/s] 25%|██▌       | 42/165 [00:00<00:00, 133.34it/s] 70%|███████   | 116/165 [00:00<00:00, 138.14it/s] 93%|█████████▎| 154/165 [00:01<00:00, 131.47it/s] 64%|██████▍   | 106/165 [00:01<00:00, 100.17it/s] 34%|███▍      | 56/165 [00:00<00:00, 133.49it/s]100%|██████████| 165/165 [00:01<00:00, 132.01it/s]
 79%|███████▉  | 130/165 [00:00<00:00, 136.99it/s] 71%|███████   | 117/165 [00:01<00:00, 100.11it/s] 42%|████▏     | 70/165 [00:00<00:00, 135.02it/s] 87%|████████▋ | 144/165 [00:01<00:00, 137.16it/s] 78%|███████▊  | 128/165 [00:01<00:00, 100.32it/s] 51%|█████     | 84/165 [00:00<00:00, 136.14it/s] 96%|█████████▌| 158/165 [00:01<00:00, 137.57it/s]100%|██████████| 165/165 [00:01<00:00, 138.53it/s]
 84%|████████▍ | 139/165 [00:01<00:00, 100.38it/s] 59%|█████▉    | 98/165 [00:00<00:00, 135.69it/s] 91%|█████████ | 150/165 [00:01<00:00, 100.58it/s] 68%|██████▊   | 112/165 [00:00<00:00, 134.88it/s] 98%|█████████▊| 161/165 [00:01<00:00, 100.78it/s] 76%|███████▋  | 126/165 [00:00<00:00, 134.53it/s]100%|██████████| 165/165 [00:01<00:00, 100.08it/s]
 85%|████████▍ | 140/165 [00:01<00:00, 132.96it/s] 93%|█████████▎| 154/165 [00:01<00:00, 130.87it/s]Using the latest cached version of the dataset since gsm8k couldn't be found on the Hugging Face Hub
2024-06-04:06:36:11,247 WARNING  [load.py:1631] Using the latest cached version of the dataset since gsm8k couldn't be found on the Hugging Face Hub
100%|██████████| 165/165 [00:01<00:00, 132.54it/s]
Found the latest cached dataset configuration 'main' at /private/home/beidic/.cache/huggingface/datasets/gsm8k/main/0.0.0/e53f048856ff4f594e959d75785d2c2d37b678ee (last modified on Thu May 16 07:01:08 2024).
2024-06-04:06:36:11,250 WARNING  [cache.py:95] Found the latest cached dataset configuration 'main' at /private/home/beidic/.cache/huggingface/datasets/gsm8k/main/0.0.0/e53f048856ff4f594e959d75785d2c2d37b678ee (last modified on Thu May 16 07:01:08 2024).
2024-06-04:06:36:11,814 INFO     [task.py:395] Building contexts for gsm8k on rank 6...
  0%|          | 0/165 [00:00<?, ?it/s]  5%|▍         | 8/165 [00:00<00:02, 65.62it/s] 10%|▉         | 16/165 [00:00<00:02, 71.47it/s] 15%|█▍        | 24/165 [00:00<00:02, 68.99it/s] 19%|█▉        | 32/165 [00:00<00:01, 67.84it/s] 24%|██▍       | 40/165 [00:00<00:01, 70.67it/s] 29%|██▉       | 48/165 [00:00<00:01, 69.10it/s] 34%|███▍      | 56/165 [00:00<00:01, 71.36it/s] 39%|███▉      | 64/165 [00:00<00:01, 69.60it/s] 44%|████▎     | 72/165 [00:01<00:01, 71.62it/s] 48%|████▊     | 80/165 [00:01<00:01, 69.83it/s] 53%|█████▎    | 88/165 [00:01<00:01, 71.75it/s] 58%|█████▊    | 96/165 [00:01<00:00, 69.97it/s] 63%|██████▎   | 104/165 [00:01<00:00, 71.78it/s] 68%|██████▊   | 112/165 [00:01<00:00, 70.04it/s] 73%|███████▎  | 120/165 [00:01<00:00, 68.82it/s] 78%|███████▊  | 128/165 [00:01<00:00, 70.94it/s] 82%|████████▏ | 136/165 [00:01<00:00, 69.50it/s] 87%|████████▋ | 144/165 [00:02<00:00, 71.19it/s] 92%|█████████▏| 152/165 [00:02<00:00, 69.61it/s] 97%|█████████▋| 160/165 [00:02<00:00, 71.42it/s]100%|██████████| 165/165 [00:02<00:00, 69.98it/s]
Using the latest cached version of the dataset since gsm8k couldn't be found on the Hugging Face Hub
2024-06-04:06:36:14,828 WARNING  [load.py:1631] Using the latest cached version of the dataset since gsm8k couldn't be found on the Hugging Face Hub
Found the latest cached dataset configuration 'main' at /private/home/beidic/.cache/huggingface/datasets/gsm8k/main/0.0.0/e53f048856ff4f594e959d75785d2c2d37b678ee (last modified on Thu May 16 07:01:08 2024).
2024-06-04:06:36:14,831 WARNING  [cache.py:95] Found the latest cached dataset configuration 'main' at /private/home/beidic/.cache/huggingface/datasets/gsm8k/main/0.0.0/e53f048856ff4f594e959d75785d2c2d37b678ee (last modified on Thu May 16 07:01:08 2024).
2024-06-04:06:36:15,282 INFO     [task.py:395] Building contexts for gsm8k on rank 7...
  0%|          | 0/164 [00:00<?, ?it/s]  7%|▋         | 11/164 [00:00<00:01, 107.81it/s] 13%|█▎        | 22/164 [00:00<00:01, 107.80it/s] 20%|██        | 33/164 [00:00<00:01, 107.79it/s] 27%|██▋       | 44/164 [00:00<00:01, 107.67it/s] 34%|███▎      | 55/164 [00:00<00:01, 107.64it/s] 40%|████      | 66/164 [00:00<00:00, 107.42it/s] 47%|████▋     | 77/164 [00:00<00:00, 107.73it/s] 54%|█████▎    | 88/164 [00:00<00:00, 106.18it/s] 60%|██████    | 99/164 [00:00<00:00, 106.46it/s] 67%|██████▋   | 110/164 [00:01<00:00, 106.70it/s] 74%|███████▍  | 121/164 [00:01<00:00, 106.81it/s] 80%|████████  | 132/164 [00:01<00:00, 107.08it/s] 87%|████████▋ | 143/164 [00:01<00:00, 107.16it/s] 94%|█████████▍| 154/164 [00:01<00:00, 106.96it/s]100%|██████████| 164/164 [00:01<00:00, 107.11it/s]
2024-06-04:06:36:27,224 INFO     [xevaluator.py:395] Running generate_until requests
2024-06-04:06:36:27,224 INFO     [xevaluator.py:395] Running generate_until requests
2024-06-04:06:36:27,224 INFO     [xevaluator.py:395] Running generate_until requests
2024-06-04:06:36:27,224 INFO     [xevaluator.py:395] Running generate_until requests
2024-06-04:06:36:27,225 INFO     [xevaluator.py:395] Running generate_until requests
2024-06-04:06:36:27,225 INFO     [xevaluator.py:395] Running generate_until requests
2024-06-04:06:36:27,225 INFO     [xevaluator.py:395] Running generate_until requests
Running generate_until requests:   0%|          | 0/165 [00:00<?, ?it/s]2024-06-04:06:36:27,240 INFO     [xevaluator.py:395] Running generate_until requests
Running generate_until requests:   1%|          | 1/165 [00:17<47:01, 17.20s/it]Running generate_until requests:   1%|          | 2/165 [00:25<32:33, 11.98s/it]Running generate_until requests:   2%|▏         | 3/165 [00:38<33:37, 12.45s/it]Running generate_until requests:   2%|▏         | 4/165 [00:53<36:33, 13.63s/it]Running generate_until requests:   3%|▎         | 5/165 [01:04<33:41, 12.64s/it]Running generate_until requests:   4%|▎         | 6/165 [01:15<31:46, 11.99s/it]Running generate_until requests:   4%|▍         | 7/165 [01:18<23:22,  8.88s/it]Running generate_until requests:   5%|▍         | 8/165 [01:24<21:09,  8.09s/it]Running generate_until requests:   5%|▌         | 9/165 [01:29<18:11,  7.00s/it]Running generate_until requests:   6%|▌         | 10/165 [01:34<17:01,  6.59s/it]Running generate_until requests:   7%|▋         | 11/165 [01:43<18:45,  7.31s/it]Running generate_until requests:   7%|▋         | 12/165 [01:47<15:46,  6.18s/it]Running generate_until requests:   8%|▊         | 13/165 [01:52<14:58,  5.91s/it]Running generate_until requests:   8%|▊         | 14/165 [02:01<17:12,  6.84s/it]Running generate_until requests:   9%|▉         | 15/165 [02:06<15:28,  6.19s/it]Running generate_until requests:  10%|▉         | 16/165 [02:11<14:51,  5.99s/it]Running generate_until requests:  10%|█         | 17/165 [02:20<16:28,  6.68s/it]Running generate_until requests:  11%|█         | 18/165 [02:25<15:07,  6.17s/it]Running generate_until requests:  12%|█▏        | 19/165 [02:34<17:19,  7.12s/it]Running generate_until requests:  12%|█▏        | 20/165 [02:41<17:04,  7.06s/it]Running generate_until requests:  13%|█▎        | 21/165 [02:46<15:56,  6.64s/it]Running generate_until requests:  13%|█▎        | 22/165 [02:52<15:02,  6.31s/it]Running generate_until requests:  14%|█▍        | 23/165 [03:08<21:30,  9.09s/it]Running generate_until requests:  15%|█▍        | 24/165 [03:23<26:10, 11.14s/it]Running generate_until requests:  15%|█▌        | 25/165 [03:39<29:17, 12.55s/it]Running generate_until requests:  16%|█▌        | 26/165 [03:47<25:51, 11.16s/it]Running generate_until requests:  16%|█▋        | 27/165 [03:53<21:57,  9.55s/it]Running generate_until requests:  17%|█▋        | 28/165 [04:09<25:54, 11.35s/it]Running generate_until requests:  18%|█▊        | 29/165 [04:15<22:39, 10.00s/it]Running generate_until requests:  18%|█▊        | 30/165 [04:18<17:47,  7.91s/it]Running generate_until requests:  19%|█▉        | 31/165 [04:25<17:04,  7.64s/it]Running generate_until requests:  19%|█▉        | 32/165 [04:32<16:19,  7.36s/it]Running generate_until requests:  20%|██        | 33/165 [04:35<13:05,  5.95s/it]Running generate_until requests:  21%|██        | 34/165 [04:40<12:28,  5.71s/it]Running generate_until requests:  21%|██        | 35/165 [04:47<13:07,  6.06s/it]Running generate_until requests:  22%|██▏       | 36/165 [04:57<15:29,  7.20s/it]Running generate_until requests:  22%|██▏       | 37/165 [05:00<12:34,  5.89s/it]Running generate_until requests:  23%|██▎       | 38/165 [05:08<13:54,  6.57s/it]Running generate_until requests:  24%|██▎       | 39/165 [05:18<16:10,  7.70s/it]Running generate_until requests:  24%|██▍       | 40/165 [05:23<14:27,  6.94s/it]Running generate_until requests:  25%|██▍       | 41/165 [05:30<14:22,  6.95s/it]Running generate_until requests:  25%|██▌       | 42/165 [05:41<16:23,  7.99s/it]Running generate_until requests:  26%|██▌       | 43/165 [05:47<15:01,  7.39s/it]Running generate_until requests:  27%|██▋       | 44/165 [05:57<16:43,  8.29s/it]Running generate_until requests:  27%|██▋       | 45/165 [06:04<15:56,  7.97s/it]Running generate_until requests:  28%|██▊       | 46/165 [06:10<14:41,  7.41s/it]Running generate_until requests:  28%|██▊       | 47/165 [06:16<13:15,  6.75s/it]Running generate_until requests:  29%|██▉       | 48/165 [06:19<11:10,  5.73s/it]Running generate_until requests:  30%|██▉       | 49/165 [06:25<11:15,  5.82s/it]Running generate_until requests:  30%|███       | 50/165 [06:31<11:29,  6.00s/it]Running generate_until requests:  31%|███       | 51/165 [06:41<13:15,  6.98s/it]Running generate_until requests:  32%|███▏      | 52/165 [06:56<18:09,  9.64s/it]Running generate_until requests:  32%|███▏      | 53/165 [07:10<20:22, 10.91s/it]Running generate_until requests:  33%|███▎      | 54/165 [07:25<22:25, 12.12s/it]Running generate_until requests:  33%|███▎      | 55/165 [07:41<24:05, 13.14s/it]Running generate_until requests:  34%|███▍      | 56/165 [07:47<20:06, 11.06s/it]Running generate_until requests:  35%|███▍      | 57/165 [07:53<17:00,  9.45s/it]Running generate_until requests:  35%|███▌      | 58/165 [08:02<16:47,  9.42s/it]Running generate_until requests:  36%|███▌      | 59/165 [08:08<14:54,  8.44s/it]Running generate_until requests:  36%|███▋      | 60/165 [08:14<13:31,  7.73s/it]Running generate_until requests:  37%|███▋      | 61/165 [08:20<12:26,  7.18s/it]Running generate_until requests:  38%|███▊      | 62/165 [08:24<10:51,  6.32s/it]Running generate_until requests:  38%|███▊      | 63/165 [08:27<08:45,  5.15s/it]Running generate_until requests:  39%|███▉      | 64/165 [08:33<09:06,  5.41s/it]Running generate_until requests:  39%|███▉      | 65/165 [08:36<07:56,  4.77s/it]Running generate_until requests:  40%|████      | 66/165 [08:52<13:11,  7.99s/it]Running generate_until requests:  41%|████      | 67/165 [08:55<10:30,  6.44s/it]Running generate_until requests:  41%|████      | 68/165 [09:10<14:47,  9.15s/it]Running generate_until requests:  42%|████▏     | 69/165 [09:20<15:06,  9.44s/it]Running generate_until requests:  42%|████▏     | 70/165 [09:35<17:43, 11.19s/it]Running generate_until requests:  43%|████▎     | 71/165 [09:50<19:12, 12.26s/it]Running generate_until requests:  44%|████▎     | 72/165 [09:57<16:18, 10.53s/it]Running generate_until requests:  44%|████▍     | 73/165 [10:04<14:53,  9.71s/it]Running generate_until requests:  45%|████▍     | 74/165 [10:10<12:53,  8.50s/it]Running generate_until requests:  45%|████▌     | 75/165 [10:26<15:55, 10.61s/it]Running generate_until requests:  46%|████▌     | 76/165 [10:32<13:59,  9.43s/it]Running generate_until requests:  47%|████▋     | 77/165 [10:48<16:30, 11.26s/it]Running generate_until requests:  47%|████▋     | 78/165 [10:57<15:18, 10.56s/it]Running generate_until requests:  48%|████▊     | 79/165 [11:13<17:25, 12.16s/it]Running generate_until requests:  48%|████▊     | 80/165 [11:23<16:29, 11.64s/it]Running generate_until requests:  49%|████▉     | 81/165 [11:39<17:58, 12.84s/it]Running generate_until requests:  50%|████▉     | 82/165 [11:43<14:20, 10.37s/it]Running generate_until requests:  50%|█████     | 83/165 [11:58<16:05, 11.77s/it]Running generate_until requests:  51%|█████     | 84/165 [12:05<13:37, 10.09s/it]Running generate_until requests:  52%|█████▏    | 85/165 [12:15<13:42, 10.28s/it]Running generate_until requests:  52%|█████▏    | 86/165 [12:24<13:00,  9.88s/it]Running generate_until requests:  53%|█████▎    | 87/165 [12:30<11:05,  8.54s/it]Running generate_until requests:  53%|█████▎    | 88/165 [12:34<09:28,  7.38s/it]Running generate_until requests:  54%|█████▍    | 89/165 [12:42<09:18,  7.34s/it]Running generate_until requests:  55%|█████▍    | 90/165 [12:45<07:44,  6.20s/it]Running generate_until requests:  55%|█████▌    | 91/165 [12:51<07:33,  6.12s/it]Running generate_until requests:  56%|█████▌    | 92/165 [12:57<07:25,  6.10s/it]Running generate_until requests:  56%|█████▋    | 93/165 [13:05<07:54,  6.59s/it]Running generate_until requests:  57%|█████▋    | 94/165 [13:16<09:24,  7.95s/it]Running generate_until requests:  58%|█████▊    | 95/165 [13:24<09:22,  8.03s/it]Running generate_until requests:  58%|█████▊    | 96/165 [13:30<08:28,  7.37s/it]Running generate_until requests:  59%|█████▉    | 97/165 [13:33<06:58,  6.16s/it]Running generate_until requests:  59%|█████▉    | 98/165 [13:38<06:24,  5.73s/it]Running generate_until requests:  60%|██████    | 99/165 [13:48<07:41,  6.99s/it]Running generate_until requests:  61%|██████    | 100/165 [13:53<06:59,  6.45s/it]Running generate_until requests:  61%|██████    | 101/165 [14:00<07:07,  6.69s/it]Running generate_until requests:  62%|██████▏   | 102/165 [14:06<06:41,  6.37s/it]Running generate_until requests:  62%|██████▏   | 103/165 [14:11<06:00,  5.82s/it]Running generate_until requests:  63%|██████▎   | 104/165 [14:15<05:25,  5.33s/it]Running generate_until requests:  64%|██████▎   | 105/165 [14:26<06:57,  6.96s/it]Running generate_until requests:  64%|██████▍   | 106/165 [14:30<06:10,  6.27s/it]Running generate_until requests:  65%|██████▍   | 107/165 [14:46<08:44,  9.04s/it]Running generate_until requests:  65%|██████▌   | 108/165 [14:50<07:20,  7.74s/it]Running generate_until requests:  66%|██████▌   | 109/165 [14:56<06:34,  7.05s/it]Running generate_until requests:  67%|██████▋   | 110/165 [15:03<06:31,  7.12s/it]Running generate_until requests:  67%|██████▋   | 111/165 [15:12<06:47,  7.55s/it]Running generate_until requests:  68%|██████▊   | 112/165 [15:16<05:54,  6.68s/it]Running generate_until requests:  68%|██████▊   | 113/165 [15:22<05:38,  6.51s/it]Running generate_until requests:  69%|██████▉   | 114/165 [15:30<05:47,  6.82s/it]Running generate_until requests:  70%|██████▉   | 115/165 [15:36<05:22,  6.45s/it]Running generate_until requests:  70%|███████   | 116/165 [15:40<04:39,  5.71s/it]Running generate_until requests:  71%|███████   | 117/165 [15:42<03:52,  4.84s/it]Running generate_until requests:  72%|███████▏  | 118/165 [15:47<03:46,  4.81s/it]Running generate_until requests:  72%|███████▏  | 119/165 [15:53<04:01,  5.24s/it]Running generate_until requests:  73%|███████▎  | 120/165 [15:58<03:44,  4.99s/it]Running generate_until requests:  73%|███████▎  | 121/165 [16:02<03:30,  4.78s/it]Running generate_until requests:  74%|███████▍  | 122/165 [16:08<03:42,  5.17s/it]Running generate_until requests:  75%|███████▍  | 123/165 [16:17<04:21,  6.22s/it]Running generate_until requests:  75%|███████▌  | 124/165 [16:24<04:27,  6.53s/it]Running generate_until requests:  76%|███████▌  | 125/165 [16:29<04:03,  6.10s/it]Running generate_until requests:  76%|███████▋  | 126/165 [16:38<04:34,  7.04s/it]Running generate_until requests:  77%|███████▋  | 127/165 [16:46<04:31,  7.15s/it]Running generate_until requests:  78%|███████▊  | 128/165 [16:50<03:55,  6.37s/it]Running generate_until requests:  78%|███████▊  | 129/165 [16:57<03:55,  6.54s/it]Running generate_until requests:  79%|███████▉  | 130/165 [17:06<04:16,  7.34s/it]Running generate_until requests:  79%|███████▉  | 131/165 [17:16<04:30,  7.96s/it]Running generate_until requests:  80%|████████  | 132/165 [17:21<03:58,  7.24s/it]Running generate_until requests:  81%|████████  | 133/165 [17:28<03:44,  7.02s/it]Running generate_until requests:  81%|████████  | 134/165 [17:44<05:01,  9.71s/it]Running generate_until requests:  82%|████████▏ | 135/165 [17:47<03:48,  7.61s/it]Running generate_until requests:  82%|████████▏ | 136/165 [17:52<03:20,  6.93s/it]Running generate_until requests:  83%|████████▎ | 137/165 [17:58<03:10,  6.79s/it]Running generate_until requests:  84%|████████▎ | 138/165 [18:06<03:08,  7.00s/it]Running generate_until requests:  84%|████████▍ | 139/165 [18:10<02:37,  6.07s/it]Running generate_until requests:  85%|████████▍ | 140/165 [18:14<02:17,  5.50s/it]Running generate_until requests:  85%|████████▌ | 141/165 [18:23<02:40,  6.69s/it]Running generate_until requests:  86%|████████▌ | 142/165 [18:27<02:12,  5.76s/it]Running generate_until requests:  87%|████████▋ | 143/165 [18:33<02:09,  5.89s/it]Running generate_until requests:  87%|████████▋ | 144/165 [18:40<02:07,  6.08s/it]Running generate_until requests:  88%|████████▊ | 145/165 [18:49<02:18,  6.94s/it]Running generate_until requests:  88%|████████▊ | 146/165 [18:55<02:09,  6.79s/it]Running generate_until requests:  89%|████████▉ | 147/165 [19:06<02:21,  7.87s/it]Running generate_until requests:  90%|████████▉ | 148/165 [19:13<02:10,  7.67s/it]Running generate_until requests:  90%|█████████ | 149/165 [19:16<01:41,  6.32s/it]Running generate_until requests:  91%|█████████ | 150/165 [19:21<01:27,  5.80s/it]Running generate_until requests:  92%|█████████▏| 151/165 [19:26<01:19,  5.69s/it]Running generate_until requests:  92%|█████████▏| 152/165 [19:30<01:08,  5.29s/it]Running generate_until requests:  93%|█████████▎| 153/165 [19:45<01:38,  8.18s/it]Running generate_until requests:  93%|█████████▎| 154/165 [19:51<01:22,  7.52s/it]Running generate_until requests:  94%|█████████▍| 155/165 [19:54<01:01,  6.14s/it]Running generate_until requests:  95%|█████████▍| 156/165 [19:59<00:53,  5.89s/it]Running generate_until requests:  95%|█████████▌| 157/165 [20:05<00:46,  5.84s/it]Running generate_until requests:  96%|█████████▌| 158/165 [20:21<01:00,  8.70s/it]Running generate_until requests:  96%|█████████▋| 159/165 [20:33<00:58,  9.77s/it]Running generate_until requests:  97%|█████████▋| 160/165 [20:41<00:45,  9.17s/it]Running generate_until requests:  98%|█████████▊| 161/165 [20:45<00:30,  7.67s/it]Running generate_until requests:  98%|█████████▊| 162/165 [21:00<00:29,  9.99s/it]Running generate_until requests:  99%|█████████▉| 163/165 [21:08<00:18,  9.35s/it]Running generate_until requests:  99%|█████████▉| 164/165 [21:10<00:07,  7.18s/it]Running generate_until requests: 100%|██████████| 165/165 [21:17<00:00,  7.22s/it]Running generate_until requests: 100%|██████████| 165/165 [21:17<00:00,  7.75s/it]
[2024-06-04 07:03:16,717] torch.distributed.elastic.multiprocessing.api: [ERROR] failed (exitcode: -7) local_rank: 0 (pid: 600189) of binary: /private/home/beidic/.conda/envs/griffin/bin/python
Traceback (most recent call last):
  File "/private/home/beidic/.conda/envs/griffin/bin/accelerate", line 8, in <module>
    sys.exit(main())
             ^^^^^^
  File "/private/home/beidic/.conda/envs/griffin/lib/python3.12/site-packages/accelerate/commands/accelerate_cli.py", line 47, in main
    args.func(args)
  File "/private/home/beidic/.conda/envs/griffin/lib/python3.12/site-packages/accelerate/commands/launch.py", line 985, in launch_command
    multi_gpu_launcher(args)
  File "/private/home/beidic/.conda/envs/griffin/lib/python3.12/site-packages/accelerate/commands/launch.py", line 654, in multi_gpu_launcher
    distrib_run.run(args)
  File "/private/home/beidic/.conda/envs/griffin/lib/python3.12/site-packages/torch/distributed/run.py", line 803, in run
    elastic_launch(
  File "/private/home/beidic/.conda/envs/griffin/lib/python3.12/site-packages/torch/distributed/launcher/api.py", line 135, in __call__
    return launch_agent(self._config, self._entrypoint, list(args))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/private/home/beidic/.conda/envs/griffin/lib/python3.12/site-packages/torch/distributed/launcher/api.py", line 268, in launch_agent
    raise ChildFailedError(
torch.distributed.elastic.multiprocessing.errors.ChildFailedError: 
======================================================
main.py FAILED
------------------------------------------------------
Failures:
[1]:
  time      : 2024-06-04_07:03:16
  host      : learnfair5099.h2.fair
  rank      : 1 (local_rank: 1)
  exitcode  : -7 (pid: 600190)
  error_file: <N/A>
  traceback : Signal 7 (SIGBUS) received by PID 600190
[2]:
  time      : 2024-06-04_07:03:16
  host      : learnfair5099.h2.fair
  rank      : 2 (local_rank: 2)
  exitcode  : -7 (pid: 600191)
  error_file: <N/A>
  traceback : Signal 7 (SIGBUS) received by PID 600191
[3]:
  time      : 2024-06-04_07:03:16
  host      : learnfair5099.h2.fair
  rank      : 3 (local_rank: 3)
  exitcode  : -7 (pid: 600192)
  error_file: <N/A>
  traceback : Signal 7 (SIGBUS) received by PID 600192
[4]:
  time      : 2024-06-04_07:03:16
  host      : learnfair5099.h2.fair
  rank      : 4 (local_rank: 4)
  exitcode  : -7 (pid: 600193)
  error_file: <N/A>
  traceback : Signal 7 (SIGBUS) received by PID 600193
------------------------------------------------------
Root Cause (first observed failure):
[0]:
  time      : 2024-06-04_07:03:16
  host      : learnfair5099.h2.fair
  rank      : 0 (local_rank: 0)
  exitcode  : -7 (pid: 600189)
  error_file: <N/A>
  traceback : Signal 7 (SIGBUS) received by PID 600189
======================================================
/var/spool/slurm//job28572751/slurm_script: line 59: 600149 Bus error               (core dumped) accelerate launch --main_process_port 29510 --num_processes 8 --num_machines 1 main.py --model xhf --model_args pretrained=meta-llama/Llama-2-7b-hf,cats=True,check=True,kernel_size=16,spr=0.5,thr=0.1 --tasks gsm8k --batch_size 1
