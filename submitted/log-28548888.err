Already on 'yangexp2'
WARNING: Skipping /private/home/beidic/.conda/envs/griffin/lib/python3.12/site-packages/~egex-2024.5.15.dist-info due to invalid metadata entry 'name'
WARNING: Skipping /private/home/beidic/.conda/envs/griffin/lib/python3.12/site-packages/~yYAML-6.0.1.dist-info due to invalid metadata entry 'name'
WARNING: Ignoring invalid distribution ~umpy (/private/home/beidic/.conda/envs/griffin/lib/python3.12/site-packages)
WARNING: Ignoring invalid distribution ~umpy (/private/home/beidic/.conda/envs/griffin/lib/python3.12/site-packages)
WARNING: Ignoring invalid distribution ~umpy (/private/home/beidic/.conda/envs/griffin/lib/python3.12/site-packages)
WARNING: Ignoring invalid distribution ~umpy (/private/home/beidic/.conda/envs/griffin/lib/python3.12/site-packages)
WARNING: Ignoring invalid distribution ~umpy (/private/home/beidic/.conda/envs/griffin/lib/python3.12/site-packages)
WARNING: Ignoring invalid distribution ~umpy (/private/home/beidic/.conda/envs/griffin/lib/python3.12/site-packages)
Traceback (most recent call last):
  File "<frozen runpy>", line 189, in _run_module_as_main
  File "<frozen runpy>", line 148, in _get_module_details
  File "<frozen runpy>", line 112, in _get_module_details
  File "/private/home/beidic/.conda/envs/griffin/lib/python3.12/site-packages/wandb/__init__.py", line 27, in <module>
    from wandb import sdk as wandb_sdk
  File "/private/home/beidic/.conda/envs/griffin/lib/python3.12/site-packages/wandb/sdk/__init__.py", line 25, in <module>
    from .artifacts.artifact import Artifact
  File "/private/home/beidic/.conda/envs/griffin/lib/python3.12/site-packages/wandb/sdk/artifacts/artifact.py", line 37, in <module>
    from wandb.apis.normalize import normalize_exceptions
  File "/private/home/beidic/.conda/envs/griffin/lib/python3.12/site-packages/wandb/apis/__init__.py", line 44, in <module>
    from .public import Api as PublicApi  # noqa
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/private/home/beidic/.conda/envs/griffin/lib/python3.12/site-packages/wandb/apis/public/__init__.py", line 1, in <module>
    from wandb.apis.public.api import Api, RetryingClient, requests
  File "/private/home/beidic/.conda/envs/griffin/lib/python3.12/site-packages/wandb/apis/public/api.py", line 30, in <module>
    from wandb.sdk.launch.utils import LAUNCH_DEFAULT_PROJECT
  File "/private/home/beidic/.conda/envs/griffin/lib/python3.12/site-packages/wandb/sdk/launch/__init__.py", line 1, in <module>
    from ._launch import launch
  File "/private/home/beidic/.conda/envs/griffin/lib/python3.12/site-packages/wandb/sdk/launch/_launch.py", line 14, in <module>
    from .agent import LaunchAgent
  File "/private/home/beidic/.conda/envs/griffin/lib/python3.12/site-packages/wandb/sdk/launch/agent/__init__.py", line 1, in <module>
    from .agent import LaunchAgent
  File "/private/home/beidic/.conda/envs/griffin/lib/python3.12/site-packages/wandb/sdk/launch/agent/agent.py", line 16, in <module>
    from wandb.sdk.launch._launch_add import launch_add
  File "/private/home/beidic/.conda/envs/griffin/lib/python3.12/site-packages/wandb/sdk/launch/_launch_add.py", line 10, in <module>
    from wandb.sdk.launch.builder.build import build_image_from_project
  File "/private/home/beidic/.conda/envs/griffin/lib/python3.12/site-packages/wandb/sdk/launch/builder/build.py", line 11, in <module>
    import pkg_resources
  File "/private/home/beidic/.conda/envs/griffin/lib/python3.12/site-packages/pkg_resources/__init__.py", line 3327, in <module>
    @_call_aside
     ^^^^^^^^^^^
  File "/private/home/beidic/.conda/envs/griffin/lib/python3.12/site-packages/pkg_resources/__init__.py", line 3302, in _call_aside
    f(*args, **kwargs)
  File "/private/home/beidic/.conda/envs/griffin/lib/python3.12/site-packages/pkg_resources/__init__.py", line 3340, in _initialize_master_working_set
    working_set = WorkingSet._build_master()
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/private/home/beidic/.conda/envs/griffin/lib/python3.12/site-packages/pkg_resources/__init__.py", line 622, in _build_master
    ws = cls()
         ^^^^^
  File "/private/home/beidic/.conda/envs/griffin/lib/python3.12/site-packages/pkg_resources/__init__.py", line 615, in __init__
    self.add_entry(entry)
  File "/private/home/beidic/.conda/envs/griffin/lib/python3.12/site-packages/pkg_resources/__init__.py", line 671, in add_entry
    for dist in find_distributions(entry, True):
  File "/private/home/beidic/.conda/envs/griffin/lib/python3.12/site-packages/pkg_resources/__init__.py", line 2134, in find_on_path
    for dist in factory(fullpath):
  File "/private/home/beidic/.conda/envs/griffin/lib/python3.12/site-packages/pkg_resources/__init__.py", line 2192, in distributions_from_metadata
    if len(os.listdir(path)) == 0:
           ^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/private/home/beidic/.conda/envs/griffin/lib/python3.12/site-packages/~harset_normalizer-3.3.2.dist-info'
wandb: ERROR Find detailed error logs at: /tmp/debug-cli.beidic.log
Error: The wandb service process exited with 1. Ensure that `sys.executable` is a valid python interpreter. You can override it with the `_executable` setting or with the `WANDB__EXECUTABLE` environment variable.
Traceback (most recent call last):
  File "/private/home/beidic/.conda/envs/griffin/bin/transformers-cli", line 5, in <module>
    from transformers.commands.transformers_cli import main
  File "/private/home/beidic/.conda/envs/griffin/lib/python3.12/site-packages/transformers/__init__.py", line 26, in <module>
    from . import dependency_versions_check
  File "/private/home/beidic/.conda/envs/griffin/lib/python3.12/site-packages/transformers/dependency_versions_check.py", line 16, in <module>
    from .utils.versions import require_version, require_version_core
  File "/private/home/beidic/.conda/envs/griffin/lib/python3.12/site-packages/transformers/utils/__init__.py", line 18, in <module>
    from huggingface_hub import get_full_repo_name  # for backward compatibility
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/private/home/beidic/.conda/envs/griffin/lib/python3.12/site-packages/huggingface_hub/__init__.py", line 503, in __getattr__
    submod = importlib.import_module(submod_path)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/private/home/beidic/.conda/envs/griffin/lib/python3.12/importlib/__init__.py", line 90, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/private/home/beidic/.conda/envs/griffin/lib/python3.12/site-packages/huggingface_hub/hf_api.py", line 50, in <module>
    from ._commit_api import (
  File "/private/home/beidic/.conda/envs/griffin/lib/python3.12/site-packages/huggingface_hub/_commit_api.py", line 19, in <module>
    from .file_download import hf_hub_url
  File "/private/home/beidic/.conda/envs/griffin/lib/python3.12/site-packages/huggingface_hub/file_download.py", line 21, in <module>
    from ._local_folder import (
  File "/private/home/beidic/.conda/envs/griffin/lib/python3.12/site-packages/huggingface_hub/_local_folder.py", line 59, in <module>
    from .utils import WeakFileLock
  File "/private/home/beidic/.conda/envs/griffin/lib/python3.12/site-packages/huggingface_hub/utils/__init__.py", line 56, in <module>
  File "/private/home/beidic/.conda/envs/griffin/lib/python3.12/site-packages/huggingface_hub/utils/_headers.py", line 34, in <module>
ModuleNotFoundError: No module named 'huggingface_hub.utils._token'
/var/spool/slurm//job28548888/slurm_script: line 61: huggingface-cli: command not found
The following values were not passed to `accelerate launch` and had defaults used instead:
		More than one GPU was found, enabling multi-GPU training.
		If this was unintended please pass in `--num_processes=1`.
	`--mixed_precision` was set to a value of `'no'`
	`--dynamo_backend` was set to a value of `'no'`
To avoid this warning pass in values for each of the problematic parameters or run `accelerate config`.
2024-06-03:14:40:38,404 INFO     [main.py:288] Verbosity set to INFO
2024-06-03:14:40:38,404 INFO     [main.py:288] Verbosity set to INFO
2024-06-03:14:40:38,404 INFO     [main.py:288] Verbosity set to INFO
2024-06-03:14:40:38,404 INFO     [main.py:288] Verbosity set to INFO
2024-06-03:14:40:38,404 INFO     [main.py:288] Verbosity set to INFO
2024-06-03:14:40:38,404 INFO     [main.py:288] Verbosity set to INFO
2024-06-03:14:40:38,404 INFO     [main.py:288] Verbosity set to INFO
2024-06-03:14:40:39,354 INFO     [main.py:288] Verbosity set to INFO
2024-06-03:14:40:44,688 INFO     [main.py:378] Selected Tasks: ['gsm8k']
2024-06-03:14:40:44,688 INFO     [main.py:378] Selected Tasks: ['gsm8k']
2024-06-03:14:40:44,688 INFO     [main.py:378] Selected Tasks: ['gsm8k']
2024-06-03:14:40:44,688 INFO     [main.py:378] Selected Tasks: ['gsm8k']
2024-06-03:14:40:44,702 INFO     [xevaluator.py:137] Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234
2024-06-03:14:40:44,702 INFO     [xevaluator.py:137] Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234
2024-06-03:14:40:44,702 INFO     [xevaluator.py:184] Initializing xhf model, with arguments: {'pretrained': 'meta-llama/Llama-2-7b-hf', 'cats': True, 'check': False}
2024-06-03:14:40:44,702 INFO     [xevaluator.py:184] Initializing xhf model, with arguments: {'pretrained': 'meta-llama/Llama-2-7b-hf', 'cats': True, 'check': False}
2024-06-03:14:40:44,702 INFO     [xevaluator.py:137] Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234
2024-06-03:14:40:44,702 INFO     [xevaluator.py:137] Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234
2024-06-03:14:40:44,702 INFO     [xevaluator.py:184] Initializing xhf model, with arguments: {'pretrained': 'meta-llama/Llama-2-7b-hf', 'cats': True, 'check': False}
2024-06-03:14:40:44,702 INFO     [xevaluator.py:184] Initializing xhf model, with arguments: {'pretrained': 'meta-llama/Llama-2-7b-hf', 'cats': True, 'check': False}
2024-06-03:14:40:45,258 INFO     [main.py:378] Selected Tasks: ['gsm8k']
2024-06-03:14:40:45,262 INFO     [xevaluator.py:137] Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234
2024-06-03:14:40:45,262 INFO     [xevaluator.py:184] Initializing xhf model, with arguments: {'pretrained': 'meta-llama/Llama-2-7b-hf', 'cats': True, 'check': False}
2024-06-03:14:40:45,496 INFO     [main.py:378] Selected Tasks: ['gsm8k']
2024-06-03:14:40:45,500 INFO     [xevaluator.py:137] Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234
2024-06-03:14:40:45,500 INFO     [xevaluator.py:184] Initializing xhf model, with arguments: {'pretrained': 'meta-llama/Llama-2-7b-hf', 'cats': True, 'check': False}
2024-06-03:14:40:45,515 INFO     [main.py:378] Selected Tasks: ['gsm8k']
2024-06-03:14:40:45,519 INFO     [xevaluator.py:137] Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234
2024-06-03:14:40:45,519 INFO     [xevaluator.py:184] Initializing xhf model, with arguments: {'pretrained': 'meta-llama/Llama-2-7b-hf', 'cats': True, 'check': False}
2024-06-03:14:40:46,058 INFO     [main.py:378] Selected Tasks: ['gsm8k']
2024-06-03:14:40:46,062 INFO     [xevaluator.py:137] Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234
2024-06-03:14:40:46,062 INFO     [xevaluator.py:184] Initializing xhf model, with arguments: {'pretrained': 'meta-llama/Llama-2-7b-hf', 'cats': True, 'check': False}
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [01:00<01:00, 60.62s/it]Loading checkpoint shards:  50%|█████     | 1/2 [01:02<01:02, 62.62s/it]Loading checkpoint shards:  50%|█████     | 1/2 [01:01<01:01, 61.59s/it]Loading checkpoint shards:  50%|█████     | 1/2 [01:02<01:02, 62.59s/it]Loading checkpoint shards:  50%|█████     | 1/2 [01:02<01:02, 62.35s/it]Loading checkpoint shards:  50%|█████     | 1/2 [01:02<01:02, 62.43s/it]Loading checkpoint shards:  50%|█████     | 1/2 [01:02<01:02, 62.47s/it]Loading checkpoint shards:  50%|█████     | 1/2 [01:02<01:02, 62.03s/it]Loading checkpoint shards: 100%|██████████| 2/2 [01:20<00:00, 36.31s/it]Loading checkpoint shards: 100%|██████████| 2/2 [01:20<00:00, 40.22s/it]
Loading checkpoint shards: 100%|██████████| 2/2 [01:21<00:00, 36.80s/it]Loading checkpoint shards: 100%|██████████| 2/2 [01:21<00:00, 40.68s/it]
Loading checkpoint shards: 100%|██████████| 2/2 [01:21<00:00, 36.70s/it]Loading checkpoint shards: 100%|██████████| 2/2 [01:21<00:00, 40.57s/it]
Loading checkpoint shards: 100%|██████████| 2/2 [01:20<00:00, 36.77s/it]Loading checkpoint shards: 100%|██████████| 2/2 [01:20<00:00, 40.34s/it]
Loading checkpoint shards: 100%|██████████| 2/2 [01:20<00:00, 36.38s/it]Loading checkpoint shards: 100%|██████████| 2/2 [01:20<00:00, 40.17s/it]
Loading checkpoint shards: 100%|██████████| 2/2 [01:20<00:00, 36.54s/it]Loading checkpoint shards: 100%|██████████| 2/2 [01:20<00:00, 40.36s/it]
Loading checkpoint shards: 100%|██████████| 2/2 [01:21<00:00, 36.80s/it]Loading checkpoint shards: 100%|██████████| 2/2 [01:21<00:00, 40.67s/it]
Loading checkpoint shards: 100%|██████████| 2/2 [01:21<00:00, 36.75s/it]Loading checkpoint shards: 100%|██████████| 2/2 [01:21<00:00, 40.60s/it]
Using the latest cached version of the dataset since gsm8k couldn't be found on the Hugging Face Hub
2024-06-03:14:42:37,155 WARNING  [load.py:1631] Using the latest cached version of the dataset since gsm8k couldn't be found on the Hugging Face Hub
Found the latest cached dataset configuration 'main' at /private/home/beidic/.cache/huggingface/datasets/gsm8k/main/0.0.0/e53f048856ff4f594e959d75785d2c2d37b678ee (last modified on Thu May 16 07:01:08 2024).
2024-06-03:14:42:37,157 WARNING  [cache.py:95] Found the latest cached dataset configuration 'main' at /private/home/beidic/.cache/huggingface/datasets/gsm8k/main/0.0.0/e53f048856ff4f594e959d75785d2c2d37b678ee (last modified on Thu May 16 07:01:08 2024).
Using the latest cached version of the dataset since gsm8k couldn't be found on the Hugging Face Hub
2024-06-03:14:42:37,163 WARNING  [load.py:1631] Using the latest cached version of the dataset since gsm8k couldn't be found on the Hugging Face Hub
Found the latest cached dataset configuration 'main' at /private/home/beidic/.cache/huggingface/datasets/gsm8k/main/0.0.0/e53f048856ff4f594e959d75785d2c2d37b678ee (last modified on Thu May 16 07:01:08 2024).
2024-06-03:14:42:37,165 WARNING  [cache.py:95] Found the latest cached dataset configuration 'main' at /private/home/beidic/.cache/huggingface/datasets/gsm8k/main/0.0.0/e53f048856ff4f594e959d75785d2c2d37b678ee (last modified on Thu May 16 07:01:08 2024).
2024-06-03:14:42:37,396 INFO     [task.py:395] Building contexts for gsm8k on rank 1...
  0%|          | 0/165 [00:00<?, ?it/s]2024-06-03:14:42:37,428 INFO     [task.py:395] Building contexts for gsm8k on rank 5...
  0%|          | 0/165 [00:00<?, ?it/s] 13%|█▎        | 21/165 [00:00<00:00, 207.72it/s] 13%|█▎        | 21/165 [00:00<00:00, 206.08it/s] 25%|██▌       | 42/165 [00:00<00:00, 208.40it/s] 25%|██▌       | 42/165 [00:00<00:00, 206.46it/s] 38%|███▊      | 63/165 [00:00<00:00, 208.62it/s] 38%|███▊      | 63/165 [00:00<00:00, 206.59it/s] 51%|█████     | 84/165 [00:00<00:00, 208.77it/s] 51%|█████     | 84/165 [00:00<00:00, 206.78it/s] 64%|██████▎   | 105/165 [00:00<00:00, 208.97it/s] 64%|██████▎   | 105/165 [00:00<00:00, 207.01it/s] 76%|███████▋  | 126/165 [00:00<00:00, 209.15it/s] 76%|███████▋  | 126/165 [00:00<00:00, 206.98it/s] 89%|████████▉ | 147/165 [00:00<00:00, 209.21it/s] 89%|████████▉ | 147/165 [00:00<00:00, 206.87it/s]100%|██████████| 165/165 [00:00<00:00, 208.96it/s]
100%|██████████| 165/165 [00:00<00:00, 207.02it/s]
2024-06-03:14:42:49,012 INFO     [xhuggingface.py:314] Using 8 devices with data parallelism
Using the latest cached version of the dataset since gsm8k couldn't be found on the Hugging Face Hub
2024-06-03:14:42:49,249 WARNING  [load.py:1631] Using the latest cached version of the dataset since gsm8k couldn't be found on the Hugging Face Hub
Found the latest cached dataset configuration 'main' at /private/home/beidic/.cache/huggingface/datasets/gsm8k/main/0.0.0/e53f048856ff4f594e959d75785d2c2d37b678ee (last modified on Thu May 16 07:01:08 2024).
2024-06-03:14:42:49,251 WARNING  [cache.py:95] Found the latest cached dataset configuration 'main' at /private/home/beidic/.cache/huggingface/datasets/gsm8k/main/0.0.0/e53f048856ff4f594e959d75785d2c2d37b678ee (last modified on Thu May 16 07:01:08 2024).
Using the latest cached version of the dataset since gsm8k couldn't be found on the Hugging Face Hub
2024-06-03:14:42:49,362 WARNING  [load.py:1631] Using the latest cached version of the dataset since gsm8k couldn't be found on the Hugging Face Hub
Found the latest cached dataset configuration 'main' at /private/home/beidic/.cache/huggingface/datasets/gsm8k/main/0.0.0/e53f048856ff4f594e959d75785d2c2d37b678ee (last modified on Thu May 16 07:01:08 2024).
2024-06-03:14:42:49,363 WARNING  [cache.py:95] Found the latest cached dataset configuration 'main' at /private/home/beidic/.cache/huggingface/datasets/gsm8k/main/0.0.0/e53f048856ff4f594e959d75785d2c2d37b678ee (last modified on Thu May 16 07:01:08 2024).
2024-06-03:14:42:49,419 INFO     [task.py:395] Building contexts for gsm8k on rank 0...
  0%|          | 0/165 [00:00<?, ?it/s]2024-06-03:14:42:49,515 INFO     [task.py:395] Building contexts for gsm8k on rank 3...
  0%|          | 0/165 [00:00<?, ?it/s] 13%|█▎        | 22/165 [00:00<00:00, 213.36it/s] 13%|█▎        | 22/165 [00:00<00:00, 216.33it/s] 27%|██▋       | 44/165 [00:00<00:00, 214.72it/s] 27%|██▋       | 44/165 [00:00<00:00, 215.84it/s] 40%|████      | 66/165 [00:00<00:00, 214.89it/s] 40%|████      | 66/165 [00:00<00:00, 216.33it/s] 53%|█████▎    | 88/165 [00:00<00:00, 215.71it/s] 53%|█████▎    | 88/165 [00:00<00:00, 216.67it/s] 67%|██████▋   | 110/165 [00:00<00:00, 215.90it/s] 67%|██████▋   | 110/165 [00:00<00:00, 216.44it/s] 80%|████████  | 132/165 [00:00<00:00, 215.61it/s] 80%|████████  | 132/165 [00:00<00:00, 216.37it/s] 93%|█████████▎| 154/165 [00:00<00:00, 215.47it/s]100%|██████████| 165/165 [00:00<00:00, 215.35it/s]
 93%|█████████▎| 154/165 [00:00<00:00, 212.54it/s]100%|██████████| 165/165 [00:00<00:00, 210.39it/s]
Using the latest cached version of the dataset since gsm8k couldn't be found on the Hugging Face Hub
2024-06-03:14:42:54,024 WARNING  [load.py:1631] Using the latest cached version of the dataset since gsm8k couldn't be found on the Hugging Face Hub
Found the latest cached dataset configuration 'main' at /private/home/beidic/.cache/huggingface/datasets/gsm8k/main/0.0.0/e53f048856ff4f594e959d75785d2c2d37b678ee (last modified on Thu May 16 07:01:08 2024).
2024-06-03:14:42:54,025 WARNING  [cache.py:95] Found the latest cached dataset configuration 'main' at /private/home/beidic/.cache/huggingface/datasets/gsm8k/main/0.0.0/e53f048856ff4f594e959d75785d2c2d37b678ee (last modified on Thu May 16 07:01:08 2024).
2024-06-03:14:42:54,182 INFO     [task.py:395] Building contexts for gsm8k on rank 7...
  0%|          | 0/164 [00:00<?, ?it/s] 10%|▉         | 16/164 [00:00<00:00, 154.93it/s] 21%|██        | 34/164 [00:00<00:00, 165.31it/s] 34%|███▍      | 56/164 [00:00<00:00, 189.08it/s]Using the latest cached version of the dataset since gsm8k couldn't be found on the Hugging Face Hub
2024-06-03:14:42:54,611 WARNING  [load.py:1631] Using the latest cached version of the dataset since gsm8k couldn't be found on the Hugging Face Hub
Found the latest cached dataset configuration 'main' at /private/home/beidic/.cache/huggingface/datasets/gsm8k/main/0.0.0/e53f048856ff4f594e959d75785d2c2d37b678ee (last modified on Thu May 16 07:01:08 2024).
2024-06-03:14:42:54,614 WARNING  [cache.py:95] Found the latest cached dataset configuration 'main' at /private/home/beidic/.cache/huggingface/datasets/gsm8k/main/0.0.0/e53f048856ff4f594e959d75785d2c2d37b678ee (last modified on Thu May 16 07:01:08 2024).
 48%|████▊     | 78/164 [00:00<00:00, 196.65it/s] 60%|█████▉    | 98/164 [00:00<00:00, 179.62it/s] 71%|███████▏  | 117/164 [00:00<00:00, 173.23it/s]2024-06-03:14:42:54,877 INFO     [task.py:395] Building contexts for gsm8k on rank 4...
  0%|          | 0/165 [00:00<?, ?it/s]Using the latest cached version of the dataset since gsm8k couldn't be found on the Hugging Face Hub
2024-06-03:14:42:54,915 WARNING  [load.py:1631] Using the latest cached version of the dataset since gsm8k couldn't be found on the Hugging Face Hub
Found the latest cached dataset configuration 'main' at /private/home/beidic/.cache/huggingface/datasets/gsm8k/main/0.0.0/e53f048856ff4f594e959d75785d2c2d37b678ee (last modified on Thu May 16 07:01:08 2024).
2024-06-03:14:42:54,917 WARNING  [cache.py:95] Found the latest cached dataset configuration 'main' at /private/home/beidic/.cache/huggingface/datasets/gsm8k/main/0.0.0/e53f048856ff4f594e959d75785d2c2d37b678ee (last modified on Thu May 16 07:01:08 2024).
Using the latest cached version of the dataset since gsm8k couldn't be found on the Hugging Face Hub
2024-06-03:14:42:54,930 WARNING  [load.py:1631] Using the latest cached version of the dataset since gsm8k couldn't be found on the Hugging Face Hub
Found the latest cached dataset configuration 'main' at /private/home/beidic/.cache/huggingface/datasets/gsm8k/main/0.0.0/e53f048856ff4f594e959d75785d2c2d37b678ee (last modified on Thu May 16 07:01:08 2024).
2024-06-03:14:42:54,932 WARNING  [cache.py:95] Found the latest cached dataset configuration 'main' at /private/home/beidic/.cache/huggingface/datasets/gsm8k/main/0.0.0/e53f048856ff4f594e959d75785d2c2d37b678ee (last modified on Thu May 16 07:01:08 2024).
 83%|████████▎ | 136/164 [00:00<00:00, 177.01it/s] 10%|▉         | 16/165 [00:00<00:00, 159.30it/s] 94%|█████████▍| 154/164 [00:00<00:00, 165.51it/s] 19%|█▉        | 32/165 [00:00<00:00, 145.97it/s]100%|██████████| 164/164 [00:00<00:00, 170.74it/s]
2024-06-03:14:42:55,205 INFO     [task.py:395] Building contexts for gsm8k on rank 2...
2024-06-03:14:42:55,205 INFO     [task.py:395] Building contexts for gsm8k on rank 6...
 28%|██▊       | 47/165 [00:00<00:00, 141.90it/s]  0%|          | 0/165 [00:00<?, ?it/s]  0%|          | 0/165 [00:00<?, ?it/s] 12%|█▏        | 20/165 [00:00<00:00, 197.43it/s] 38%|███▊      | 63/165 [00:00<00:00, 145.56it/s]  9%|▉         | 15/165 [00:00<00:01, 142.00it/s] 24%|██▍       | 40/165 [00:00<00:00, 197.45it/s] 47%|████▋     | 78/165 [00:00<00:00, 143.50it/s] 18%|█▊        | 30/165 [00:00<00:00, 140.89it/s] 36%|███▋      | 60/165 [00:00<00:00, 198.23it/s] 56%|█████▋    | 93/165 [00:00<00:00, 142.48it/s] 27%|██▋       | 45/165 [00:00<00:00, 140.69it/s] 48%|████▊     | 80/165 [00:00<00:00, 198.50it/s] 65%|██████▌   | 108/165 [00:00<00:00, 141.88it/s] 36%|███▋      | 60/165 [00:00<00:00, 140.69it/s] 61%|██████    | 100/165 [00:00<00:00, 198.91it/s] 75%|███████▍  | 123/165 [00:00<00:00, 141.42it/s] 45%|████▌     | 75/165 [00:00<00:00, 140.60it/s] 73%|███████▎  | 120/165 [00:00<00:00, 198.93it/s] 84%|████████▎ | 138/165 [00:00<00:00, 141.28it/s] 55%|█████▍    | 90/165 [00:00<00:00, 141.16it/s] 85%|████████▍ | 140/165 [00:00<00:00, 198.87it/s] 93%|█████████▎| 153/165 [00:01<00:00, 141.63it/s] 64%|██████▎   | 105/165 [00:00<00:00, 141.60it/s] 97%|█████████▋| 160/165 [00:00<00:00, 198.77it/s]100%|██████████| 165/165 [00:01<00:00, 142.80it/s]
100%|██████████| 165/165 [00:00<00:00, 198.46it/s]
 73%|███████▎  | 120/165 [00:00<00:00, 142.65it/s] 82%|████████▏ | 135/165 [00:00<00:00, 140.84it/s] 91%|█████████ | 150/165 [00:01<00:00, 142.58it/s]100%|██████████| 165/165 [00:01<00:00, 145.06it/s]
2024-06-03:14:43:00,697 INFO     [xevaluator.py:395] Running generate_until requests
2024-06-03:14:43:00,697 INFO     [xevaluator.py:395] Running generate_until requests
2024-06-03:14:43:00,697 INFO     [xevaluator.py:395] Running generate_until requests
2024-06-03:14:43:00,697 INFO     [xevaluator.py:395] Running generate_until requests
2024-06-03:14:43:00,697 INFO     [xevaluator.py:395] Running generate_until requests
2024-06-03:14:43:00,697 INFO     [xevaluator.py:395] Running generate_until requests
2024-06-03:14:43:00,697 INFO     [xevaluator.py:395] Running generate_until requests
Running generate_until requests:   0%|          | 0/165 [00:00<?, ?it/s]2024-06-03:14:43:00,698 INFO     [xevaluator.py:395] Running generate_until requests
Running generate_until requests:   1%|          | 1/165 [00:14<39:42, 14.53s/it]Running generate_until requests:   1%|          | 2/165 [00:27<36:52, 13.57s/it]Running generate_until requests:   2%|▏         | 3/165 [00:30<24:01,  8.90s/it]Running generate_until requests:   2%|▏         | 4/165 [00:43<28:04, 10.46s/it]Running generate_until requests:   3%|▎         | 5/165 [00:52<26:24,  9.90s/it]Running generate_until requests:   4%|▎         | 6/165 [00:56<21:06,  7.97s/it]Running generate_until requests:   4%|▍         | 7/165 [00:58<15:54,  6.04s/it]Running generate_until requests:   5%|▍         | 8/165 [01:03<14:35,  5.58s/it]Running generate_until requests:   5%|▌         | 9/165 [01:07<13:05,  5.04s/it]Running generate_until requests:   6%|▌         | 10/165 [01:11<12:40,  4.91s/it]Running generate_until requests:   7%|▋         | 11/165 [01:18<14:05,  5.49s/it]Running generate_until requests:   7%|▋         | 12/165 [01:21<12:06,  4.75s/it]Running generate_until requests:   8%|▊         | 13/165 [01:26<11:56,  4.71s/it]Running generate_until requests:   8%|▊         | 14/165 [01:35<15:09,  6.02s/it]Running generate_until requests:   9%|▉         | 15/165 [01:39<13:26,  5.37s/it]Running generate_until requests:  10%|▉         | 16/165 [01:44<13:10,  5.31s/it]Running generate_until requests:  10%|█         | 17/165 [01:50<13:28,  5.46s/it]Running generate_until requests:  11%|█         | 18/165 [01:54<12:23,  5.06s/it]Running generate_until requests:  12%|█▏        | 19/165 [02:02<14:46,  6.07s/it]Running generate_until requests:  12%|█▏        | 20/165 [02:08<14:30,  6.01s/it]Running generate_until requests:  13%|█▎        | 21/165 [02:14<14:15,  5.94s/it]Running generate_until requests:  13%|█▎        | 22/165 [02:19<13:10,  5.52s/it]Running generate_until requests:  14%|█▍        | 23/165 [02:31<18:13,  7.70s/it]Running generate_until requests:  15%|█▍        | 24/165 [02:34<14:50,  6.32s/it]Running generate_until requests:  15%|█▌        | 25/165 [02:41<14:40,  6.29s/it]Running generate_until requests:  16%|█▌        | 26/165 [02:47<14:45,  6.37s/it]Running generate_until requests:  16%|█▋        | 27/165 [02:52<13:34,  5.90s/it]Running generate_until requests:  17%|█▋        | 28/165 [03:02<16:18,  7.14s/it]Running generate_until requests:  18%|█▊        | 29/165 [03:12<18:01,  7.95s/it]Running generate_until requests:  18%|█▊        | 30/165 [03:14<14:13,  6.32s/it]Running generate_until requests:  19%|█▉        | 31/165 [03:19<13:14,  5.93s/it]Running generate_until requests:  19%|█▉        | 32/165 [03:26<13:41,  6.18s/it]Running generate_until requests:  20%|██        | 33/165 [03:28<10:58,  4.99s/it]Running generate_until requests:  21%|██        | 34/165 [03:32<10:13,  4.69s/it]Running generate_until requests:  21%|██        | 35/165 [03:38<10:47,  4.98s/it]Running generate_until requests:  22%|██▏       | 36/165 [03:43<10:55,  5.08s/it]Running generate_until requests:  22%|██▏       | 37/165 [03:45<08:58,  4.21s/it]Running generate_until requests:  23%|██▎       | 38/165 [03:50<09:22,  4.43s/it]Running generate_until requests:  24%|██▎       | 39/165 [03:55<09:11,  4.38s/it]Running generate_until requests:  24%|██▍       | 40/165 [03:59<08:55,  4.28s/it]Running generate_until requests:  25%|██▍       | 41/165 [04:04<09:30,  4.60s/it]Running generate_until requests:  25%|██▌       | 42/165 [04:09<09:45,  4.76s/it]Running generate_until requests:  26%|██▌       | 43/165 [04:13<09:11,  4.52s/it]Running generate_until requests:  27%|██▋       | 44/165 [04:22<11:33,  5.73s/it]Running generate_until requests:  27%|██▋       | 45/165 [04:27<11:27,  5.73s/it]Running generate_until requests:  28%|██▊       | 46/165 [04:32<10:50,  5.46s/it]Running generate_until requests:  28%|██▊       | 47/165 [04:37<10:08,  5.16s/it]Running generate_until requests:  29%|██▉       | 48/165 [04:40<08:59,  4.61s/it]Running generate_until requests:  30%|██▉       | 49/165 [04:45<09:05,  4.70s/it]Running generate_until requests:  30%|███       | 50/165 [04:50<09:13,  4.82s/it]Running generate_until requests:  31%|███       | 51/165 [04:56<09:36,  5.06s/it]Running generate_until requests:  32%|███▏      | 52/165 [05:08<13:52,  7.37s/it]Running generate_until requests:  32%|███▏      | 53/165 [05:18<15:12,  8.15s/it]Running generate_until requests:  33%|███▎      | 54/165 [05:31<17:37,  9.53s/it]Running generate_until requests:  33%|███▎      | 55/165 [05:44<19:13, 10.49s/it]Running generate_until requests:  34%|███▍      | 56/165 [05:49<16:11,  8.91s/it]Running generate_until requests:  35%|███▍      | 57/165 [05:54<14:03,  7.81s/it]Running generate_until requests:  35%|███▌      | 58/165 [06:01<13:18,  7.46s/it]Running generate_until requests:  36%|███▌      | 59/165 [06:06<11:55,  6.75s/it]Running generate_until requests:  36%|███▋      | 60/165 [06:19<14:58,  8.55s/it]Running generate_until requests:  37%|███▋      | 61/165 [06:24<12:54,  7.45s/it]Running generate_until requests:  38%|███▊      | 62/165 [06:27<10:50,  6.32s/it]Running generate_until requests:  38%|███▊      | 63/165 [06:30<08:34,  5.04s/it]Running generate_until requests:  39%|███▉      | 64/165 [06:34<08:00,  4.76s/it]Running generate_until requests:  39%|███▉      | 65/165 [06:36<06:50,  4.10s/it]Running generate_until requests:  40%|████      | 66/165 [06:41<07:13,  4.38s/it]Running generate_until requests:  41%|████      | 67/165 [06:44<06:09,  3.77s/it]Running generate_until requests:  41%|████      | 68/165 [06:51<07:55,  4.90s/it]Running generate_until requests:  42%|████▏     | 69/165 [06:59<09:26,  5.90s/it]Running generate_until requests:  42%|████▏     | 70/165 [07:12<12:35,  7.96s/it]Running generate_until requests:  43%|████▎     | 71/165 [07:21<12:44,  8.13s/it]Running generate_until requests:  44%|████▎     | 72/165 [07:25<10:59,  7.09s/it]Running generate_until requests:  44%|████▍     | 73/165 [07:31<10:26,  6.81s/it]Running generate_until requests:  45%|████▍     | 74/165 [07:36<09:16,  6.11s/it]Running generate_until requests:  45%|████▌     | 75/165 [07:49<12:08,  8.10s/it]Running generate_until requests:  46%|████▌     | 76/165 [07:54<10:57,  7.39s/it]Running generate_until requests:  47%|████▋     | 77/165 [08:07<13:11,  9.00s/it]Running generate_until requests:  47%|████▋     | 78/165 [08:20<14:40, 10.12s/it]Running generate_until requests:  48%|████▊     | 79/165 [08:30<14:36, 10.19s/it]Running generate_until requests:  48%|████▊     | 80/165 [08:37<12:59,  9.16s/it]Running generate_until requests:  49%|████▉     | 81/165 [08:50<14:19, 10.23s/it]Running generate_until requests:  50%|████▉     | 82/165 [08:53<11:27,  8.29s/it]Running generate_until requests:  50%|█████     | 83/165 [09:05<12:28,  9.12s/it]Running generate_until requests:  51%|█████     | 84/165 [09:10<10:40,  7.90s/it]Running generate_until requests:  52%|█████▏    | 85/165 [09:18<10:38,  7.98s/it]Running generate_until requests:  52%|█████▏    | 86/165 [09:29<11:48,  8.96s/it]Running generate_until requests:  53%|█████▎    | 87/165 [09:34<09:56,  7.65s/it]Running generate_until requests:  53%|█████▎    | 88/165 [09:38<08:37,  6.72s/it]Running generate_until requests:  54%|█████▍    | 89/165 [09:44<08:16,  6.53s/it]Running generate_until requests:  55%|█████▍    | 90/165 [09:47<06:48,  5.45s/it]Running generate_until requests:  55%|█████▌    | 91/165 [09:54<07:11,  5.83s/it]Running generate_until requests:  56%|█████▌    | 92/165 [09:57<06:11,  5.09s/it]Running generate_until requests:  56%|█████▋    | 93/165 [10:04<06:48,  5.67s/it]Running generate_until requests:  57%|█████▋    | 94/165 [10:11<07:07,  6.03s/it]Running generate_until requests:  58%|█████▊    | 95/165 [10:18<07:17,  6.25s/it]Running generate_until requests:  58%|█████▊    | 96/165 [10:23<06:42,  5.84s/it]Running generate_until requests:  59%|█████▉    | 97/165 [10:26<05:47,  5.10s/it]Running generate_until requests:  59%|█████▉    | 98/165 [10:30<05:20,  4.78s/it]Running generate_until requests:  60%|██████    | 99/165 [10:35<05:10,  4.71s/it]Running generate_until requests:  61%|██████    | 100/165 [10:39<04:55,  4.55s/it]Running generate_until requests:  61%|██████    | 101/165 [10:43<04:46,  4.48s/it]Running generate_until requests:  62%|██████▏   | 102/165 [10:56<07:17,  6.95s/it]Running generate_until requests:  62%|██████▏   | 103/165 [11:09<08:58,  8.68s/it]Running generate_until requests:  63%|██████▎   | 104/165 [11:11<06:56,  6.83s/it]Running generate_until requests:  64%|██████▎   | 105/165 [11:18<06:50,  6.84s/it]Running generate_until requests:  64%|██████▍   | 106/165 [11:21<05:42,  5.81s/it]Running generate_until requests:  65%|██████▍   | 107/165 [11:34<07:37,  7.88s/it]Running generate_until requests:  65%|██████▌   | 108/165 [11:37<06:10,  6.49s/it]Running generate_until requests:  66%|██████▌   | 109/165 [11:42<05:31,  5.92s/it]Running generate_until requests:  67%|██████▋   | 110/165 [11:48<05:27,  5.95s/it]Running generate_until requests:  67%|██████▋   | 111/165 [12:01<07:10,  7.98s/it]Running generate_until requests:  68%|██████▊   | 112/165 [12:04<05:54,  6.69s/it]Running generate_until requests:  68%|██████▊   | 113/165 [12:10<05:24,  6.25s/it]Running generate_until requests:  69%|██████▉   | 114/165 [12:16<05:13,  6.15s/it]Running generate_until requests:  70%|██████▉   | 115/165 [12:19<04:23,  5.26s/it]Running generate_until requests:  70%|███████   | 116/165 [12:22<03:42,  4.55s/it]Running generate_until requests:  71%|███████   | 117/165 [12:23<02:58,  3.72s/it]Running generate_until requests:  72%|███████▏  | 118/165 [12:27<02:58,  3.81s/it]Running generate_until requests:  72%|███████▏  | 119/165 [12:32<03:04,  4.01s/it]Running generate_until requests:  73%|███████▎  | 120/165 [12:36<02:58,  3.97s/it]Running generate_until requests:  73%|███████▎  | 121/165 [12:39<02:39,  3.62s/it]Running generate_until requests:  74%|███████▍  | 122/165 [12:44<02:56,  4.12s/it]Running generate_until requests:  75%|███████▍  | 123/165 [12:51<03:33,  5.08s/it]Running generate_until requests:  75%|███████▌  | 124/165 [12:58<03:52,  5.67s/it]Running generate_until requests:  76%|███████▌  | 125/165 [13:02<03:22,  5.07s/it]Running generate_until requests:  76%|███████▋  | 126/165 [13:06<03:05,  4.77s/it]Running generate_until requests:  77%|███████▋  | 127/165 [13:14<03:39,  5.77s/it]Running generate_until requests:  78%|███████▊  | 128/165 [13:18<03:14,  5.27s/it]Running generate_until requests:  78%|███████▊  | 129/165 [13:24<03:14,  5.40s/it]Running generate_until requests:  79%|███████▉  | 130/165 [13:31<03:31,  6.05s/it]Running generate_until requests:  79%|███████▉  | 131/165 [13:44<04:33,  8.04s/it]Running generate_until requests:  80%|████████  | 132/165 [13:49<03:50,  6.99s/it]Running generate_until requests:  81%|████████  | 133/165 [13:53<03:21,  6.29s/it]Running generate_until requests:  81%|████████  | 134/165 [13:59<03:11,  6.18s/it]Running generate_until requests:  82%|████████▏ | 135/165 [14:02<02:30,  5.01s/it]Running generate_until requests:  82%|████████▏ | 136/165 [14:04<02:05,  4.33s/it]Running generate_until requests:  83%|████████▎ | 137/165 [14:09<02:07,  4.57s/it]Running generate_until requests:  84%|████████▎ | 138/165 [14:17<02:24,  5.34s/it]Running generate_until requests:  84%|████████▍ | 139/165 [14:20<02:03,  4.74s/it]Running generate_until requests:  85%|████████▍ | 140/165 [14:23<01:48,  4.36s/it]Running generate_until requests:  85%|████████▌ | 141/165 [14:30<02:03,  5.16s/it]Running generate_until requests:  86%|████████▌ | 142/165 [14:33<01:42,  4.46s/it]Running generate_until requests:  87%|████████▋ | 143/165 [14:37<01:30,  4.13s/it]Running generate_until requests:  87%|████████▋ | 144/165 [14:42<01:35,  4.53s/it]Running generate_until requests:  88%|████████▊ | 145/165 [14:47<01:35,  4.77s/it]Running generate_until requests:  88%|████████▊ | 146/165 [14:53<01:34,  4.96s/it]Running generate_until requests:  89%|████████▉ | 147/165 [14:58<01:33,  5.17s/it]Running generate_until requests:  90%|████████▉ | 148/165 [15:06<01:39,  5.85s/it]Running generate_until requests:  90%|█████████ | 149/165 [15:08<01:18,  4.88s/it]Running generate_until requests:  91%|█████████ | 150/165 [15:12<01:08,  4.55s/it]Running generate_until requests:  92%|█████████▏| 151/165 [15:17<01:03,  4.54s/it]Running generate_until requests:  92%|█████████▏| 152/165 [15:20<00:55,  4.26s/it]Running generate_until requests:  93%|█████████▎| 153/165 [15:33<01:21,  6.79s/it]Running generate_until requests:  93%|█████████▎| 154/165 [15:38<01:08,  6.24s/it]Running generate_until requests:  94%|█████████▍| 155/165 [15:40<00:50,  5.09s/it]Running generate_until requests:  95%|█████████▍| 156/165 [15:46<00:48,  5.35s/it]Running generate_until requests:  95%|█████████▌| 157/165 [15:50<00:39,  4.94s/it]Running generate_until requests:  96%|█████████▌| 158/165 [16:03<00:50,  7.27s/it]Running generate_until requests:  96%|█████████▋| 159/165 [16:09<00:41,  6.94s/it]Running generate_until requests:  97%|█████████▋| 160/165 [16:16<00:33,  6.80s/it]Running generate_until requests:  98%|█████████▊| 161/165 [16:19<00:23,  5.88s/it]Running generate_until requests:  98%|█████████▊| 162/165 [16:32<00:23,  7.91s/it]Running generate_until requests:  99%|█████████▉| 163/165 [16:36<00:13,  6.83s/it]Running generate_until requests:  99%|█████████▉| 164/165 [16:40<00:05,  5.90s/it]Running generate_until requests: 100%|██████████| 165/165 [16:46<00:00,  5.93s/it]Running generate_until requests: 100%|██████████| 165/165 [16:46<00:00,  6.10s/it]
[2024-06-03 15:05:25,389] torch.distributed.elastic.multiprocessing.api: [WARNING] Sending process 3485939 closing signal SIGTERM
[2024-06-03 15:05:25,414] torch.distributed.elastic.multiprocessing.api: [WARNING] Sending process 3485940 closing signal SIGTERM
[2024-06-03 15:05:25,415] torch.distributed.elastic.multiprocessing.api: [WARNING] Sending process 3485941 closing signal SIGTERM
[2024-06-03 15:05:25,415] torch.distributed.elastic.multiprocessing.api: [WARNING] Sending process 3485942 closing signal SIGTERM
[2024-06-03 15:05:25,415] torch.distributed.elastic.multiprocessing.api: [WARNING] Sending process 3485943 closing signal SIGTERM
[2024-06-03 15:05:31,325] torch.distributed.elastic.multiprocessing.api: [ERROR] failed (exitcode: -7) local_rank: 5 (pid: 3485944) of binary: /private/home/beidic/.conda/envs/griffin/bin/python
Traceback (most recent call last):
  File "/private/home/beidic/.conda/envs/griffin/bin/accelerate", line 8, in <module>
    sys.exit(main())
             ^^^^^^
  File "/private/home/beidic/.conda/envs/griffin/lib/python3.12/site-packages/accelerate/commands/accelerate_cli.py", line 47, in main
    args.func(args)
  File "/private/home/beidic/.conda/envs/griffin/lib/python3.12/site-packages/accelerate/commands/launch.py", line 985, in launch_command
    multi_gpu_launcher(args)
  File "/private/home/beidic/.conda/envs/griffin/lib/python3.12/site-packages/accelerate/commands/launch.py", line 654, in multi_gpu_launcher
    distrib_run.run(args)
  File "/private/home/beidic/.conda/envs/griffin/lib/python3.12/site-packages/torch/distributed/run.py", line 803, in run
    elastic_launch(
  File "/private/home/beidic/.conda/envs/griffin/lib/python3.12/site-packages/torch/distributed/launcher/api.py", line 135, in __call__
    return launch_agent(self._config, self._entrypoint, list(args))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/private/home/beidic/.conda/envs/griffin/lib/python3.12/site-packages/torch/distributed/launcher/api.py", line 268, in launch_agent
    raise ChildFailedError(
torch.distributed.elastic.multiprocessing.errors.ChildFailedError: 
=======================================================
main.py FAILED
-------------------------------------------------------
Failures:
[1]:
  time      : 2024-06-03_15:05:25
  host      : learnfair7707.h2.fair
  rank      : 6 (local_rank: 6)
  exitcode  : -7 (pid: 3485945)
  error_file: <N/A>
  traceback : Signal 7 (SIGBUS) received by PID 3485945
[2]:
  time      : 2024-06-03_15:05:25
  host      : learnfair7707.h2.fair
  rank      : 7 (local_rank: 7)
  exitcode  : -7 (pid: 3485946)
  error_file: <N/A>
  traceback : Signal 7 (SIGBUS) received by PID 3485946
-------------------------------------------------------
Root Cause (first observed failure):
[0]:
  time      : 2024-06-03_15:05:25
  host      : learnfair7707.h2.fair
  rank      : 5 (local_rank: 5)
  exitcode  : -7 (pid: 3485944)
  error_file: <N/A>
  traceback : Signal 7 (SIGBUS) received by PID 3485944
=======================================================
/var/spool/slurm//job28548888/slurm_script: line 63: 3485887 Bus error               (core dumped) accelerate launch --main_process_port 29510 --num_processes 8 --num_machines 1 main.py --model xhf --model_args pretrained=meta-llama/Llama-2-7b-hf,cats=True,check=False --tasks gsm8k --batch_size 1
