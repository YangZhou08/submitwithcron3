ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.
datasets 2.19.1 requires fsspec[http]<=2024.3.1,>=2023.1.0, but you have fsspec 2024.6.0 which is incompatible.
Already on 'yangexp2'
wandb: Currently logged in as: stevenzhou0816100. Use `wandb login --relogin` to force relogin
Traceback (most recent call last):
  File "/private/home/beidic/.conda/envs/griffin/bin/huggingface-cli", line 8, in <module>
    sys.exit(main())
             ^^^^^^
  File "/private/home/beidic/.conda/envs/griffin/lib/python3.12/site-packages/huggingface_hub/commands/huggingface_cli.py", line 51, in main
    service.run()
  File "/private/home/beidic/.conda/envs/griffin/lib/python3.12/site-packages/huggingface_hub/commands/user.py", line 98, in run
    login(token=self.args.token, add_to_git_credential=self.args.add_to_git_credential)
  File "/private/home/beidic/.conda/envs/griffin/lib/python3.12/site-packages/huggingface_hub/_login.py", line 111, in login
    _login(token, add_to_git_credential=add_to_git_credential, write_permission=write_permission)
  File "/private/home/beidic/.conda/envs/griffin/lib/python3.12/site-packages/huggingface_hub/_login.py", line 307, in _login
    raise ValueError("Invalid token passed!")
ValueError: Invalid token passed!
The following values were not passed to `accelerate launch` and had defaults used instead:
		More than one GPU was found, enabling multi-GPU training.
		If this was unintended please pass in `--num_processes=1`.
	`--mixed_precision` was set to a value of `'no'`
	`--dynamo_backend` was set to a value of `'no'`
To avoid this warning pass in values for each of the problematic parameters or run `accelerate config`.
2024-06-04:06:41:14,781 INFO     [main.py:288] Verbosity set to INFO
2024-06-04:06:41:14,781 INFO     [main.py:288] Verbosity set to INFO
2024-06-04:06:41:14,781 INFO     [main.py:288] Verbosity set to INFO
2024-06-04:06:41:14,781 INFO     [main.py:288] Verbosity set to INFO
2024-06-04:06:41:14,794 INFO     [main.py:288] Verbosity set to INFO
2024-06-04:06:41:15,344 INFO     [main.py:288] Verbosity set to INFO
2024-06-04:06:41:16,854 INFO     [main.py:288] Verbosity set to INFO
2024-06-04:06:41:18,386 INFO     [main.py:288] Verbosity set to INFO
2024-06-04:06:41:21,188 WARNING  [main.py:303]  --limit SHOULD ONLY BE USED FOR TESTING.REAL METRICS SHOULD NOT BE COMPUTED USING LIMIT.
2024-06-04:06:41:21,190 WARNING  [main.py:303]  --limit SHOULD ONLY BE USED FOR TESTING.REAL METRICS SHOULD NOT BE COMPUTED USING LIMIT.
2024-06-04:06:41:21,191 INFO     [main.py:378] Selected Tasks: ['gsm8k']
2024-06-04:06:41:21,191 INFO     [main.py:378] Selected Tasks: ['gsm8k']
2024-06-04:06:41:21,201 INFO     [xevaluator.py:137] Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234
2024-06-04:06:41:21,201 INFO     [xevaluator.py:137] Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234
2024-06-04:06:41:21,201 INFO     [xevaluator.py:184] Initializing xhf model, with arguments: {'pretrained': 'meta-llama/Meta-Llama-3-8B-Instruct', 'griffin': False, 'check': False}
2024-06-04:06:41:21,202 INFO     [xevaluator.py:184] Initializing xhf model, with arguments: {'pretrained': 'meta-llama/Meta-Llama-3-8B-Instruct', 'griffin': False, 'check': False}
2024-06-04:06:41:21,207 WARNING  [main.py:303]  --limit SHOULD ONLY BE USED FOR TESTING.REAL METRICS SHOULD NOT BE COMPUTED USING LIMIT.
2024-06-04:06:41:21,208 INFO     [main.py:378] Selected Tasks: ['gsm8k']
2024-06-04:06:41:21,212 INFO     [xevaluator.py:137] Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234
2024-06-04:06:41:21,212 INFO     [xevaluator.py:184] Initializing xhf model, with arguments: {'pretrained': 'meta-llama/Meta-Llama-3-8B-Instruct', 'griffin': False, 'check': False}
2024-06-04:06:41:21,332 WARNING  [main.py:303]  --limit SHOULD ONLY BE USED FOR TESTING.REAL METRICS SHOULD NOT BE COMPUTED USING LIMIT.
2024-06-04:06:41:21,333 INFO     [main.py:378] Selected Tasks: ['gsm8k']
2024-06-04:06:41:21,337 INFO     [xevaluator.py:137] Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234
2024-06-04:06:41:21,337 INFO     [xevaluator.py:184] Initializing xhf model, with arguments: {'pretrained': 'meta-llama/Meta-Llama-3-8B-Instruct', 'griffin': False, 'check': False}
2024-06-04:06:41:21,390 WARNING  [main.py:303]  --limit SHOULD ONLY BE USED FOR TESTING.REAL METRICS SHOULD NOT BE COMPUTED USING LIMIT.
2024-06-04:06:41:21,391 INFO     [main.py:378] Selected Tasks: ['gsm8k']
2024-06-04:06:41:21,394 INFO     [xevaluator.py:137] Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234
2024-06-04:06:41:21,394 INFO     [xevaluator.py:184] Initializing xhf model, with arguments: {'pretrained': 'meta-llama/Meta-Llama-3-8B-Instruct', 'griffin': False, 'check': False}
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]2024-06-04:06:41:26,563 WARNING  [main.py:303]  --limit SHOULD ONLY BE USED FOR TESTING.REAL METRICS SHOULD NOT BE COMPUTED USING LIMIT.
2024-06-04:06:41:26,565 INFO     [main.py:378] Selected Tasks: ['gsm8k']
2024-06-04:06:41:26,570 INFO     [xevaluator.py:137] Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234
2024-06-04:06:41:26,570 INFO     [xevaluator.py:184] Initializing xhf model, with arguments: {'pretrained': 'meta-llama/Meta-Llama-3-8B-Instruct', 'griffin': False, 'check': False}
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]2024-06-04:06:41:28,673 WARNING  [main.py:303]  --limit SHOULD ONLY BE USED FOR TESTING.REAL METRICS SHOULD NOT BE COMPUTED USING LIMIT.
2024-06-04:06:41:28,675 INFO     [main.py:378] Selected Tasks: ['gsm8k']
2024-06-04:06:41:28,681 INFO     [xevaluator.py:137] Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234
2024-06-04:06:41:28,681 INFO     [xevaluator.py:184] Initializing xhf model, with arguments: {'pretrained': 'meta-llama/Meta-Llama-3-8B-Instruct', 'griffin': False, 'check': False}
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]2024-06-04:06:41:30,826 WARNING  [main.py:303]  --limit SHOULD ONLY BE USED FOR TESTING.REAL METRICS SHOULD NOT BE COMPUTED USING LIMIT.
2024-06-04:06:41:30,828 INFO     [main.py:378] Selected Tasks: ['gsm8k']
2024-06-04:06:41:30,834 INFO     [xevaluator.py:137] Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234
2024-06-04:06:41:30,834 INFO     [xevaluator.py:184] Initializing xhf model, with arguments: {'pretrained': 'meta-llama/Meta-Llama-3-8B-Instruct', 'griffin': False, 'check': False}
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:  25%|██▌       | 1/4 [00:20<01:00, 20.29s/it]Loading checkpoint shards:  25%|██▌       | 1/4 [00:28<01:25, 28.36s/it]Loading checkpoint shards:  25%|██▌       | 1/4 [00:28<01:25, 28.66s/it]Loading checkpoint shards:  25%|██▌       | 1/4 [00:28<01:26, 28.96s/it]Loading checkpoint shards:  25%|██▌       | 1/4 [00:28<01:25, 28.63s/it]Loading checkpoint shards:  25%|██▌       | 1/4 [00:28<01:26, 28.86s/it]Loading checkpoint shards:  25%|██▌       | 1/4 [00:23<01:10, 23.59s/it]Loading checkpoint shards:  25%|██▌       | 1/4 [00:19<00:58, 19.43s/it]Loading checkpoint shards:  50%|█████     | 2/4 [00:55<00:55, 27.51s/it]Loading checkpoint shards:  50%|█████     | 2/4 [00:51<00:51, 25.86s/it]Loading checkpoint shards:  50%|█████     | 2/4 [00:56<00:56, 28.12s/it]Loading checkpoint shards:  50%|█████     | 2/4 [00:55<00:55, 27.93s/it]Loading checkpoint shards:  50%|█████     | 2/4 [00:56<00:55, 27.99s/it]Loading checkpoint shards:  50%|█████     | 2/4 [00:56<00:56, 28.07s/it]Loading checkpoint shards:  50%|█████     | 2/4 [00:48<00:50, 25.11s/it]Loading checkpoint shards:  50%|█████     | 2/4 [00:47<00:48, 24.31s/it]Loading checkpoint shards:  75%|███████▌  | 3/4 [01:22<00:27, 27.31s/it]Loading checkpoint shards:  75%|███████▌  | 3/4 [01:23<00:27, 27.60s/it]Loading checkpoint shards:  75%|███████▌  | 3/4 [01:13<00:25, 25.40s/it]Loading checkpoint shards:  75%|███████▌  | 3/4 [01:23<00:27, 27.54s/it]Loading checkpoint shards:  75%|███████▌  | 3/4 [01:23<00:27, 27.59s/it]Loading checkpoint shards:  75%|███████▌  | 3/4 [01:23<00:27, 27.67s/it]Loading checkpoint shards:  75%|███████▌  | 3/4 [01:18<00:26, 26.49s/it]Loading checkpoint shards:  75%|███████▌  | 3/4 [01:16<00:26, 26.18s/it]Loading checkpoint shards: 100%|██████████| 4/4 [01:18<00:00, 17.28s/it]Loading checkpoint shards: 100%|██████████| 4/4 [01:18<00:00, 19.67s/it]
Loading checkpoint shards: 100%|██████████| 4/4 [01:28<00:00, 18.74s/it]Loading checkpoint shards: 100%|██████████| 4/4 [01:28<00:00, 22.17s/it]
Loading checkpoint shards: 100%|██████████| 4/4 [01:28<00:00, 18.70s/it]Loading checkpoint shards: 100%|██████████| 4/4 [01:28<00:00, 22.05s/it]
Loading checkpoint shards: 100%|██████████| 4/4 [01:28<00:00, 18.71s/it]Loading checkpoint shards: 100%|██████████| 4/4 [01:28<00:00, 22.10s/it]
Loading checkpoint shards: 100%|██████████| 4/4 [01:28<00:00, 18.75s/it]Loading checkpoint shards: 100%|██████████| 4/4 [01:28<00:00, 22.15s/it]
Loading checkpoint shards: 100%|██████████| 4/4 [01:28<00:00, 18.91s/it]Loading checkpoint shards: 100%|██████████| 4/4 [01:28<00:00, 22.12s/it]
Loading checkpoint shards: 100%|██████████| 4/4 [01:21<00:00, 17.73s/it]Loading checkpoint shards: 100%|██████████| 4/4 [01:21<00:00, 20.25s/it]
Loading checkpoint shards: 100%|██████████| 4/4 [01:23<00:00, 18.16s/it]Loading checkpoint shards: 100%|██████████| 4/4 [01:23<00:00, 20.92s/it]
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
2024-06-04:06:42:51,803 INFO     [xhuggingface.py:314] Using 8 devices with data parallelism
Using the latest cached version of the dataset since gsm8k couldn't be found on the Hugging Face Hub
2024-06-04:06:42:51,871 WARNING  [load.py:1631] Using the latest cached version of the dataset since gsm8k couldn't be found on the Hugging Face Hub
Using the latest cached version of the dataset since gsm8k couldn't be found on the Hugging Face Hub
2024-06-04:06:42:51,871 WARNING  [load.py:1631] Using the latest cached version of the dataset since gsm8k couldn't be found on the Hugging Face Hub
Found the latest cached dataset configuration 'main' at /private/home/beidic/.cache/huggingface/datasets/gsm8k/main/0.0.0/e53f048856ff4f594e959d75785d2c2d37b678ee (last modified on Thu May 16 07:01:08 2024).
2024-06-04:06:42:51,874 WARNING  [cache.py:95] Found the latest cached dataset configuration 'main' at /private/home/beidic/.cache/huggingface/datasets/gsm8k/main/0.0.0/e53f048856ff4f594e959d75785d2c2d37b678ee (last modified on Thu May 16 07:01:08 2024).
Found the latest cached dataset configuration 'main' at /private/home/beidic/.cache/huggingface/datasets/gsm8k/main/0.0.0/e53f048856ff4f594e959d75785d2c2d37b678ee (last modified on Thu May 16 07:01:08 2024).
2024-06-04:06:42:51,874 WARNING  [cache.py:95] Found the latest cached dataset configuration 'main' at /private/home/beidic/.cache/huggingface/datasets/gsm8k/main/0.0.0/e53f048856ff4f594e959d75785d2c2d37b678ee (last modified on Thu May 16 07:01:08 2024).
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
2024-06-04:06:42:52,110 INFO     [task.py:395] Building contexts for gsm8k on rank 0...
Using the latest cached version of the dataset since gsm8k couldn't be found on the Hugging Face Hub
2024-06-04:06:42:52,113 WARNING  [load.py:1631] Using the latest cached version of the dataset since gsm8k couldn't be found on the Hugging Face Hub
Found the latest cached dataset configuration 'main' at /private/home/beidic/.cache/huggingface/datasets/gsm8k/main/0.0.0/e53f048856ff4f594e959d75785d2c2d37b678ee (last modified on Thu May 16 07:01:08 2024).
2024-06-04:06:42:52,115 WARNING  [cache.py:95] Found the latest cached dataset configuration 'main' at /private/home/beidic/.cache/huggingface/datasets/gsm8k/main/0.0.0/e53f048856ff4f594e959d75785d2c2d37b678ee (last modified on Thu May 16 07:01:08 2024).
  0%|          | 0/83 [00:00<?, ?it/s]Using the latest cached version of the dataset since gsm8k couldn't be found on the Hugging Face Hub
2024-06-04:06:42:52,139 WARNING  [load.py:1631] Using the latest cached version of the dataset since gsm8k couldn't be found on the Hugging Face Hub
Found the latest cached dataset configuration 'main' at /private/home/beidic/.cache/huggingface/datasets/gsm8k/main/0.0.0/e53f048856ff4f594e959d75785d2c2d37b678ee (last modified on Thu May 16 07:01:08 2024).
2024-06-04:06:42:52,141 WARNING  [cache.py:95] Found the latest cached dataset configuration 'main' at /private/home/beidic/.cache/huggingface/datasets/gsm8k/main/0.0.0/e53f048856ff4f594e959d75785d2c2d37b678ee (last modified on Thu May 16 07:01:08 2024).
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
Using the latest cached version of the dataset since gsm8k couldn't be found on the Hugging Face Hub
2024-06-04:06:42:52,164 WARNING  [load.py:1631] Using the latest cached version of the dataset since gsm8k couldn't be found on the Hugging Face Hub
Found the latest cached dataset configuration 'main' at /private/home/beidic/.cache/huggingface/datasets/gsm8k/main/0.0.0/e53f048856ff4f594e959d75785d2c2d37b678ee (last modified on Thu May 16 07:01:08 2024).
2024-06-04:06:42:52,166 WARNING  [cache.py:95] Found the latest cached dataset configuration 'main' at /private/home/beidic/.cache/huggingface/datasets/gsm8k/main/0.0.0/e53f048856ff4f594e959d75785d2c2d37b678ee (last modified on Thu May 16 07:01:08 2024).
Using the latest cached version of the dataset since gsm8k couldn't be found on the Hugging Face Hub
2024-06-04:06:42:52,187 WARNING  [load.py:1631] Using the latest cached version of the dataset since gsm8k couldn't be found on the Hugging Face Hub
Found the latest cached dataset configuration 'main' at /private/home/beidic/.cache/huggingface/datasets/gsm8k/main/0.0.0/e53f048856ff4f594e959d75785d2c2d37b678ee (last modified on Thu May 16 07:01:08 2024).
2024-06-04:06:42:52,189 WARNING  [cache.py:95] Found the latest cached dataset configuration 'main' at /private/home/beidic/.cache/huggingface/datasets/gsm8k/main/0.0.0/e53f048856ff4f594e959d75785d2c2d37b678ee (last modified on Thu May 16 07:01:08 2024).
 22%|██▏       | 18/83 [00:00<00:00, 168.96it/s]Using the latest cached version of the dataset since gsm8k couldn't be found on the Hugging Face Hub
2024-06-04:06:42:52,248 WARNING  [load.py:1631] Using the latest cached version of the dataset since gsm8k couldn't be found on the Hugging Face Hub
Found the latest cached dataset configuration 'main' at /private/home/beidic/.cache/huggingface/datasets/gsm8k/main/0.0.0/e53f048856ff4f594e959d75785d2c2d37b678ee (last modified on Thu May 16 07:01:08 2024).
2024-06-04:06:42:52,250 WARNING  [cache.py:95] Found the latest cached dataset configuration 'main' at /private/home/beidic/.cache/huggingface/datasets/gsm8k/main/0.0.0/e53f048856ff4f594e959d75785d2c2d37b678ee (last modified on Thu May 16 07:01:08 2024).
2024-06-04:06:42:52,285 INFO     [task.py:395] Building contexts for gsm8k on rank 3...
  0%|          | 0/83 [00:00<?, ?it/s]2024-06-04:06:42:52,305 INFO     [task.py:395] Building contexts for gsm8k on rank 7...
  0%|          | 0/82 [00:00<?, ?it/s] 42%|████▏     | 35/83 [00:00<00:00, 142.31it/s] 24%|██▍       | 20/83 [00:00<00:00, 197.44it/s] 16%|█▌        | 13/82 [00:00<00:00, 128.15it/s]2024-06-04:06:42:52,470 INFO     [task.py:395] Building contexts for gsm8k on rank 5...
 60%|██████    | 50/83 [00:00<00:00, 134.16it/s]  0%|          | 0/82 [00:00<?, ?it/s]2024-06-04:06:42:52,497 INFO     [task.py:395] Building contexts for gsm8k on rank 6...
 48%|████▊     | 40/83 [00:00<00:00, 196.85it/s]  0%|          | 0/82 [00:00<?, ?it/s] 32%|███▏      | 26/82 [00:00<00:00, 128.80it/s]2024-06-04:06:42:52,553 INFO     [task.py:395] Building contexts for gsm8k on rank 1...
  0%|          | 0/83 [00:00<?, ?it/s] 77%|███████▋  | 64/83 [00:00<00:00, 133.62it/s] 16%|█▌        | 13/82 [00:00<00:00, 125.30it/s] 72%|███████▏  | 60/83 [00:00<00:00, 197.34it/s]2024-06-04:06:42:52,627 INFO     [task.py:395] Building contexts for gsm8k on rank 2...
 17%|█▋        | 14/82 [00:00<00:00, 130.52it/s] 48%|████▊     | 39/82 [00:00<00:00, 127.61it/s]  0%|          | 0/83 [00:00<?, ?it/s] 17%|█▋        | 14/83 [00:00<00:00, 130.17it/s] 94%|█████████▍| 78/83 [00:00<00:00, 133.32it/s] 96%|█████████▋| 80/83 [00:00<00:00, 197.75it/s] 33%|███▎      | 27/82 [00:00<00:00, 129.22it/s]100%|██████████| 83/83 [00:00<00:00, 197.61it/s]
100%|██████████| 83/83 [00:00<00:00, 136.14it/s]
 34%|███▍      | 28/82 [00:00<00:00, 131.02it/s] 63%|██████▎   | 52/82 [00:00<00:00, 127.49it/s] 16%|█▌        | 13/83 [00:00<00:00, 120.39it/s] 34%|███▎      | 28/83 [00:00<00:00, 130.98it/s] 52%|█████▏    | 43/82 [00:00<00:00, 142.85it/s] 79%|███████▉  | 65/82 [00:00<00:00, 125.15it/s] 51%|█████     | 42/82 [00:00<00:00, 130.49it/s] 31%|███▏      | 26/83 [00:00<00:00, 118.43it/s] 51%|█████     | 42/83 [00:00<00:00, 129.22it/s] 71%|███████   | 58/82 [00:00<00:00, 137.34it/s] 95%|█████████▌| 78/82 [00:00<00:00, 121.51it/s] 68%|██████▊   | 56/82 [00:00<00:00, 126.45it/s] 46%|████▌     | 38/83 [00:00<00:00, 117.85it/s]100%|██████████| 82/82 [00:00<00:00, 124.16it/s]
 66%|██████▋   | 55/83 [00:00<00:00, 127.60it/s] 88%|████████▊ | 72/82 [00:00<00:00, 133.66it/s] 84%|████████▍ | 69/82 [00:00<00:00, 126.03it/s] 60%|██████    | 50/83 [00:00<00:00, 114.48it/s] 82%|████████▏ | 68/83 [00:00<00:00, 127.59it/s]100%|██████████| 82/82 [00:00<00:00, 131.87it/s]
100%|██████████| 82/82 [00:00<00:00, 126.60it/s]100%|██████████| 82/82 [00:00<00:00, 127.45it/s]
 75%|███████▍  | 62/83 [00:00<00:00, 115.29it/s] 98%|█████████▊| 81/83 [00:00<00:00, 126.37it/s]100%|██████████| 83/83 [00:00<00:00, 126.86it/s]
 89%|████████▉ | 74/83 [00:00<00:00, 115.56it/s]Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
100%|██████████| 83/83 [00:00<00:00, 116.40it/s]
Using the latest cached version of the dataset since gsm8k couldn't be found on the Hugging Face Hub
2024-06-04:06:42:53,471 WARNING  [load.py:1631] Using the latest cached version of the dataset since gsm8k couldn't be found on the Hugging Face Hub
Found the latest cached dataset configuration 'main' at /private/home/beidic/.cache/huggingface/datasets/gsm8k/main/0.0.0/e53f048856ff4f594e959d75785d2c2d37b678ee (last modified on Thu May 16 07:01:08 2024).
2024-06-04:06:42:53,476 WARNING  [cache.py:95] Found the latest cached dataset configuration 'main' at /private/home/beidic/.cache/huggingface/datasets/gsm8k/main/0.0.0/e53f048856ff4f594e959d75785d2c2d37b678ee (last modified on Thu May 16 07:01:08 2024).
2024-06-04:06:42:54,598 INFO     [task.py:395] Building contexts for gsm8k on rank 4...
  0%|          | 0/82 [00:00<?, ?it/s]  6%|▌         | 5/82 [00:00<00:01, 42.15it/s] 12%|█▏        | 10/82 [00:00<00:01, 42.76it/s] 18%|█▊        | 15/82 [00:00<00:01, 42.94it/s] 24%|██▍       | 20/82 [00:00<00:01, 42.87it/s] 30%|███       | 25/82 [00:00<00:01, 42.37it/s] 37%|███▋      | 30/82 [00:00<00:01, 42.64it/s] 43%|████▎     | 35/82 [00:00<00:01, 42.73it/s] 49%|████▉     | 40/82 [00:00<00:00, 42.80it/s] 55%|█████▍    | 45/82 [00:01<00:00, 42.68it/s] 61%|██████    | 50/82 [00:01<00:00, 42.83it/s] 67%|██████▋   | 55/82 [00:01<00:00, 42.86it/s] 73%|███████▎  | 60/82 [00:01<00:00, 42.97it/s] 79%|███████▉  | 65/82 [00:01<00:00, 42.33it/s] 85%|████████▌ | 70/82 [00:01<00:00, 42.41it/s] 91%|█████████▏| 75/82 [00:01<00:00, 42.59it/s] 98%|█████████▊| 80/82 [00:01<00:00, 42.71it/s]100%|██████████| 82/82 [00:01<00:00, 42.69it/s]
2024-06-04:06:43:07,167 INFO     [xevaluator.py:395] Running generate_until requests
2024-06-04:06:43:07,167 INFO     [xevaluator.py:395] Running generate_until requests
2024-06-04:06:43:07,167 INFO     [xevaluator.py:395] Running generate_until requests
2024-06-04:06:43:07,167 INFO     [xevaluator.py:395] Running generate_until requests
2024-06-04:06:43:07,167 INFO     [xevaluator.py:395] Running generate_until requests
2024-06-04:06:43:07,168 INFO     [xevaluator.py:395] Running generate_until requests
Running generate_until requests:   0%|          | 0/83 [00:00<?, ?it/s]2024-06-04:06:43:07,169 INFO     [xevaluator.py:395] Running generate_until requests
2024-06-04:06:43:07,182 INFO     [xevaluator.py:395] Running generate_until requests
Running generate_until requests:   1%|          | 1/83 [00:06<09:33,  7.00s/it]Running generate_until requests:   2%|▏         | 2/83 [00:14<09:37,  7.14s/it]Running generate_until requests:   4%|▎         | 3/83 [00:19<08:05,  6.07s/it]Running generate_until requests:   5%|▍         | 4/83 [00:22<06:37,  5.03s/it]Running generate_until requests:   6%|▌         | 5/83 [00:26<06:13,  4.79s/it]Running generate_until requests:   7%|▋         | 6/83 [00:30<05:39,  4.41s/it]Running generate_until requests:   8%|▊         | 7/83 [00:36<06:21,  5.02s/it]Running generate_until requests:  10%|▉         | 8/83 [00:41<06:00,  4.81s/it]Running generate_until requests:  11%|█         | 9/83 [00:46<06:13,  5.05s/it]Running generate_until requests:  12%|█▏        | 10/83 [00:50<05:36,  4.61s/it]Running generate_until requests:  13%|█▎        | 11/83 [00:54<05:24,  4.51s/it]Running generate_until requests:  14%|█▍        | 12/83 [01:00<05:49,  4.92s/it]Running generate_until requests:  16%|█▌        | 13/83 [01:04<05:22,  4.60s/it]Running generate_until requests:  17%|█▋        | 14/83 [01:08<05:09,  4.48s/it]Running generate_until requests:  18%|█▊        | 15/83 [01:15<06:00,  5.31s/it]Running generate_until requests:  19%|█▉        | 16/83 [01:22<06:14,  5.60s/it]Running generate_until requests:  20%|██        | 17/83 [01:26<05:54,  5.38s/it]Running generate_until requests:  22%|██▏       | 18/83 [01:31<05:31,  5.10s/it]Running generate_until requests:  23%|██▎       | 19/83 [01:35<05:10,  4.86s/it]Running generate_until requests:  24%|██▍       | 20/83 [01:42<05:36,  5.34s/it]Running generate_until requests:  25%|██▌       | 21/83 [01:45<05:02,  4.89s/it]Running generate_until requests:  27%|██▋       | 22/83 [01:49<04:41,  4.62s/it]Running generate_until requests:  28%|██▊       | 23/83 [01:54<04:33,  4.55s/it]Running generate_until requests:  29%|██▉       | 24/83 [01:58<04:18,  4.38s/it]Running generate_until requests:  30%|███       | 25/83 [02:03<04:27,  4.61s/it]Running generate_until requests:  31%|███▏      | 26/83 [02:07<04:12,  4.44s/it]Running generate_until requests:  33%|███▎      | 27/83 [02:11<04:08,  4.43s/it]Running generate_until requests:  34%|███▎      | 28/83 [02:15<03:53,  4.24s/it]Running generate_until requests:  35%|███▍      | 29/83 [02:20<03:54,  4.33s/it]Running generate_until requests:  36%|███▌      | 30/83 [02:25<04:00,  4.53s/it]Running generate_until requests:  37%|███▋      | 31/83 [02:29<03:44,  4.32s/it]Running generate_until requests:  39%|███▊      | 32/83 [02:33<03:47,  4.47s/it]Running generate_until requests:  40%|███▉      | 33/83 [02:36<03:21,  4.04s/it]Running generate_until requests:  41%|████      | 34/83 [02:41<03:30,  4.30s/it]Running generate_until requests:  42%|████▏     | 35/83 [02:45<03:18,  4.13s/it]Running generate_until requests:  43%|████▎     | 36/83 [02:49<03:13,  4.12s/it]Running generate_until requests:  45%|████▍     | 37/83 [02:53<03:09,  4.11s/it]Running generate_until requests:  46%|████▌     | 38/83 [02:59<03:21,  4.48s/it]Running generate_until requests:  47%|████▋     | 39/83 [03:02<03:03,  4.17s/it]Running generate_until requests:  48%|████▊     | 40/83 [03:08<03:17,  4.58s/it]Running generate_until requests:  49%|████▉     | 41/83 [03:11<02:54,  4.16s/it]Running generate_until requests:  51%|█████     | 42/83 [03:15<02:48,  4.12s/it]Running generate_until requests:  52%|█████▏    | 43/83 [03:19<02:50,  4.27s/it]Running generate_until requests:  53%|█████▎    | 44/83 [03:23<02:34,  3.96s/it]Running generate_until requests:  54%|█████▍    | 45/83 [03:27<02:29,  3.93s/it]Running generate_until requests:  55%|█████▌    | 46/83 [03:30<02:24,  3.91s/it]Running generate_until requests:  57%|█████▋    | 47/83 [03:34<02:12,  3.69s/it]Running generate_until requests:  58%|█████▊    | 48/83 [03:38<02:17,  3.92s/it]Running generate_until requests:  59%|█████▉    | 49/83 [03:41<02:01,  3.58s/it]Running generate_until requests:  60%|██████    | 50/83 [03:46<02:09,  3.93s/it]Running generate_until requests:  61%|██████▏   | 51/83 [03:50<02:06,  3.96s/it]Running generate_until requests:  63%|██████▎   | 52/83 [03:52<01:52,  3.64s/it]Running generate_until requests:  64%|██████▍   | 53/83 [03:57<01:54,  3.82s/it]Running generate_until requests:  65%|██████▌   | 54/83 [04:00<01:44,  3.61s/it]Running generate_until requests:  66%|██████▋   | 55/83 [04:03<01:38,  3.53s/it]Running generate_until requests:  67%|██████▋   | 56/83 [04:11<02:08,  4.75s/it]Running generate_until requests:  69%|██████▊   | 57/83 [04:16<02:09,  4.98s/it]Running generate_until requests:  70%|██████▉   | 58/83 [04:20<01:58,  4.73s/it]Running generate_until requests:  71%|███████   | 59/83 [04:24<01:43,  4.31s/it]Running generate_until requests:  72%|███████▏  | 60/83 [04:27<01:31,  3.99s/it]Running generate_until requests:  73%|███████▎  | 61/83 [04:32<01:31,  4.15s/it]Running generate_until requests:  75%|███████▍  | 62/83 [04:35<01:19,  3.80s/it]Running generate_until requests:  76%|███████▌  | 63/83 [04:38<01:13,  3.69s/it]Running generate_until requests:  77%|███████▋  | 64/83 [04:43<01:17,  4.06s/it]Running generate_until requests:  78%|███████▊  | 65/83 [04:46<01:09,  3.88s/it]Running generate_until requests:  80%|███████▉  | 66/83 [04:49<01:01,  3.59s/it]Running generate_until requests:  81%|████████  | 67/83 [04:52<00:54,  3.39s/it]Running generate_until requests:  82%|████████▏ | 68/83 [04:55<00:50,  3.36s/it]Running generate_until requests:  83%|████████▎ | 69/83 [05:02<00:58,  4.20s/it]Running generate_until requests:  84%|████████▍ | 70/83 [05:06<00:56,  4.31s/it]Running generate_until requests:  86%|████████▌ | 71/83 [05:09<00:45,  3.82s/it]Running generate_until requests:  87%|████████▋ | 72/83 [05:12<00:38,  3.50s/it]Running generate_until requests:  88%|████████▊ | 73/83 [05:15<00:34,  3.48s/it]Running generate_until requests:  89%|████████▉ | 74/83 [05:18<00:30,  3.44s/it]Running generate_until requests:  90%|█████████ | 75/83 [05:24<00:31,  3.96s/it]Running generate_until requests:  92%|█████████▏| 76/83 [05:28<00:27,  3.96s/it]Running generate_until requests:  93%|█████████▎| 77/83 [05:31<00:22,  3.69s/it]Running generate_until requests:  94%|█████████▍| 78/83 [05:34<00:17,  3.58s/it]Running generate_until requests:  95%|█████████▌| 79/83 [05:38<00:14,  3.71s/it]Running generate_until requests:  96%|█████████▋| 80/83 [05:41<00:11,  3.67s/it]Running generate_until requests:  98%|█████████▊| 81/83 [05:46<00:07,  3.84s/it]Running generate_until requests:  99%|█████████▉| 82/83 [05:49<00:03,  3.66s/it]Running generate_until requests: 100%|██████████| 83/83 [05:52<00:00,  3.49s/it]Running generate_until requests: 100%|██████████| 83/83 [05:52<00:00,  4.25s/it]
