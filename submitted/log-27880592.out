Updating 6b9b553..d9656db
Fast-forward
 measuring_human_eval/eval_plain.py | 7 ++++---
 1 file changed, 4 insertions(+), 3 deletions(-)
Already up to date.
Looking in indexes: https://pypi.org/simple, http://webservice
Requirement already satisfied: termcolor in /private/home/beidic/.conda/envs/griffin/lib/python3.12/site-packages (2.4.0)
Looking in indexes: https://pypi.org/simple, http://webservice
Requirement already satisfied: wandb in /private/home/beidic/.conda/envs/griffin/lib/python3.12/site-packages (0.16.3)
Requirement already satisfied: Click!=8.0.0,>=7.1 in /private/home/beidic/.conda/envs/griffin/lib/python3.12/site-packages (from wandb) (8.1.7)
Requirement already satisfied: GitPython!=3.1.29,>=1.0.0 in /private/home/beidic/.conda/envs/griffin/lib/python3.12/site-packages (from wandb) (3.1.42)
Requirement already satisfied: requests<3,>=2.0.0 in /private/home/beidic/.conda/envs/griffin/lib/python3.12/site-packages (from wandb) (2.31.0)
Requirement already satisfied: psutil>=5.0.0 in /private/home/beidic/.conda/envs/griffin/lib/python3.12/site-packages (from wandb) (5.9.8)
Requirement already satisfied: sentry-sdk>=1.0.0 in /private/home/beidic/.conda/envs/griffin/lib/python3.12/site-packages (from wandb) (1.40.6)
Requirement already satisfied: docker-pycreds>=0.4.0 in /private/home/beidic/.conda/envs/griffin/lib/python3.12/site-packages (from wandb) (0.4.0)
Requirement already satisfied: PyYAML in /private/home/beidic/.conda/envs/griffin/lib/python3.12/site-packages (from wandb) (6.0.1)
Requirement already satisfied: setproctitle in /private/home/beidic/.conda/envs/griffin/lib/python3.12/site-packages (from wandb) (1.3.3)
Requirement already satisfied: setuptools in /private/home/beidic/.conda/envs/griffin/lib/python3.12/site-packages (from wandb) (68.2.2)
Requirement already satisfied: appdirs>=1.4.3 in /private/home/beidic/.conda/envs/griffin/lib/python3.12/site-packages (from wandb) (1.4.4)
Requirement already satisfied: protobuf!=4.21.0,<5,>=3.19.0 in /private/home/beidic/.conda/envs/griffin/lib/python3.12/site-packages (from wandb) (4.25.2)
Requirement already satisfied: six>=1.4.0 in /private/home/beidic/.conda/envs/griffin/lib/python3.12/site-packages (from docker-pycreds>=0.4.0->wandb) (1.16.0)
Requirement already satisfied: gitdb<5,>=4.0.1 in /private/home/beidic/.conda/envs/griffin/lib/python3.12/site-packages (from GitPython!=3.1.29,>=1.0.0->wandb) (4.0.11)
Requirement already satisfied: charset-normalizer<4,>=2 in /private/home/beidic/.conda/envs/griffin/lib/python3.12/site-packages (from requests<3,>=2.0.0->wandb) (2.0.4)
Requirement already satisfied: idna<4,>=2.5 in /private/home/beidic/.conda/envs/griffin/lib/python3.12/site-packages (from requests<3,>=2.0.0->wandb) (3.4)
Requirement already satisfied: urllib3<3,>=1.21.1 in /private/home/beidic/.conda/envs/griffin/lib/python3.12/site-packages (from requests<3,>=2.0.0->wandb) (1.26.18)
Requirement already satisfied: certifi>=2017.4.17 in /private/home/beidic/.conda/envs/griffin/lib/python3.12/site-packages (from requests<3,>=2.0.0->wandb) (2024.2.2)
Requirement already satisfied: smmap<6,>=3.0.1 in /private/home/beidic/.conda/envs/griffin/lib/python3.12/site-packages (from gitdb<5,>=4.0.1->GitPython!=3.1.29,>=1.0.0->wandb) (5.0.1)
Looking in indexes: https://pypi.org/simple, http://webservice
Requirement already satisfied: huggingface_hub[cli] in /private/home/beidic/.conda/envs/griffin/lib/python3.12/site-packages (0.23.0)
Requirement already satisfied: filelock in /private/home/beidic/.conda/envs/griffin/lib/python3.12/site-packages (from huggingface_hub[cli]) (3.13.1)
Requirement already satisfied: fsspec>=2023.5.0 in /private/home/beidic/.conda/envs/griffin/lib/python3.12/site-packages (from huggingface_hub[cli]) (2023.6.0)
Requirement already satisfied: packaging>=20.9 in /private/home/beidic/.conda/envs/griffin/lib/python3.12/site-packages (from huggingface_hub[cli]) (23.2)
Requirement already satisfied: pyyaml>=5.1 in /private/home/beidic/.conda/envs/griffin/lib/python3.12/site-packages (from huggingface_hub[cli]) (6.0.1)
Requirement already satisfied: requests in /private/home/beidic/.conda/envs/griffin/lib/python3.12/site-packages (from huggingface_hub[cli]) (2.31.0)
Requirement already satisfied: tqdm>=4.42.1 in /private/home/beidic/.conda/envs/griffin/lib/python3.12/site-packages (from huggingface_hub[cli]) (4.66.1)
Requirement already satisfied: typing-extensions>=3.7.4.3 in /private/home/beidic/.conda/envs/griffin/lib/python3.12/site-packages (from huggingface_hub[cli]) (4.9.0)
Requirement already satisfied: InquirerPy==0.3.4 in /private/home/beidic/.conda/envs/griffin/lib/python3.12/site-packages (from huggingface_hub[cli]) (0.3.4)
Requirement already satisfied: pfzy<0.4.0,>=0.3.1 in /private/home/beidic/.conda/envs/griffin/lib/python3.12/site-packages (from InquirerPy==0.3.4->huggingface_hub[cli]) (0.3.4)
Requirement already satisfied: prompt-toolkit<4.0.0,>=3.0.1 in /private/home/beidic/.conda/envs/griffin/lib/python3.12/site-packages (from InquirerPy==0.3.4->huggingface_hub[cli]) (3.0.43)
Requirement already satisfied: charset-normalizer<4,>=2 in /private/home/beidic/.conda/envs/griffin/lib/python3.12/site-packages (from requests->huggingface_hub[cli]) (2.0.4)
Requirement already satisfied: idna<4,>=2.5 in /private/home/beidic/.conda/envs/griffin/lib/python3.12/site-packages (from requests->huggingface_hub[cli]) (3.4)
Requirement already satisfied: urllib3<3,>=1.21.1 in /private/home/beidic/.conda/envs/griffin/lib/python3.12/site-packages (from requests->huggingface_hub[cli]) (1.26.18)
Requirement already satisfied: certifi>=2017.4.17 in /private/home/beidic/.conda/envs/griffin/lib/python3.12/site-packages (from requests->huggingface_hub[cli]) (2024.2.2)
Requirement already satisfied: wcwidth in /private/home/beidic/.conda/envs/griffin/lib/python3.12/site-packages (from prompt-toolkit<4.0.0,>=3.0.1->InquirerPy==0.3.4->huggingface_hub[cli]) (0.2.13)
Looking in indexes: https://pypi.org/simple, http://webservice
Requirement already satisfied: matplotlib in /private/home/beidic/.conda/envs/griffin/lib/python3.12/site-packages (3.8.0)
Requirement already satisfied: contourpy>=1.0.1 in /private/home/beidic/.conda/envs/griffin/lib/python3.12/site-packages (from matplotlib) (1.2.0)
Requirement already satisfied: cycler>=0.10 in /private/home/beidic/.conda/envs/griffin/lib/python3.12/site-packages (from matplotlib) (0.11.0)
Requirement already satisfied: fonttools>=4.22.0 in /private/home/beidic/.conda/envs/griffin/lib/python3.12/site-packages (from matplotlib) (4.25.0)
Requirement already satisfied: kiwisolver>=1.0.1 in /private/home/beidic/.conda/envs/griffin/lib/python3.12/site-packages (from matplotlib) (1.4.4)
Requirement already satisfied: numpy<2,>=1.21 in /private/home/beidic/.conda/envs/griffin/lib/python3.12/site-packages (from matplotlib) (1.26.3)
Requirement already satisfied: packaging>=20.0 in /private/home/beidic/.conda/envs/griffin/lib/python3.12/site-packages (from matplotlib) (23.2)
Requirement already satisfied: pillow>=6.2.0 in /private/home/beidic/.conda/envs/griffin/lib/python3.12/site-packages (from matplotlib) (10.0.1)
Requirement already satisfied: pyparsing>=2.3.1 in /private/home/beidic/.conda/envs/griffin/lib/python3.12/site-packages (from matplotlib) (3.0.9)
Requirement already satisfied: python-dateutil>=2.7 in /private/home/beidic/.conda/envs/griffin/lib/python3.12/site-packages (from matplotlib) (2.8.2)
Requirement already satisfied: six>=1.5 in /private/home/beidic/.conda/envs/griffin/lib/python3.12/site-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)
Looking in indexes: https://pypi.org/simple, http://webservice
Requirement already satisfied: langdetect in /private/home/beidic/.conda/envs/griffin/lib/python3.12/site-packages (1.0.9)
Requirement already satisfied: six in /private/home/beidic/.conda/envs/griffin/lib/python3.12/site-packages (from langdetect) (1.16.0)
Looking in indexes: https://pypi.org/simple, http://webservice
Requirement already satisfied: immutabledict in /private/home/beidic/.conda/envs/griffin/lib/python3.12/site-packages (4.2.0)
Looking in indexes: https://pypi.org/simple, http://webservice
Requirement already satisfied: sentencepiece in /private/home/beidic/.conda/envs/griffin/lib/python3.12/site-packages (0.1.99)
/private/home/beidic/.conda/envs/griffin/bin/python
/private/home/beidic/.conda/envs/griffin/bin/python
[1m[31mERROR! `huggingface-cli login` uses an outdated login mechanism that is not compatible with the Hugging Face Hub backend anymore. Please use `huggingface-cli login instead.[0m
The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-cli` if you want to set the git credential as well.
Token is valid (permission: read).
Your token has been saved to /private/home/beidic/.cache/huggingface/token
Login successful
Namespace(model='xhf', tasks='gsm8k,triviaqa,ifeval', model_args='pretrained=meta-llama/Llama-2-7b-chat-hf,griffin=True,check=False,griffinnotcats=False', num_fewshot=None, batch_size='1', max_batch_size=None, device=None, output_path=None, limit=None, topp=1.1, topk=64, spr=0.25, sink=8, local=256, use_cache=None, cache_requests=None, check_integrity=False, write_out=False, log_samples=False, show_config=False, include_path=None, gen_kwargs=None, verbosity='INFO', wandb_args='', predict_only=False, seed=[0, 1234, 1234], trust_remote_code=False)Namespace(model='xhf', tasks='gsm8k,triviaqa,ifeval', model_args='pretrained=meta-llama/Llama-2-7b-chat-hf,griffin=True,check=False,griffinnotcats=False', num_fewshot=None, batch_size='1', max_batch_size=None, device=None, output_path=None, limit=None, topp=1.1, topk=64, spr=0.25, sink=8, local=256, use_cache=None, cache_requests=None, check_integrity=False, write_out=False, log_samples=False, show_config=False, include_path=None, gen_kwargs=None, verbosity='INFO', wandb_args='', predict_only=False, seed=[0, 1234, 1234], trust_remote_code=False)

the kernel size is 8
the kernel size is 8
Namespace(model='xhf', tasks='gsm8k,triviaqa,ifeval', model_args='pretrained=meta-llama/Llama-2-7b-chat-hf,griffin=True,check=False,griffinnotcats=False', num_fewshot=None, batch_size='1', max_batch_size=None, device=None, output_path=None, limit=None, topp=1.1, topk=64, spr=0.25, sink=8, local=256, use_cache=None, cache_requests=None, check_integrity=False, write_out=False, log_samples=False, show_config=False, include_path=None, gen_kwargs=None, verbosity='INFO', wandb_args='', predict_only=False, seed=[0, 1234, 1234], trust_remote_code=False)
Namespace(model='xhf', tasks='gsm8k,triviaqa,ifeval', model_args='pretrained=meta-llama/Llama-2-7b-chat-hf,griffin=True,check=False,griffinnotcats=False', num_fewshot=None, batch_size='1', max_batch_size=None, device=None, output_path=None, limit=None, topp=1.1, topk=64, spr=0.25, sink=8, local=256, use_cache=None, cache_requests=None, check_integrity=False, write_out=False, log_samples=False, show_config=False, include_path=None, gen_kwargs=None, verbosity='INFO', wandb_args='', predict_only=False, seed=[0, 1234, 1234], trust_remote_code=False)
Namespace(model='xhf', tasks='gsm8k,triviaqa,ifeval', model_args='pretrained=meta-llama/Llama-2-7b-chat-hf,griffin=True,check=False,griffinnotcats=False', num_fewshot=None, batch_size='1', max_batch_size=None, device=None, output_path=None, limit=None, topp=1.1, topk=64, spr=0.25, sink=8, local=256, use_cache=None, cache_requests=None, check_integrity=False, write_out=False, log_samples=False, show_config=False, include_path=None, gen_kwargs=None, verbosity='INFO', wandb_args='', predict_only=False, seed=[0, 1234, 1234], trust_remote_code=False)
Namespace(model='xhf', tasks='gsm8k,triviaqa,ifeval', model_args='pretrained=meta-llama/Llama-2-7b-chat-hf,griffin=True,check=False,griffinnotcats=False', num_fewshot=None, batch_size='1', max_batch_size=None, device=None, output_path=None, limit=None, topp=1.1, topk=64, spr=0.25, sink=8, local=256, use_cache=None, cache_requests=None, check_integrity=False, write_out=False, log_samples=False, show_config=False, include_path=None, gen_kwargs=None, verbosity='INFO', wandb_args='', predict_only=False, seed=[0, 1234, 1234], trust_remote_code=False)
Namespace(model='xhf', tasks='gsm8k,triviaqa,ifeval', model_args='pretrained=meta-llama/Llama-2-7b-chat-hf,griffin=True,check=False,griffinnotcats=False', num_fewshot=None, batch_size='1', max_batch_size=None, device=None, output_path=None, limit=None, topp=1.1, topk=64, spr=0.25, sink=8, local=256, use_cache=None, cache_requests=None, check_integrity=False, write_out=False, log_samples=False, show_config=False, include_path=None, gen_kwargs=None, verbosity='INFO', wandb_args='', predict_only=False, seed=[0, 1234, 1234], trust_remote_code=False)
Namespace(model='xhf', tasks='gsm8k,triviaqa,ifeval', model_args='pretrained=meta-llama/Llama-2-7b-chat-hf,griffin=True,check=False,griffinnotcats=False', num_fewshot=None, batch_size='1', max_batch_size=None, device=None, output_path=None, limit=None, topp=1.1, topk=64, spr=0.25, sink=8, local=256, use_cache=None, cache_requests=None, check_integrity=False, write_out=False, log_samples=False, show_config=False, include_path=None, gen_kwargs=None, verbosity='INFO', wandb_args='', predict_only=False, seed=[0, 1234, 1234], trust_remote_code=False)
the kernel size is 8
the kernel size is 8
the kernel size is 8
the kernel size is 8
the kernel size is 8
the kernel size is 8
{'results': {'triviaqa': {'exact_match,remove_whitespace': 0.18206642888987962, 'exact_match_stderr,remove_whitespace': 0.0028808883358414383, 'alias': 'triviaqa'}, 'ifeval': {'prompt_level_strict_acc,none': 0.3123844731977819, 'prompt_level_strict_acc_stderr,none': 0.019944386293758908, 'inst_level_strict_acc,none': 0.4352517985611511, 'inst_level_strict_acc_stderr,none': 'N/A', 'prompt_level_loose_acc,none': 0.3419593345656192, 'prompt_level_loose_acc_stderr,none': 0.020413464513923615, 'inst_level_loose_acc,none': 0.46642685851318944, 'inst_level_loose_acc_stderr,none': 'N/A', 'alias': 'ifeval'}, 'gsm8k': {'exact_match,strict-match': 0.19711902956785443, 'exact_match_stderr,strict-match': 0.010958021630300614, 'exact_match,flexible-extract': 0.19939347990902198, 'exact_match_stderr,flexible-extract': 0.011005438029475647, 'alias': 'gsm8k'}}, 'group_subtasks': {'gsm8k': [], 'ifeval': [], 'triviaqa': []}, 'configs': {'gsm8k': {'task': 'gsm8k', 'group': ['math_word_problems'], 'dataset_path': 'gsm8k', 'dataset_name': 'main', 'training_split': 'train', 'test_split': 'test', 'fewshot_split': 'train', 'doc_to_text': 'Question: {{question}}\nAnswer:', 'doc_to_target': '{{answer}}', 'description': '', 'target_delimiter': ' ', 'fewshot_delimiter': '\n\n', 'num_fewshot': 5, 'metric_list': [{'metric': 'exact_match', 'aggregation': 'mean', 'higher_is_better': True, 'ignore_case': True, 'ignore_punctuation': False, 'regexes_to_ignore': [',', '\\$', '(?s).*#### ', '\\.$']}], 'output_type': 'generate_until', 'generation_kwargs': {'until': ['Question:', '</s>', '<|im_end|>'], 'do_sample': False, 'temperature': 0.0}, 'repeats': 1, 'filter_list': [{'name': 'strict-match', 'filter': [{'function': 'regex', 'regex_pattern': '#### (\\-?[0-9\\.\\,]+)'}, {'function': 'take_first'}]}, {'name': 'flexible-extract', 'filter': [{'function': 'regex', 'group_select': -1, 'regex_pattern': '(-?[$0-9.,]{2,})|(-?[0-9]+)'}, {'function': 'take_first'}]}], 'should_decontaminate': False, 'metadata': {'version': 3.0}}, 'ifeval': {'task': 'ifeval', 'dataset_path': 'wis-k/instruction-following-eval', 'test_split': 'train', 'doc_to_text': 'prompt', 'doc_to_target': 0, 'process_results': 'def process_results(doc, results):\n    eval_logger.warning(\n        "This task is meant for chat-finetuned models, and may not give meaningful results for models other than `openai` or `anthropic` if `doc_to_text` in its YAML is not wrapped in the appropriate chat template string. This warning will be removed when chat templating support is added natively to local models"\n    )\n\n    inp = InputExample(\n        key=doc["key"],\n        instruction_id_list=doc["instruction_id_list"],\n        prompt=doc["prompt"],\n        kwargs=doc["kwargs"],\n    )\n    response = results[0]\n\n    out_strict = test_instruction_following_strict(inp, response)\n    out_loose = test_instruction_following_loose(inp, response)\n\n    return {\n        "prompt_level_strict_acc": out_strict.follow_all_instructions,\n        "inst_level_strict_acc": out_strict.follow_instruction_list,\n        "prompt_level_loose_acc": out_loose.follow_all_instructions,\n        "inst_level_loose_acc": out_loose.follow_instruction_list,\n    }\n', 'description': '', 'target_delimiter': ' ', 'fewshot_delimiter': '\n\n', 'num_fewshot': 0, 'metric_list': [{'metric': 'prompt_level_strict_acc', 'aggregation': 'mean', 'higher_is_better': True}, {'metric': 'inst_level_strict_acc', 'aggregation': 'def agg_inst_level_acc(items):\n    flat_items = [item for sublist in items for item in sublist]\n    inst_level_acc = sum(flat_items) / len(flat_items)\n    return inst_level_acc\n', 'higher_is_better': True}, {'metric': 'prompt_level_loose_acc', 'aggregation': 'mean', 'higher_is_better': True}, {'metric': 'inst_level_loose_acc', 'aggregation': 'def agg_inst_level_acc(items):\n    flat_items = [item for sublist in items for item in sublist]\n    inst_level_acc = sum(flat_items) / len(flat_items)\n    return inst_level_acc\n', 'higher_is_better': True}], 'output_type': 'generate_until', 'generation_kwargs': {'until': [], 'do_sample': False, 'temperature': 0.0, 'max_gen_toks': 1280}, 'repeats': 1, 'should_decontaminate': False, 'metadata': {'version': 2.0}}, 'triviaqa': {'task': 'triviaqa', 'dataset_path': 'trivia_qa', 'dataset_name': 'rc.nocontext', 'training_split': 'train', 'validation_split': 'validation', 'doc_to_text': 'Question: {{question}}?\nAnswer:', 'doc_to_target': '{{answer.aliases}}', 'description': '', 'target_delimiter': ' ', 'fewshot_delimiter': '\n\n', 'num_fewshot': 0, 'metric_list': [{'metric': 'exact_match', 'aggregation': 'mean', 'higher_is_better': True, 'ignore_case': True, 'ignore_punctuation': True}], 'output_type': 'generate_until', 'generation_kwargs': {'until': ['\n', '.', ','], 'do_sample': False, 'temperature': 0.0}, 'repeats': 1, 'filter_list': [{'name': 'remove_whitespace', 'filter': [{'function': 'remove_whitespace'}, {'function': 'take_first'}]}], 'should_decontaminate': True, 'doc_to_decontamination_query': 'question', 'metadata': {'version': 3.0}}}, 'versions': {'gsm8k': 3.0, 'ifeval': 2.0, 'triviaqa': 3.0}, 'n-shot': {'gsm8k': 5, 'ifeval': 0, 'triviaqa': 0}}
xhf (pretrained=meta-llama/Llama-2-7b-chat-hf,griffin=True,check=False,griffinnotcats=False), gen_kwargs: (None), limit: None, num_fewshot: None, batch_size: 1
| Tasks  |Version|     Filter      |n-shot|        Metric         |Value |   |Stderr|
|--------|------:|-----------------|-----:|-----------------------|-----:|---|------|
|triviaqa|      3|remove_whitespace|     0|exact_match            |0.1821|±  |0.0029|
|ifeval  |      2|none             |     0|prompt_level_strict_acc|0.3124|±  |0.0199|
|        |       |none             |     0|inst_level_strict_acc  |0.4353|±  |N/A   |
|        |       |none             |     0|prompt_level_loose_acc |0.3420|±  |0.0204|
|        |       |none             |     0|inst_level_loose_acc   |0.4664|±  |N/A   |
|gsm8k   |      3|strict-match     |     5|exact_match            |0.1971|±  |0.0110|
|        |       |flexible-extract |     5|exact_match            |0.1994|±  |0.0110|

