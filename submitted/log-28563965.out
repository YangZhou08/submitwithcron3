M	__pycache__/cache.cpython-312.pyc
M	__pycache__/xevaluator.cpython-312.pyc
M	__pycache__/xhuggingface.cpython-312.pyc
Your branch is up to date with 'origin/yangexp2'.
Already up to date.
/private/home/beidic/.conda/envs/griffin/bin/python
[1m[31mERROR! `huggingface-cli login` uses an outdated login mechanism that is not compatible with the Hugging Face Hub backend anymore. Please use `huggingface-cli login instead.[0m
The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-cli` if you want to set the git credential as well.
Namespace(model='xhf', tasks='gsm8k', model_args='pretrained=meta-llama/Meta-Llama-3-8B-Instruct,cats=True,spr=0.5,check=True,kernel_size=16,thr=0.05', num_fewshot=None, batch_size='1', max_batch_size=None, device=None, output_path=None, limit=0.5, topp=1.1, topk=64, spr=0.25, sink=8, local=256, use_cache=None, cache_requests=None, check_integrity=False, write_out=False, log_samples=False, show_config=False, include_path=None, gen_kwargs=None, verbosity='INFO', wandb_args='', predict_only=False, seed=[0, 1234, 1234], trust_remote_code=False)Namespace(model='xhf', tasks='gsm8k', model_args='pretrained=meta-llama/Meta-Llama-3-8B-Instruct,cats=True,spr=0.5,check=True,kernel_size=16,thr=0.05', num_fewshot=None, batch_size='1', max_batch_size=None, device=None, output_path=None, limit=0.5, topp=1.1, topk=64, spr=0.25, sink=8, local=256, use_cache=None, cache_requests=None, check_integrity=False, write_out=False, log_samples=False, show_config=False, include_path=None, gen_kwargs=None, verbosity='INFO', wandb_args='', predict_only=False, seed=[0, 1234, 1234], trust_remote_code=False)

Namespace(model='xhf', tasks='gsm8k', model_args='pretrained=meta-llama/Meta-Llama-3-8B-Instruct,cats=True,spr=0.5,check=True,kernel_size=16,thr=0.05', num_fewshot=None, batch_size='1', max_batch_size=None, device=None, output_path=None, limit=0.5, topp=1.1, topk=64, spr=0.25, sink=8, local=256, use_cache=None, cache_requests=None, check_integrity=False, write_out=False, log_samples=False, show_config=False, include_path=None, gen_kwargs=None, verbosity='INFO', wandb_args='', predict_only=False, seed=[0, 1234, 1234], trust_remote_code=False)Namespace(model='xhf', tasks='gsm8k', model_args='pretrained=meta-llama/Meta-Llama-3-8B-Instruct,cats=True,spr=0.5,check=True,kernel_size=16,thr=0.05', num_fewshot=None, batch_size='1', max_batch_size=None, device=None, output_path=None, limit=0.5, topp=1.1, topk=64, spr=0.25, sink=8, local=256, use_cache=None, cache_requests=None, check_integrity=False, write_out=False, log_samples=False, show_config=False, include_path=None, gen_kwargs=None, verbosity='INFO', wandb_args='', predict_only=False, seed=[0, 1234, 1234], trust_remote_code=False)

Namespace(model='xhf', tasks='gsm8k', model_args='pretrained=meta-llama/Meta-Llama-3-8B-Instruct,cats=True,spr=0.5,check=True,kernel_size=16,thr=0.05', num_fewshot=None, batch_size='1', max_batch_size=None, device=None, output_path=None, limit=0.5, topp=1.1, topk=64, spr=0.25, sink=8, local=256, use_cache=None, cache_requests=None, check_integrity=False, write_out=False, log_samples=False, show_config=False, include_path=None, gen_kwargs=None, verbosity='INFO', wandb_args='', predict_only=False, seed=[0, 1234, 1234], trust_remote_code=False)Namespace(model='xhf', tasks='gsm8k', model_args='pretrained=meta-llama/Meta-Llama-3-8B-Instruct,cats=True,spr=0.5,check=True,kernel_size=16,thr=0.05', num_fewshot=None, batch_size='1', max_batch_size=None, device=None, output_path=None, limit=0.5, topp=1.1, topk=64, spr=0.25, sink=8, local=256, use_cache=None, cache_requests=None, check_integrity=False, write_out=False, log_samples=False, show_config=False, include_path=None, gen_kwargs=None, verbosity='INFO', wandb_args='', predict_only=False, seed=[0, 1234, 1234], trust_remote_code=False)Namespace(model='xhf', tasks='gsm8k', model_args='pretrained=meta-llama/Meta-Llama-3-8B-Instruct,cats=True,spr=0.5,check=True,kernel_size=16,thr=0.05', num_fewshot=None, batch_size='1', max_batch_size=None, device=None, output_path=None, limit=0.5, topp=1.1, topk=64, spr=0.25, sink=8, local=256, use_cache=None, cache_requests=None, check_integrity=False, write_out=False, log_samples=False, show_config=False, include_path=None, gen_kwargs=None, verbosity='INFO', wandb_args='', predict_only=False, seed=[0, 1234, 1234], trust_remote_code=False)Namespace(model='xhf', tasks='gsm8k', model_args='pretrained=meta-llama/Meta-Llama-3-8B-Instruct,cats=True,spr=0.5,check=True,kernel_size=16,thr=0.05', num_fewshot=None, batch_size='1', max_batch_size=None, device=None, output_path=None, limit=0.5, topp=1.1, topk=64, spr=0.25, sink=8, local=256, use_cache=None, cache_requests=None, check_integrity=False, write_out=False, log_samples=False, show_config=False, include_path=None, gen_kwargs=None, verbosity='INFO', wandb_args='', predict_only=False, seed=[0, 1234, 1234], trust_remote_code=False)



7474 488 15.315573770491802
6819 446 15.289237668161435
7055 464 15.204741379310345
7513 487 15.427104722792608
7629 501 15.22754491017964
8327 550 15.14
7969 524 15.208015267175572
7937 517 15.352030947775628
xhf (pretrained=meta-llama/Meta-Llama-3-8B-Instruct,cats=True,spr=0.5,check=True,kernel_size=16,thr=0.05), gen_kwargs: (None), limit: 0.5, num_fewshot: None, batch_size: 1
|Tasks|Version|     Filter     |n-shot|  Metric   |Value |   |Stderr|
|-----|------:|----------------|-----:|-----------|-----:|---|-----:|
|gsm8k|      3|strict-match    |     5|exact_match|0.7152|Â±  |0.0176|
|     |       |flexible-extract|     5|exact_match|0.7152|Â±  |0.0176|

Namespace(model='xhf', tasks='gsm8k', model_args='pretrained=meta-llama/Meta-Llama-3-8B-Instruct,cats=True,spr=0.5,check=True,kernel_size=16,thr=0.1', num_fewshot=None, batch_size='1', max_batch_size=None, device=None, output_path=None, limit=0.5, topp=1.1, topk=64, spr=0.25, sink=8, local=256, use_cache=None, cache_requests=None, check_integrity=False, write_out=False, log_samples=False, show_config=False, include_path=None, gen_kwargs=None, verbosity='INFO', wandb_args='', predict_only=False, seed=[0, 1234, 1234], trust_remote_code=False)
Namespace(model='xhf', tasks='gsm8k', model_args='pretrained=meta-llama/Meta-Llama-3-8B-Instruct,cats=True,spr=0.5,check=True,kernel_size=16,thr=0.1', num_fewshot=None, batch_size='1', max_batch_size=None, device=None, output_path=None, limit=0.5, topp=1.1, topk=64, spr=0.25, sink=8, local=256, use_cache=None, cache_requests=None, check_integrity=False, write_out=False, log_samples=False, show_config=False, include_path=None, gen_kwargs=None, verbosity='INFO', wandb_args='', predict_only=False, seed=[0, 1234, 1234], trust_remote_code=False)
Namespace(model='xhf', tasks='gsm8k', model_args='pretrained=meta-llama/Meta-Llama-3-8B-Instruct,cats=True,spr=0.5,check=True,kernel_size=16,thr=0.1', num_fewshot=None, batch_size='1', max_batch_size=None, device=None, output_path=None, limit=0.5, topp=1.1, topk=64, spr=0.25, sink=8, local=256, use_cache=None, cache_requests=None, check_integrity=False, write_out=False, log_samples=False, show_config=False, include_path=None, gen_kwargs=None, verbosity='INFO', wandb_args='', predict_only=False, seed=[0, 1234, 1234], trust_remote_code=False)
Namespace(model='xhf', tasks='gsm8k', model_args='pretrained=meta-llama/Meta-Llama-3-8B-Instruct,cats=True,spr=0.5,check=True,kernel_size=16,thr=0.1', num_fewshot=None, batch_size='1', max_batch_size=None, device=None, output_path=None, limit=0.5, topp=1.1, topk=64, spr=0.25, sink=8, local=256, use_cache=None, cache_requests=None, check_integrity=False, write_out=False, log_samples=False, show_config=False, include_path=None, gen_kwargs=None, verbosity='INFO', wandb_args='', predict_only=False, seed=[0, 1234, 1234], trust_remote_code=False)
Namespace(model='xhf', tasks='gsm8k', model_args='pretrained=meta-llama/Meta-Llama-3-8B-Instruct,cats=True,spr=0.5,check=True,kernel_size=16,thr=0.1', num_fewshot=None, batch_size='1', max_batch_size=None, device=None, output_path=None, limit=0.5, topp=1.1, topk=64, spr=0.25, sink=8, local=256, use_cache=None, cache_requests=None, check_integrity=False, write_out=False, log_samples=False, show_config=False, include_path=None, gen_kwargs=None, verbosity='INFO', wandb_args='', predict_only=False, seed=[0, 1234, 1234], trust_remote_code=False)
Namespace(model='xhf', tasks='gsm8k', model_args='pretrained=meta-llama/Meta-Llama-3-8B-Instruct,cats=True,spr=0.5,check=True,kernel_size=16,thr=0.1', num_fewshot=None, batch_size='1', max_batch_size=None, device=None, output_path=None, limit=0.5, topp=1.1, topk=64, spr=0.25, sink=8, local=256, use_cache=None, cache_requests=None, check_integrity=False, write_out=False, log_samples=False, show_config=False, include_path=None, gen_kwargs=None, verbosity='INFO', wandb_args='', predict_only=False, seed=[0, 1234, 1234], trust_remote_code=False)
Namespace(model='xhf', tasks='gsm8k', model_args='pretrained=meta-llama/Meta-Llama-3-8B-Instruct,cats=True,spr=0.5,check=True,kernel_size=16,thr=0.1', num_fewshot=None, batch_size='1', max_batch_size=None, device=None, output_path=None, limit=0.5, topp=1.1, topk=64, spr=0.25, sink=8, local=256, use_cache=None, cache_requests=None, check_integrity=False, write_out=False, log_samples=False, show_config=False, include_path=None, gen_kwargs=None, verbosity='INFO', wandb_args='', predict_only=False, seed=[0, 1234, 1234], trust_remote_code=False)
Namespace(model='xhf', tasks='gsm8k', model_args='pretrained=meta-llama/Meta-Llama-3-8B-Instruct,cats=True,spr=0.5,check=True,kernel_size=16,thr=0.1', num_fewshot=None, batch_size='1', max_batch_size=None, device=None, output_path=None, limit=0.5, topp=1.1, topk=64, spr=0.25, sink=8, local=256, use_cache=None, cache_requests=None, check_integrity=False, write_out=False, log_samples=False, show_config=False, include_path=None, gen_kwargs=None, verbosity='INFO', wandb_args='', predict_only=False, seed=[0, 1234, 1234], trust_remote_code=False)
8049 554 14.528880866425993
7309 489 14.946830265848671
6770 458 14.781659388646288
7178 494 14.530364372469636
7265 494 14.706477732793521
7792 532 14.646616541353383
7916 539 14.686456400742115
7893 533 14.808630393996248
xhf (pretrained=meta-llama/Meta-Llama-3-8B-Instruct,cats=True,spr=0.5,check=True,kernel_size=16,thr=0.1), gen_kwargs: (None), limit: 0.5, num_fewshot: None, batch_size: 1
|Tasks|Version|     Filter     |n-shot|  Metric   |Value |   |Stderr|
|-----|------:|----------------|-----:|-----------|-----:|---|-----:|
|gsm8k|      3|strict-match    |     5|exact_match|0.7152|Â±  |0.0176|
|     |       |flexible-extract|     5|exact_match|0.7152|Â±  |0.0176|

Namespace(model='xhf', tasks='gsm8k', model_args='pretrained=meta-llama/Meta-Llama-3-8B-Instruct,cats=True,spr=0.5,check=True,kernel_size=16,thr=0.15', num_fewshot=None, batch_size='1', max_batch_size=None, device=None, output_path=None, limit=0.5, topp=1.1, topk=64, spr=0.25, sink=8, local=256, use_cache=None, cache_requests=None, check_integrity=False, write_out=False, log_samples=False, show_config=False, include_path=None, gen_kwargs=None, verbosity='INFO', wandb_args='', predict_only=False, seed=[0, 1234, 1234], trust_remote_code=False)
Namespace(model='xhf', tasks='gsm8k', model_args='pretrained=meta-llama/Meta-Llama-3-8B-Instruct,cats=True,spr=0.5,check=True,kernel_size=16,thr=0.15', num_fewshot=None, batch_size='1', max_batch_size=None, device=None, output_path=None, limit=0.5, topp=1.1, topk=64, spr=0.25, sink=8, local=256, use_cache=None, cache_requests=None, check_integrity=False, write_out=False, log_samples=False, show_config=False, include_path=None, gen_kwargs=None, verbosity='INFO', wandb_args='', predict_only=False, seed=[0, 1234, 1234], trust_remote_code=False)
Namespace(model='xhf', tasks='gsm8k', model_args='pretrained=meta-llama/Meta-Llama-3-8B-Instruct,cats=True,spr=0.5,check=True,kernel_size=16,thr=0.15', num_fewshot=None, batch_size='1', max_batch_size=None, device=None, output_path=None, limit=0.5, topp=1.1, topk=64, spr=0.25, sink=8, local=256, use_cache=None, cache_requests=None, check_integrity=False, write_out=False, log_samples=False, show_config=False, include_path=None, gen_kwargs=None, verbosity='INFO', wandb_args='', predict_only=False, seed=[0, 1234, 1234], trust_remote_code=False)
Namespace(model='xhf', tasks='gsm8k', model_args='pretrained=meta-llama/Meta-Llama-3-8B-Instruct,cats=True,spr=0.5,check=True,kernel_size=16,thr=0.15', num_fewshot=None, batch_size='1', max_batch_size=None, device=None, output_path=None, limit=0.5, topp=1.1, topk=64, spr=0.25, sink=8, local=256, use_cache=None, cache_requests=None, check_integrity=False, write_out=False, log_samples=False, show_config=False, include_path=None, gen_kwargs=None, verbosity='INFO', wandb_args='', predict_only=False, seed=[0, 1234, 1234], trust_remote_code=False)
Namespace(model='xhf', tasks='gsm8k', model_args='pretrained=meta-llama/Meta-Llama-3-8B-Instruct,cats=True,spr=0.5,check=True,kernel_size=16,thr=0.15', num_fewshot=None, batch_size='1', max_batch_size=None, device=None, output_path=None, limit=0.5, topp=1.1, topk=64, spr=0.25, sink=8, local=256, use_cache=None, cache_requests=None, check_integrity=False, write_out=False, log_samples=False, show_config=False, include_path=None, gen_kwargs=None, verbosity='INFO', wandb_args='', predict_only=False, seed=[0, 1234, 1234], trust_remote_code=False)
Namespace(model='xhf', tasks='gsm8k', model_args='pretrained=meta-llama/Meta-Llama-3-8B-Instruct,cats=True,spr=0.5,check=True,kernel_size=16,thr=0.15', num_fewshot=None, batch_size='1', max_batch_size=None, device=None, output_path=None, limit=0.5, topp=1.1, topk=64, spr=0.25, sink=8, local=256, use_cache=None, cache_requests=None, check_integrity=False, write_out=False, log_samples=False, show_config=False, include_path=None, gen_kwargs=None, verbosity='INFO', wandb_args='', predict_only=False, seed=[0, 1234, 1234], trust_remote_code=False)
Namespace(model='xhf', tasks='gsm8k', model_args='pretrained=meta-llama/Meta-Llama-3-8B-Instruct,cats=True,spr=0.5,check=True,kernel_size=16,thr=0.15', num_fewshot=None, batch_size='1', max_batch_size=None, device=None, output_path=None, limit=0.5, topp=1.1, topk=64, spr=0.25, sink=8, local=256, use_cache=None, cache_requests=None, check_integrity=False, write_out=False, log_samples=False, show_config=False, include_path=None, gen_kwargs=None, verbosity='INFO', wandb_args='', predict_only=False, seed=[0, 1234, 1234], trust_remote_code=False)
Namespace(model='xhf', tasks='gsm8k', model_args='pretrained=meta-llama/Meta-Llama-3-8B-Instruct,cats=True,spr=0.5,check=True,kernel_size=16,thr=0.15', num_fewshot=None, batch_size='1', max_batch_size=None, device=None, output_path=None, limit=0.5, topp=1.1, topk=64, spr=0.25, sink=8, local=256, use_cache=None, cache_requests=None, check_integrity=False, write_out=False, log_samples=False, show_config=False, include_path=None, gen_kwargs=None, verbosity='INFO', wandb_args='', predict_only=False, seed=[0, 1234, 1234], trust_remote_code=False)
6795 500 13.59
7271 522 13.92911877394636
7189 514 13.986381322957198
7767 550 14.121818181818181
7765 555 13.99099099099099
6653 468 14.215811965811966
8062 581 13.876075731497417
8021 586 13.687713310580206
xhf (pretrained=meta-llama/Meta-Llama-3-8B-Instruct,cats=True,spr=0.5,check=True,kernel_size=16,thr=0.15), gen_kwargs: (None), limit: 0.5, num_fewshot: None, batch_size: 1
|Tasks|Version|     Filter     |n-shot|  Metric   |Value |   |Stderr|
|-----|------:|----------------|-----:|-----------|-----:|---|-----:|
|gsm8k|      3|strict-match    |     5|exact_match|0.7288|Â±  |0.0173|
|     |       |flexible-extract|     5|exact_match|0.7303|Â±  |0.0173|

Namespace(model='xhf', tasks='gsm8k', model_args='pretrained=meta-llama/Meta-Llama-3-8B-Instruct,cats=True,spr=0.5,check=True,kernel_size=16,thr=0.2', num_fewshot=None, batch_size='1', max_batch_size=None, device=None, output_path=None, limit=0.5, topp=1.1, topk=64, spr=0.25, sink=8, local=256, use_cache=None, cache_requests=None, check_integrity=False, write_out=False, log_samples=False, show_config=False, include_path=None, gen_kwargs=None, verbosity='INFO', wandb_args='', predict_only=False, seed=[0, 1234, 1234], trust_remote_code=False)
Namespace(model='xhf', tasks='gsm8k', model_args='pretrained=meta-llama/Meta-Llama-3-8B-Instruct,cats=True,spr=0.5,check=True,kernel_size=16,thr=0.2', num_fewshot=None, batch_size='1', max_batch_size=None, device=None, output_path=None, limit=0.5, topp=1.1, topk=64, spr=0.25, sink=8, local=256, use_cache=None, cache_requests=None, check_integrity=False, write_out=False, log_samples=False, show_config=False, include_path=None, gen_kwargs=None, verbosity='INFO', wandb_args='', predict_only=False, seed=[0, 1234, 1234], trust_remote_code=False)
Namespace(model='xhf', tasks='gsm8k', model_args='pretrained=meta-llama/Meta-Llama-3-8B-Instruct,cats=True,spr=0.5,check=True,kernel_size=16,thr=0.2', num_fewshot=None, batch_size='1', max_batch_size=None, device=None, output_path=None, limit=0.5, topp=1.1, topk=64, spr=0.25, sink=8, local=256, use_cache=None, cache_requests=None, check_integrity=False, write_out=False, log_samples=False, show_config=False, include_path=None, gen_kwargs=None, verbosity='INFO', wandb_args='', predict_only=False, seed=[0, 1234, 1234], trust_remote_code=False)
Namespace(model='xhf', tasks='gsm8k', model_args='pretrained=meta-llama/Meta-Llama-3-8B-Instruct,cats=True,spr=0.5,check=True,kernel_size=16,thr=0.2', num_fewshot=None, batch_size='1', max_batch_size=None, device=None, output_path=None, limit=0.5, topp=1.1, topk=64, spr=0.25, sink=8, local=256, use_cache=None, cache_requests=None, check_integrity=False, write_out=False, log_samples=False, show_config=False, include_path=None, gen_kwargs=None, verbosity='INFO', wandb_args='', predict_only=False, seed=[0, 1234, 1234], trust_remote_code=False)
Namespace(model='xhf', tasks='gsm8k', model_args='pretrained=meta-llama/Meta-Llama-3-8B-Instruct,cats=True,spr=0.5,check=True,kernel_size=16,thr=0.2', num_fewshot=None, batch_size='1', max_batch_size=None, device=None, output_path=None, limit=0.5, topp=1.1, topk=64, spr=0.25, sink=8, local=256, use_cache=None, cache_requests=None, check_integrity=False, write_out=False, log_samples=False, show_config=False, include_path=None, gen_kwargs=None, verbosity='INFO', wandb_args='', predict_only=False, seed=[0, 1234, 1234], trust_remote_code=False)
Namespace(model='xhf', tasks='gsm8k', model_args='pretrained=meta-llama/Meta-Llama-3-8B-Instruct,cats=True,spr=0.5,check=True,kernel_size=16,thr=0.2', num_fewshot=None, batch_size='1', max_batch_size=None, device=None, output_path=None, limit=0.5, topp=1.1, topk=64, spr=0.25, sink=8, local=256, use_cache=None, cache_requests=None, check_integrity=False, write_out=False, log_samples=False, show_config=False, include_path=None, gen_kwargs=None, verbosity='INFO', wandb_args='', predict_only=False, seed=[0, 1234, 1234], trust_remote_code=False)
Namespace(model='xhf', tasks='gsm8k', model_args='pretrained=meta-llama/Meta-Llama-3-8B-Instruct,cats=True,spr=0.5,check=True,kernel_size=16,thr=0.2', num_fewshot=None, batch_size='1', max_batch_size=None, device=None, output_path=None, limit=0.5, topp=1.1, topk=64, spr=0.25, sink=8, local=256, use_cache=None, cache_requests=None, check_integrity=False, write_out=False, log_samples=False, show_config=False, include_path=None, gen_kwargs=None, verbosity='INFO', wandb_args='', predict_only=False, seed=[0, 1234, 1234], trust_remote_code=False)
Namespace(model='xhf', tasks='gsm8k', model_args='pretrained=meta-llama/Meta-Llama-3-8B-Instruct,cats=True,spr=0.5,check=True,kernel_size=16,thr=0.2', num_fewshot=None, batch_size='1', max_batch_size=None, device=None, output_path=None, limit=0.5, topp=1.1, topk=64, spr=0.25, sink=8, local=256, use_cache=None, cache_requests=None, check_integrity=False, write_out=False, log_samples=False, show_config=False, include_path=None, gen_kwargs=None, verbosity='INFO', wandb_args='', predict_only=False, seed=[0, 1234, 1234], trust_remote_code=False)
7254 549 13.21311475409836
7203 548 13.144160583941606
6718 502 13.382470119521912
7636 579 13.18825561312608
8071 608 13.274671052631579
8148 615 13.248780487804877
6956 532 13.075187969924812
7613 575 13.24
xhf (pretrained=meta-llama/Meta-Llama-3-8B-Instruct,cats=True,spr=0.5,check=True,kernel_size=16,thr=0.2), gen_kwargs: (None), limit: 0.5, num_fewshot: None, batch_size: 1
|Tasks|Version|     Filter     |n-shot|  Metric   |Value |   |Stderr|
|-----|------:|----------------|-----:|-----------|-----:|---|-----:|
|gsm8k|      3|strict-match    |     5|exact_match|0.7394|Â±  |0.0171|
|     |       |flexible-extract|     5|exact_match|0.7409|Â±  |0.0171|

Namespace(model='xhf', tasks='gsm8k', model_args='pretrained=meta-llama/Meta-Llama-3-8B-Instruct,cats=True,spr=0.5,check=True,kernel_size=16,thr=0.3', num_fewshot=None, batch_size='1', max_batch_size=None, device=None, output_path=None, limit=0.5, topp=1.1, topk=64, spr=0.25, sink=8, local=256, use_cache=None, cache_requests=None, check_integrity=False, write_out=False, log_samples=False, show_config=False, include_path=None, gen_kwargs=None, verbosity='INFO', wandb_args='', predict_only=False, seed=[0, 1234, 1234], trust_remote_code=False)
Namespace(model='xhf', tasks='gsm8k', model_args='pretrained=meta-llama/Meta-Llama-3-8B-Instruct,cats=True,spr=0.5,check=True,kernel_size=16,thr=0.3', num_fewshot=None, batch_size='1', max_batch_size=None, device=None, output_path=None, limit=0.5, topp=1.1, topk=64, spr=0.25, sink=8, local=256, use_cache=None, cache_requests=None, check_integrity=False, write_out=False, log_samples=False, show_config=False, include_path=None, gen_kwargs=None, verbosity='INFO', wandb_args='', predict_only=False, seed=[0, 1234, 1234], trust_remote_code=False)
Namespace(model='xhf', tasks='gsm8k', model_args='pretrained=meta-llama/Meta-Llama-3-8B-Instruct,cats=True,spr=0.5,check=True,kernel_size=16,thr=0.3', num_fewshot=None, batch_size='1', max_batch_size=None, device=None, output_path=None, limit=0.5, topp=1.1, topk=64, spr=0.25, sink=8, local=256, use_cache=None, cache_requests=None, check_integrity=False, write_out=False, log_samples=False, show_config=False, include_path=None, gen_kwargs=None, verbosity='INFO', wandb_args='', predict_only=False, seed=[0, 1234, 1234], trust_remote_code=False)
Namespace(model='xhf', tasks='gsm8k', model_args='pretrained=meta-llama/Meta-Llama-3-8B-Instruct,cats=True,spr=0.5,check=True,kernel_size=16,thr=0.3', num_fewshot=None, batch_size='1', max_batch_size=None, device=None, output_path=None, limit=0.5, topp=1.1, topk=64, spr=0.25, sink=8, local=256, use_cache=None, cache_requests=None, check_integrity=False, write_out=False, log_samples=False, show_config=False, include_path=None, gen_kwargs=None, verbosity='INFO', wandb_args='', predict_only=False, seed=[0, 1234, 1234], trust_remote_code=False)
Namespace(model='xhf', tasks='gsm8k', model_args='pretrained=meta-llama/Meta-Llama-3-8B-Instruct,cats=True,spr=0.5,check=True,kernel_size=16,thr=0.3', num_fewshot=None, batch_size='1', max_batch_size=None, device=None, output_path=None, limit=0.5, topp=1.1, topk=64, spr=0.25, sink=8, local=256, use_cache=None, cache_requests=None, check_integrity=False, write_out=False, log_samples=False, show_config=False, include_path=None, gen_kwargs=None, verbosity='INFO', wandb_args='', predict_only=False, seed=[0, 1234, 1234], trust_remote_code=False)
Namespace(model='xhf', tasks='gsm8k', model_args='pretrained=meta-llama/Meta-Llama-3-8B-Instruct,cats=True,spr=0.5,check=True,kernel_size=16,thr=0.3', num_fewshot=None, batch_size='1', max_batch_size=None, device=None, output_path=None, limit=0.5, topp=1.1, topk=64, spr=0.25, sink=8, local=256, use_cache=None, cache_requests=None, check_integrity=False, write_out=False, log_samples=False, show_config=False, include_path=None, gen_kwargs=None, verbosity='INFO', wandb_args='', predict_only=False, seed=[0, 1234, 1234], trust_remote_code=False)
Namespace(model='xhf', tasks='gsm8k', model_args='pretrained=meta-llama/Meta-Llama-3-8B-Instruct,cats=True,spr=0.5,check=True,kernel_size=16,thr=0.3', num_fewshot=None, batch_size='1', max_batch_size=None, device=None, output_path=None, limit=0.5, topp=1.1, topk=64, spr=0.25, sink=8, local=256, use_cache=None, cache_requests=None, check_integrity=False, write_out=False, log_samples=False, show_config=False, include_path=None, gen_kwargs=None, verbosity='INFO', wandb_args='', predict_only=False, seed=[0, 1234, 1234], trust_remote_code=False)
Namespace(model='xhf', tasks='gsm8k', model_args='pretrained=meta-llama/Meta-Llama-3-8B-Instruct,cats=True,spr=0.5,check=True,kernel_size=16,thr=0.3', num_fewshot=None, batch_size='1', max_batch_size=None, device=None, output_path=None, limit=0.5, topp=1.1, topk=64, spr=0.25, sink=8, local=256, use_cache=None, cache_requests=None, check_integrity=False, write_out=False, log_samples=False, show_config=False, include_path=None, gen_kwargs=None, verbosity='INFO', wandb_args='', predict_only=False, seed=[0, 1234, 1234], trust_remote_code=False)
7967 678 11.750737463126844
6674 557 11.982046678635548
7376 635 11.615748031496063
6825 594 11.48989898989899
7592 624 12.166666666666666
7491 643 11.650077760497668
8216 696 11.804597701149426
7668 655 11.706870229007633
xhf (pretrained=meta-llama/Meta-Llama-3-8B-Instruct,cats=True,spr=0.5,check=True,kernel_size=16,thr=0.3), gen_kwargs: (None), limit: 0.5, num_fewshot: None, batch_size: 1
|Tasks|Version|     Filter     |n-shot|  Metric   |Value |   |Stderr|
|-----|------:|----------------|-----:|-----------|-----:|---|-----:|
|gsm8k|      3|strict-match    |     5|exact_match|0.7394|Â±  |0.0171|
|     |       |flexible-extract|     5|exact_match|0.7424|Â±  |0.0170|

Namespace(model='xhf', tasks='gsm8k', model_args='pretrained=meta-llama/Meta-Llama-3-8B-Instruct,cats=True,spr=0.5,check=True,kernel_size=16,thr=0.4', num_fewshot=None, batch_size='1', max_batch_size=None, device=None, output_path=None, limit=0.5, topp=1.1, topk=64, spr=0.25, sink=8, local=256, use_cache=None, cache_requests=None, check_integrity=False, write_out=False, log_samples=False, show_config=False, include_path=None, gen_kwargs=None, verbosity='INFO', wandb_args='', predict_only=False, seed=[0, 1234, 1234], trust_remote_code=False)
Namespace(model='xhf', tasks='gsm8k', model_args='pretrained=meta-llama/Meta-Llama-3-8B-Instruct,cats=True,spr=0.5,check=True,kernel_size=16,thr=0.4', num_fewshot=None, batch_size='1', max_batch_size=None, device=None, output_path=None, limit=0.5, topp=1.1, topk=64, spr=0.25, sink=8, local=256, use_cache=None, cache_requests=None, check_integrity=False, write_out=False, log_samples=False, show_config=False, include_path=None, gen_kwargs=None, verbosity='INFO', wandb_args='', predict_only=False, seed=[0, 1234, 1234], trust_remote_code=False)
Namespace(model='xhf', tasks='gsm8k', model_args='pretrained=meta-llama/Meta-Llama-3-8B-Instruct,cats=True,spr=0.5,check=True,kernel_size=16,thr=0.4', num_fewshot=None, batch_size='1', max_batch_size=None, device=None, output_path=None, limit=0.5, topp=1.1, topk=64, spr=0.25, sink=8, local=256, use_cache=None, cache_requests=None, check_integrity=False, write_out=False, log_samples=False, show_config=False, include_path=None, gen_kwargs=None, verbosity='INFO', wandb_args='', predict_only=False, seed=[0, 1234, 1234], trust_remote_code=False)
Namespace(model='xhf', tasks='gsm8k', model_args='pretrained=meta-llama/Meta-Llama-3-8B-Instruct,cats=True,spr=0.5,check=True,kernel_size=16,thr=0.4', num_fewshot=None, batch_size='1', max_batch_size=None, device=None, output_path=None, limit=0.5, topp=1.1, topk=64, spr=0.25, sink=8, local=256, use_cache=None, cache_requests=None, check_integrity=False, write_out=False, log_samples=False, show_config=False, include_path=None, gen_kwargs=None, verbosity='INFO', wandb_args='', predict_only=False, seed=[0, 1234, 1234], trust_remote_code=False)
Namespace(model='xhf', tasks='gsm8k', model_args='pretrained=meta-llama/Meta-Llama-3-8B-Instruct,cats=True,spr=0.5,check=True,kernel_size=16,thr=0.4', num_fewshot=None, batch_size='1', max_batch_size=None, device=None, output_path=None, limit=0.5, topp=1.1, topk=64, spr=0.25, sink=8, local=256, use_cache=None, cache_requests=None, check_integrity=False, write_out=False, log_samples=False, show_config=False, include_path=None, gen_kwargs=None, verbosity='INFO', wandb_args='', predict_only=False, seed=[0, 1234, 1234], trust_remote_code=False)
Namespace(model='xhf', tasks='gsm8k', model_args='pretrained=meta-llama/Meta-Llama-3-8B-Instruct,cats=True,spr=0.5,check=True,kernel_size=16,thr=0.4', num_fewshot=None, batch_size='1', max_batch_size=None, device=None, output_path=None, limit=0.5, topp=1.1, topk=64, spr=0.25, sink=8, local=256, use_cache=None, cache_requests=None, check_integrity=False, write_out=False, log_samples=False, show_config=False, include_path=None, gen_kwargs=None, verbosity='INFO', wandb_args='', predict_only=False, seed=[0, 1234, 1234], trust_remote_code=False)
Namespace(model='xhf', tasks='gsm8k', model_args='pretrained=meta-llama/Meta-Llama-3-8B-Instruct,cats=True,spr=0.5,check=True,kernel_size=16,thr=0.4', num_fewshot=None, batch_size='1', max_batch_size=None, device=None, output_path=None, limit=0.5, topp=1.1, topk=64, spr=0.25, sink=8, local=256, use_cache=None, cache_requests=None, check_integrity=False, write_out=False, log_samples=False, show_config=False, include_path=None, gen_kwargs=None, verbosity='INFO', wandb_args='', predict_only=False, seed=[0, 1234, 1234], trust_remote_code=False)
Namespace(model='xhf', tasks='gsm8k', model_args='pretrained=meta-llama/Meta-Llama-3-8B-Instruct,cats=True,spr=0.5,check=True,kernel_size=16,thr=0.4', num_fewshot=None, batch_size='1', max_batch_size=None, device=None, output_path=None, limit=0.5, topp=1.1, topk=64, spr=0.25, sink=8, local=256, use_cache=None, cache_requests=None, check_integrity=False, write_out=False, log_samples=False, show_config=False, include_path=None, gen_kwargs=None, verbosity='INFO', wandb_args='', predict_only=False, seed=[0, 1234, 1234], trust_remote_code=False)
7368 722 10.204986149584487
6788 660 10.284848484848485
6960 722 9.6398891966759
8261 822 10.049878345498783
8020 799 10.037546933667084
8132 816 9.965686274509803
7659 759 10.090909090909092
7563 770 9.822077922077922
xhf (pretrained=meta-llama/Meta-Llama-3-8B-Instruct,cats=True,spr=0.5,check=True,kernel_size=16,thr=0.4), gen_kwargs: (None), limit: 0.5, num_fewshot: None, batch_size: 1
|Tasks|Version|     Filter     |n-shot|  Metric   |Value |   |Stderr|
|-----|------:|----------------|-----:|-----------|-----:|---|-----:|
|gsm8k|      3|strict-match    |     5|exact_match|0.7167|Â±  |0.0176|
|     |       |flexible-extract|     5|exact_match|0.7227|Â±  |0.0174|

