Already on 'yangexp2'
wandb: Currently logged in as: stevenzhou0816100. Use `wandb login --relogin` to force relogin
Traceback (most recent call last):
  File "/private/home/beidic/.conda/envs/griffin/bin/huggingface-cli", line 8, in <module>
    sys.exit(main())
             ^^^^^^
  File "/private/home/beidic/.conda/envs/griffin/lib/python3.12/site-packages/huggingface_hub/commands/huggingface_cli.py", line 51, in main
    service.run()
  File "/private/home/beidic/.conda/envs/griffin/lib/python3.12/site-packages/huggingface_hub/commands/user.py", line 98, in run
    login(token=self.args.token, add_to_git_credential=self.args.add_to_git_credential)
  File "/private/home/beidic/.conda/envs/griffin/lib/python3.12/site-packages/huggingface_hub/_login.py", line 111, in login
    _login(token, add_to_git_credential=add_to_git_credential, write_permission=write_permission)
  File "/private/home/beidic/.conda/envs/griffin/lib/python3.12/site-packages/huggingface_hub/_login.py", line 307, in _login
    raise ValueError("Invalid token passed!")
ValueError: Invalid token passed!
The following values were not passed to `accelerate launch` and had defaults used instead:
		More than one GPU was found, enabling multi-GPU training.
		If this was unintended please pass in `--num_processes=1`.
	`--mixed_precision` was set to a value of `'no'`
	`--dynamo_backend` was set to a value of `'no'`
To avoid this warning pass in values for each of the problematic parameters or run `accelerate config`.
2024-06-03:15:07:04,828 INFO     [main.py:288] Verbosity set to INFO
2024-06-03:15:07:04,829 INFO     [main.py:288] Verbosity set to INFO
2024-06-03:15:07:04,829 INFO     [main.py:288] Verbosity set to INFO
2024-06-03:15:07:04,829 INFO     [main.py:288] Verbosity set to INFO
2024-06-03:15:07:04,829 INFO     [main.py:288] Verbosity set to INFO
2024-06-03:15:07:04,835 INFO     [main.py:288] Verbosity set to INFO
2024-06-03:15:07:04,877 INFO     [main.py:288] Verbosity set to INFO
2024-06-03:15:07:04,883 INFO     [main.py:288] Verbosity set to INFO
2024-06-03:15:07:10,566 INFO     [main.py:378] Selected Tasks: ['gsm8k']
2024-06-03:15:07:10,567 INFO     [main.py:378] Selected Tasks: ['gsm8k']
2024-06-03:15:07:10,573 INFO     [xevaluator.py:137] Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234
2024-06-03:15:07:10,573 INFO     [xevaluator.py:184] Initializing xhf model, with arguments: {'pretrained': 'meta-llama/Meta-Llama-3-8B', 'griffin': True, 'check': False}
2024-06-03:15:07:10,573 INFO     [xevaluator.py:137] Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234
2024-06-03:15:07:10,573 INFO     [xevaluator.py:184] Initializing xhf model, with arguments: {'pretrained': 'meta-llama/Meta-Llama-3-8B', 'griffin': True, 'check': False}
2024-06-03:15:07:11,095 INFO     [main.py:378] Selected Tasks: ['gsm8k']
2024-06-03:15:07:11,099 INFO     [xevaluator.py:137] Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234
2024-06-03:15:07:11,099 INFO     [xevaluator.py:184] Initializing xhf model, with arguments: {'pretrained': 'meta-llama/Meta-Llama-3-8B', 'griffin': True, 'check': False}
2024-06-03:15:07:11,115 INFO     [main.py:378] Selected Tasks: ['gsm8k']
2024-06-03:15:07:11,118 INFO     [xevaluator.py:137] Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234
2024-06-03:15:07:11,118 INFO     [xevaluator.py:184] Initializing xhf model, with arguments: {'pretrained': 'meta-llama/Meta-Llama-3-8B', 'griffin': True, 'check': False}
2024-06-03:15:07:11,125 INFO     [main.py:378] Selected Tasks: ['gsm8k']
2024-06-03:15:07:11,129 INFO     [xevaluator.py:137] Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234
2024-06-03:15:07:11,129 INFO     [xevaluator.py:184] Initializing xhf model, with arguments: {'pretrained': 'meta-llama/Meta-Llama-3-8B', 'griffin': True, 'check': False}
2024-06-03:15:07:11,138 INFO     [main.py:378] Selected Tasks: ['gsm8k']
2024-06-03:15:07:11,142 INFO     [main.py:378] Selected Tasks: ['gsm8k']
2024-06-03:15:07:11,142 INFO     [xevaluator.py:137] Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234
2024-06-03:15:07:11,142 INFO     [xevaluator.py:184] Initializing xhf model, with arguments: {'pretrained': 'meta-llama/Meta-Llama-3-8B', 'griffin': True, 'check': False}
2024-06-03:15:07:11,145 INFO     [main.py:378] Selected Tasks: ['gsm8k']
2024-06-03:15:07:11,146 INFO     [xevaluator.py:137] Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234
2024-06-03:15:07:11,146 INFO     [xevaluator.py:184] Initializing xhf model, with arguments: {'pretrained': 'meta-llama/Meta-Llama-3-8B', 'griffin': True, 'check': False}
2024-06-03:15:07:11,153 INFO     [xevaluator.py:137] Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234
2024-06-03:15:07:11,153 INFO     [xevaluator.py:184] Initializing xhf model, with arguments: {'pretrained': 'meta-llama/Meta-Llama-3-8B', 'griffin': True, 'check': False}
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:  25%|██▌       | 1/4 [00:27<01:23, 27.71s/it]Loading checkpoint shards:  25%|██▌       | 1/4 [00:28<01:24, 28.10s/it]Loading checkpoint shards:  25%|██▌       | 1/4 [00:28<01:24, 28.11s/it]Loading checkpoint shards:  25%|██▌       | 1/4 [00:28<01:24, 28.23s/it]Loading checkpoint shards:  25%|██▌       | 1/4 [00:28<01:24, 28.17s/it]Loading checkpoint shards:  25%|██▌       | 1/4 [00:29<01:27, 29.29s/it]Loading checkpoint shards:  25%|██▌       | 1/4 [00:28<01:24, 28.19s/it]Loading checkpoint shards:  25%|██▌       | 1/4 [00:28<01:24, 28.17s/it]Loading checkpoint shards:  50%|█████     | 2/4 [00:53<00:52, 26.33s/it]Loading checkpoint shards:  50%|█████     | 2/4 [00:52<00:52, 26.15s/it]Loading checkpoint shards:  50%|█████     | 2/4 [00:53<00:52, 26.20s/it]Loading checkpoint shards:  50%|█████     | 2/4 [00:52<00:52, 26.18s/it]Loading checkpoint shards:  50%|█████     | 2/4 [00:52<00:52, 26.19s/it]Loading checkpoint shards:  50%|█████     | 2/4 [00:54<00:53, 26.61s/it]Loading checkpoint shards:  50%|█████     | 2/4 [00:52<00:52, 26.18s/it]Loading checkpoint shards:  50%|█████     | 2/4 [00:52<00:52, 26.19s/it]Loading checkpoint shards:  75%|███████▌  | 3/4 [01:17<00:25, 25.49s/it]Loading checkpoint shards:  75%|███████▌  | 3/4 [01:19<00:26, 26.29s/it]Loading checkpoint shards:  75%|███████▌  | 3/4 [01:18<00:25, 25.83s/it]Loading checkpoint shards:  75%|███████▌  | 3/4 [01:18<00:25, 25.81s/it]Loading checkpoint shards:  75%|███████▌  | 3/4 [01:19<00:26, 26.08s/it]Loading checkpoint shards:  75%|███████▌  | 3/4 [01:18<00:25, 25.87s/it]Loading checkpoint shards:  75%|███████▌  | 3/4 [01:18<00:25, 25.83s/it]Loading checkpoint shards:  75%|███████▌  | 3/4 [01:18<00:25, 25.86s/it]Loading checkpoint shards: 100%|██████████| 4/4 [01:23<00:00, 17.58s/it]Loading checkpoint shards: 100%|██████████| 4/4 [01:23<00:00, 20.76s/it]
Loading checkpoint shards: 100%|██████████| 4/4 [01:24<00:00, 17.69s/it]Loading checkpoint shards: 100%|██████████| 4/4 [01:24<00:00, 21.07s/it]
Loading checkpoint shards: 100%|██████████| 4/4 [01:23<00:00, 17.55s/it]Loading checkpoint shards: 100%|██████████| 4/4 [01:23<00:00, 20.81s/it]
Loading checkpoint shards: 100%|██████████| 4/4 [01:23<00:00, 17.57s/it]Loading checkpoint shards: 100%|██████████| 4/4 [01:24<00:00, 17.85s/it]Loading checkpoint shards: 100%|██████████| 4/4 [01:23<00:00, 20.82s/it]
Loading checkpoint shards: 100%|██████████| 4/4 [01:24<00:00, 21.06s/it]
Loading checkpoint shards: 100%|██████████| 4/4 [01:23<00:00, 17.57s/it]Loading checkpoint shards: 100%|██████████| 4/4 [01:23<00:00, 20.84s/it]
Loading checkpoint shards: 100%|██████████| 4/4 [01:23<00:00, 17.55s/it]Loading checkpoint shards: 100%|██████████| 4/4 [01:23<00:00, 20.80s/it]
Loading checkpoint shards: 100%|██████████| 4/4 [01:23<00:00, 17.58s/it]Loading checkpoint shards: 100%|██████████| 4/4 [01:23<00:00, 20.83s/it]
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
2024-06-03:15:09:14,009 INFO     [xhuggingface.py:314] Using 8 devices with data parallelism
Using the latest cached version of the dataset since gsm8k couldn't be found on the Hugging Face Hub
2024-06-03:15:09:14,261 WARNING  [load.py:1631] Using the latest cached version of the dataset since gsm8k couldn't be found on the Hugging Face Hub
Found the latest cached dataset configuration 'main' at /private/home/beidic/.cache/huggingface/datasets/gsm8k/main/0.0.0/e53f048856ff4f594e959d75785d2c2d37b678ee (last modified on Thu May 16 07:01:08 2024).
2024-06-03:15:09:14,264 WARNING  [cache.py:95] Found the latest cached dataset configuration 'main' at /private/home/beidic/.cache/huggingface/datasets/gsm8k/main/0.0.0/e53f048856ff4f594e959d75785d2c2d37b678ee (last modified on Thu May 16 07:01:08 2024).
2024-06-03:15:09:14,523 INFO     [task.py:395] Building contexts for gsm8k on rank 0...
  0%|          | 0/165 [00:00<?, ?it/s] 10%|▉         | 16/165 [00:00<00:00, 154.61it/s] 19%|█▉        | 32/165 [00:00<00:00, 156.26it/s] 29%|██▉       | 48/165 [00:00<00:00, 156.22it/s]Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
 39%|███▉      | 64/165 [00:00<00:00, 156.18it/s] 48%|████▊     | 80/165 [00:00<00:00, 156.07it/s] 58%|█████▊    | 96/165 [00:00<00:00, 156.02it/s]Using the latest cached version of the dataset since gsm8k couldn't be found on the Hugging Face Hub
2024-06-03:15:09:15,237 WARNING  [load.py:1631] Using the latest cached version of the dataset since gsm8k couldn't be found on the Hugging Face Hub
Found the latest cached dataset configuration 'main' at /private/home/beidic/.cache/huggingface/datasets/gsm8k/main/0.0.0/e53f048856ff4f594e959d75785d2c2d37b678ee (last modified on Thu May 16 07:01:08 2024).
2024-06-03:15:09:15,238 WARNING  [cache.py:95] Found the latest cached dataset configuration 'main' at /private/home/beidic/.cache/huggingface/datasets/gsm8k/main/0.0.0/e53f048856ff4f594e959d75785d2c2d37b678ee (last modified on Thu May 16 07:01:08 2024).
 68%|██████▊   | 112/165 [00:00<00:00, 155.31it/s] 78%|███████▊  | 128/165 [00:00<00:00, 155.57it/s]2024-06-03:15:09:15,431 INFO     [task.py:395] Building contexts for gsm8k on rank 1...
  0%|          | 0/165 [00:00<?, ?it/s] 87%|████████▋ | 144/165 [00:00<00:00, 155.34it/s] 13%|█▎        | 21/165 [00:00<00:00, 205.36it/s] 97%|█████████▋| 160/165 [00:01<00:00, 155.66it/s]100%|██████████| 165/165 [00:01<00:00, 155.73it/s]
 25%|██▌       | 42/165 [00:00<00:00, 207.19it/s] 38%|███▊      | 63/165 [00:00<00:00, 207.31it/s] 51%|█████     | 84/165 [00:00<00:00, 207.49it/s] 64%|██████▎   | 105/165 [00:00<00:00, 207.31it/s] 76%|███████▋  | 126/165 [00:00<00:00, 207.33it/s] 89%|████████▉ | 147/165 [00:00<00:00, 205.37it/s]100%|██████████| 165/165 [00:00<00:00, 206.22it/s]
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
Using the latest cached version of the dataset since gsm8k couldn't be found on the Hugging Face Hub
2024-06-03:15:09:30,122 WARNING  [load.py:1631] Using the latest cached version of the dataset since gsm8k couldn't be found on the Hugging Face Hub
Found the latest cached dataset configuration 'main' at /private/home/beidic/.cache/huggingface/datasets/gsm8k/main/0.0.0/e53f048856ff4f594e959d75785d2c2d37b678ee (last modified on Thu May 16 07:01:08 2024).
2024-06-03:15:09:30,124 WARNING  [cache.py:95] Found the latest cached dataset configuration 'main' at /private/home/beidic/.cache/huggingface/datasets/gsm8k/main/0.0.0/e53f048856ff4f594e959d75785d2c2d37b678ee (last modified on Thu May 16 07:01:08 2024).
2024-06-03:15:09:30,294 INFO     [task.py:395] Building contexts for gsm8k on rank 4...
  0%|          | 0/165 [00:00<?, ?it/s] 12%|█▏        | 20/165 [00:00<00:00, 197.05it/s] 24%|██▍       | 40/165 [00:00<00:00, 197.41it/s] 36%|███▋      | 60/165 [00:00<00:00, 197.07it/s] 48%|████▊     | 80/165 [00:00<00:00, 197.33it/s] 61%|██████    | 100/165 [00:00<00:00, 197.45it/s] 73%|███████▎  | 120/165 [00:00<00:00, 197.47it/s] 85%|████████▍ | 140/165 [00:00<00:00, 197.67it/s] 97%|█████████▋| 160/165 [00:00<00:00, 197.75it/s]100%|██████████| 165/165 [00:00<00:00, 197.47it/s]
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
Using the latest cached version of the dataset since gsm8k couldn't be found on the Hugging Face Hub
2024-06-03:15:09:36,783 WARNING  [load.py:1631] Using the latest cached version of the dataset since gsm8k couldn't be found on the Hugging Face Hub
Found the latest cached dataset configuration 'main' at /private/home/beidic/.cache/huggingface/datasets/gsm8k/main/0.0.0/e53f048856ff4f594e959d75785d2c2d37b678ee (last modified on Thu May 16 07:01:08 2024).
2024-06-03:15:09:36,785 WARNING  [cache.py:95] Found the latest cached dataset configuration 'main' at /private/home/beidic/.cache/huggingface/datasets/gsm8k/main/0.0.0/e53f048856ff4f594e959d75785d2c2d37b678ee (last modified on Thu May 16 07:01:08 2024).
2024-06-03:15:09:37,027 INFO     [task.py:395] Building contexts for gsm8k on rank 3...
  0%|          | 0/165 [00:00<?, ?it/s]  9%|▉         | 15/165 [00:00<00:01, 149.40it/s] 19%|█▉        | 31/165 [00:00<00:00, 149.95it/s] 28%|██▊       | 47/165 [00:00<00:00, 150.02it/s] 38%|███▊      | 63/165 [00:00<00:00, 149.95it/s] 48%|████▊     | 79/165 [00:00<00:00, 150.01it/s] 58%|█████▊    | 95/165 [00:00<00:00, 150.27it/s] 67%|██████▋   | 111/165 [00:00<00:00, 150.28it/s] 77%|███████▋  | 127/165 [00:00<00:00, 150.20it/s] 87%|████████▋ | 143/165 [00:00<00:00, 150.07it/s] 96%|█████████▋| 159/165 [00:01<00:00, 150.18it/s]100%|██████████| 165/165 [00:01<00:00, 150.08it/s]
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
Using the latest cached version of the dataset since gsm8k couldn't be found on the Hugging Face Hub
2024-06-03:15:09:40,183 WARNING  [load.py:1631] Using the latest cached version of the dataset since gsm8k couldn't be found on the Hugging Face Hub
Found the latest cached dataset configuration 'main' at /private/home/beidic/.cache/huggingface/datasets/gsm8k/main/0.0.0/e53f048856ff4f594e959d75785d2c2d37b678ee (last modified on Thu May 16 07:01:08 2024).
2024-06-03:15:09:40,185 WARNING  [cache.py:95] Found the latest cached dataset configuration 'main' at /private/home/beidic/.cache/huggingface/datasets/gsm8k/main/0.0.0/e53f048856ff4f594e959d75785d2c2d37b678ee (last modified on Thu May 16 07:01:08 2024).
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
Using the latest cached version of the dataset since gsm8k couldn't be found on the Hugging Face Hub
2024-06-03:15:09:40,302 WARNING  [load.py:1631] Using the latest cached version of the dataset since gsm8k couldn't be found on the Hugging Face Hub
Found the latest cached dataset configuration 'main' at /private/home/beidic/.cache/huggingface/datasets/gsm8k/main/0.0.0/e53f048856ff4f594e959d75785d2c2d37b678ee (last modified on Thu May 16 07:01:08 2024).
2024-06-03:15:09:40,304 WARNING  [cache.py:95] Found the latest cached dataset configuration 'main' at /private/home/beidic/.cache/huggingface/datasets/gsm8k/main/0.0.0/e53f048856ff4f594e959d75785d2c2d37b678ee (last modified on Thu May 16 07:01:08 2024).
2024-06-03:15:09:40,369 INFO     [task.py:395] Building contexts for gsm8k on rank 5...
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
  0%|          | 0/165 [00:00<?, ?it/s]Using the latest cached version of the dataset since gsm8k couldn't be found on the Hugging Face Hub
2024-06-03:15:09:40,454 WARNING  [load.py:1631] Using the latest cached version of the dataset since gsm8k couldn't be found on the Hugging Face Hub
Found the latest cached dataset configuration 'main' at /private/home/beidic/.cache/huggingface/datasets/gsm8k/main/0.0.0/e53f048856ff4f594e959d75785d2c2d37b678ee (last modified on Thu May 16 07:01:08 2024).
2024-06-03:15:09:40,456 WARNING  [cache.py:95] Found the latest cached dataset configuration 'main' at /private/home/beidic/.cache/huggingface/datasets/gsm8k/main/0.0.0/e53f048856ff4f594e959d75785d2c2d37b678ee (last modified on Thu May 16 07:01:08 2024).
2024-06-03:15:09:40,493 INFO     [task.py:395] Building contexts for gsm8k on rank 6...
 12%|█▏        | 20/165 [00:00<00:00, 193.99it/s]  0%|          | 0/165 [00:00<?, ?it/s] 25%|██▍       | 41/165 [00:00<00:00, 201.74it/s] 12%|█▏        | 20/165 [00:00<00:00, 194.01it/s]Using the latest cached version of the dataset since gsm8k couldn't be found on the Hugging Face Hub
2024-06-03:15:09:40,633 WARNING  [load.py:1631] Using the latest cached version of the dataset since gsm8k couldn't be found on the Hugging Face Hub
Found the latest cached dataset configuration 'main' at /private/home/beidic/.cache/huggingface/datasets/gsm8k/main/0.0.0/e53f048856ff4f594e959d75785d2c2d37b678ee (last modified on Thu May 16 07:01:08 2024).
2024-06-03:15:09:40,635 WARNING  [cache.py:95] Found the latest cached dataset configuration 'main' at /private/home/beidic/.cache/huggingface/datasets/gsm8k/main/0.0.0/e53f048856ff4f594e959d75785d2c2d37b678ee (last modified on Thu May 16 07:01:08 2024).
 38%|███▊      | 62/165 [00:00<00:00, 200.21it/s] 24%|██▍       | 40/165 [00:00<00:00, 164.52it/s]2024-06-03:15:09:40,760 INFO     [task.py:395] Building contexts for gsm8k on rank 2...
  0%|          | 0/165 [00:00<?, ?it/s] 50%|█████     | 83/165 [00:00<00:00, 198.01it/s] 35%|███▍      | 57/165 [00:00<00:00, 148.83it/s]  9%|▉         | 15/165 [00:00<00:01, 147.37it/s] 62%|██████▏   | 103/165 [00:00<00:00, 195.78it/s]2024-06-03:15:09:40,944 INFO     [task.py:395] Building contexts for gsm8k on rank 7...
  0%|          | 0/164 [00:00<?, ?it/s] 44%|████▍     | 73/165 [00:00<00:00, 143.44it/s] 18%|█▊        | 30/165 [00:00<00:00, 138.81it/s] 75%|███████▍  | 123/165 [00:00<00:00, 192.36it/s]  9%|▊         | 14/164 [00:00<00:01, 138.03it/s] 53%|█████▎    | 88/165 [00:00<00:00, 141.64it/s] 27%|██▋       | 45/165 [00:00<00:00, 142.05it/s] 87%|████████▋ | 143/165 [00:00<00:00, 192.02it/s] 17%|█▋        | 28/164 [00:00<00:00, 138.30it/s] 62%|██████▏   | 103/165 [00:00<00:00, 140.19it/s] 36%|███▋      | 60/165 [00:00<00:00, 143.45it/s] 99%|█████████▉| 163/165 [00:00<00:00, 191.83it/s]100%|██████████| 165/165 [00:00<00:00, 194.27it/s]
 26%|██▌       | 42/164 [00:00<00:00, 138.78it/s] 72%|███████▏  | 118/165 [00:00<00:00, 139.57it/s] 45%|████▌     | 75/165 [00:00<00:00, 144.72it/s] 34%|███▍      | 56/164 [00:00<00:00, 138.51it/s] 80%|████████  | 132/165 [00:00<00:00, 139.02it/s] 55%|█████▍    | 90/165 [00:00<00:00, 145.43it/s] 43%|████▎     | 70/164 [00:00<00:00, 138.74it/s] 88%|████████▊ | 146/165 [00:01<00:00, 138.62it/s] 64%|██████▎   | 105/165 [00:00<00:00, 145.73it/s] 51%|█████     | 84/164 [00:00<00:00, 139.05it/s] 97%|█████████▋| 160/165 [00:01<00:00, 138.96it/s] 73%|███████▎  | 120/165 [00:00<00:00, 146.10it/s]100%|██████████| 165/165 [00:01<00:00, 143.30it/s]
 60%|██████    | 99/164 [00:00<00:00, 141.66it/s] 82%|████████▏ | 135/165 [00:00<00:00, 146.43it/s] 70%|██████▉   | 114/164 [00:00<00:00, 139.35it/s] 91%|█████████ | 150/165 [00:01<00:00, 146.07it/s] 78%|███████▊  | 128/164 [00:00<00:00, 131.05it/s]100%|██████████| 165/165 [00:01<00:00, 142.61it/s]100%|██████████| 165/165 [00:01<00:00, 144.12it/s]
 88%|████████▊ | 144/164 [00:01<00:00, 137.26it/s] 96%|█████████▋| 158/164 [00:01<00:00, 136.57it/s]100%|██████████| 164/164 [00:01<00:00, 137.39it/s]
2024-06-03:15:09:45,837 INFO     [xevaluator.py:395] Running generate_until requests
2024-06-03:15:09:45,837 INFO     [xevaluator.py:395] Running generate_until requests
2024-06-03:15:09:45,837 INFO     [xevaluator.py:395] Running generate_until requests
2024-06-03:15:09:45,837 INFO     [xevaluator.py:395] Running generate_until requests
2024-06-03:15:09:45,837 INFO     [xevaluator.py:395] Running generate_until requests
2024-06-03:15:09:45,838 INFO     [xevaluator.py:395] Running generate_until requests
2024-06-03:15:09:45,838 INFO     [xevaluator.py:395] Running generate_until requests
Running generate_until requests:   0%|          | 0/165 [00:00<?, ?it/s]2024-06-03:15:09:45,839 INFO     [xevaluator.py:395] Running generate_until requests
Running generate_until requests:   1%|          | 1/165 [00:15<43:12, 15.81s/it]Running generate_until requests:   1%|          | 2/165 [00:22<28:20, 10.43s/it]Running generate_until requests:   2%|▏         | 3/165 [00:36<32:43, 12.12s/it]Running generate_until requests:   2%|▏         | 4/165 [00:46<30:00, 11.18s/it]Running generate_until requests:   3%|▎         | 5/165 [00:50<23:29,  8.81s/it]Running generate_until requests:   4%|▎         | 6/165 [01:01<24:38,  9.30s/it]Running generate_until requests:   4%|▍         | 7/165 [01:07<21:41,  8.24s/it]Running generate_until requests:   5%|▍         | 8/165 [01:14<20:36,  7.87s/it]Running generate_until requests:   5%|▌         | 9/165 [01:28<25:13,  9.70s/it]Running generate_until requests:   6%|▌         | 10/165 [01:33<21:39,  8.38s/it]Running generate_until requests:   7%|▋         | 11/165 [01:39<19:40,  7.67s/it]Running generate_until requests:   7%|▋         | 12/165 [01:53<24:09,  9.48s/it]Running generate_until requests:   8%|▊         | 13/165 [02:05<26:33, 10.49s/it]Running generate_until requests:   8%|▊         | 14/165 [02:11<22:30,  8.95s/it]Running generate_until requests:   9%|▉         | 15/165 [02:19<22:04,  8.83s/it]Running generate_until requests:  10%|▉         | 16/165 [02:26<20:25,  8.22s/it]Running generate_until requests:  10%|█         | 17/165 [02:32<18:28,  7.49s/it]Running generate_until requests:  11%|█         | 18/165 [02:39<17:56,  7.32s/it]Running generate_until requests:  12%|█▏        | 19/165 [02:53<22:27,  9.23s/it]Running generate_until requests:  12%|█▏        | 20/165 [02:58<19:22,  8.01s/it]Running generate_until requests:  13%|█▎        | 21/165 [03:11<22:59,  9.58s/it]Running generate_until requests:  13%|█▎        | 22/165 [03:16<19:44,  8.28s/it]Running generate_until requests:  14%|█▍        | 23/165 [03:24<18:59,  8.02s/it]Running generate_until requests:  15%|█▍        | 24/165 [03:33<19:45,  8.41s/it]Running generate_until requests:  15%|█▌        | 25/165 [03:39<17:56,  7.69s/it]Running generate_until requests:  16%|█▌        | 26/165 [03:45<16:42,  7.22s/it]Running generate_until requests:  16%|█▋        | 27/165 [03:53<16:44,  7.28s/it]Running generate_until requests:  17%|█▋        | 28/165 [03:57<14:54,  6.53s/it]Running generate_until requests:  18%|█▊        | 29/165 [04:06<15:55,  7.02s/it]Running generate_until requests:  18%|█▊        | 30/165 [04:11<14:56,  6.64s/it]Running generate_until requests:  19%|█▉        | 31/165 [04:18<15:06,  6.77s/it]Running generate_until requests:  19%|█▉        | 32/165 [04:32<19:45,  8.91s/it]Running generate_until requests:  20%|██        | 33/165 [04:37<16:49,  7.65s/it]Running generate_until requests:  21%|██        | 34/165 [04:48<19:09,  8.78s/it]Running generate_until requests:  21%|██        | 35/165 [05:02<22:26, 10.36s/it]Running generate_until requests:  22%|██▏       | 36/165 [05:10<20:34,  9.57s/it]Running generate_until requests:  22%|██▏       | 37/165 [05:16<17:59,  8.43s/it]Running generate_until requests:  23%|██▎       | 38/165 [05:20<15:06,  7.14s/it]Running generate_until requests:  24%|██▎       | 39/165 [05:34<19:05,  9.09s/it]Running generate_until requests:  24%|██▍       | 40/165 [05:42<18:09,  8.71s/it]Running generate_until requests:  25%|██▍       | 41/165 [05:47<15:52,  7.68s/it]Running generate_until requests:  25%|██▌       | 42/165 [05:54<15:37,  7.62s/it]Running generate_until requests:  26%|██▌       | 43/165 [06:01<15:01,  7.39s/it]Running generate_until requests:  27%|██▋       | 44/165 [06:08<14:39,  7.27s/it]Running generate_until requests:  27%|██▋       | 45/165 [06:22<18:30,  9.25s/it]Running generate_until requests:  28%|██▊       | 46/165 [06:28<16:30,  8.33s/it]Running generate_until requests:  28%|██▊       | 47/165 [06:33<14:22,  7.31s/it]Running generate_until requests:  29%|██▉       | 48/165 [06:41<14:48,  7.60s/it]Running generate_until requests:  30%|██▉       | 49/165 [06:48<13:58,  7.23s/it]Running generate_until requests:  30%|███       | 50/165 [07:01<17:27,  9.11s/it]Running generate_until requests:  31%|███       | 51/165 [07:07<15:39,  8.24s/it]Running generate_until requests:  32%|███▏      | 52/165 [07:10<12:20,  6.55s/it]Running generate_until requests:  32%|███▏      | 53/165 [07:16<12:06,  6.48s/it]Running generate_until requests:  33%|███▎      | 54/165 [07:30<15:46,  8.53s/it]Running generate_until requests:  33%|███▎      | 55/165 [07:34<13:23,  7.31s/it]Running generate_until requests:  34%|███▍      | 56/165 [07:39<12:00,  6.61s/it]Running generate_until requests:  35%|███▍      | 57/165 [07:45<11:42,  6.51s/it]Running generate_until requests:  35%|███▌      | 58/165 [07:50<10:36,  5.95s/it]Running generate_until requests:  36%|███▌      | 59/165 [08:03<14:27,  8.19s/it]Running generate_until requests:  36%|███▋      | 60/165 [08:07<11:55,  6.82s/it]Running generate_until requests:  37%|███▋      | 61/165 [08:14<12:04,  6.97s/it]Running generate_until requests:  38%|███▊      | 62/165 [08:20<11:19,  6.59s/it]Running generate_until requests:  38%|███▊      | 63/165 [08:26<10:40,  6.28s/it]Running generate_until requests:  39%|███▉      | 64/165 [08:30<09:41,  5.75s/it]Running generate_until requests:  39%|███▉      | 65/165 [08:44<13:39,  8.19s/it]Running generate_until requests:  40%|████      | 66/165 [08:49<11:45,  7.12s/it]Running generate_until requests:  41%|████      | 67/165 [08:55<11:20,  6.95s/it]Running generate_until requests:  41%|████      | 68/165 [09:01<10:50,  6.70s/it]Running generate_until requests:  42%|████▏     | 69/165 [09:09<10:58,  6.86s/it]Running generate_until requests:  42%|████▏     | 70/165 [09:13<09:44,  6.15s/it]Running generate_until requests:  43%|████▎     | 71/165 [09:27<13:16,  8.47s/it]Running generate_until requests:  44%|████▎     | 72/165 [09:41<15:29,  9.99s/it]Running generate_until requests:  44%|████▍     | 73/165 [09:46<13:25,  8.75s/it]Running generate_until requests:  45%|████▍     | 74/165 [09:57<14:17,  9.42s/it]Running generate_until requests:  45%|████▌     | 75/165 [10:06<13:50,  9.23s/it]Running generate_until requests:  46%|████▌     | 76/165 [10:11<11:56,  8.06s/it]Running generate_until requests:  47%|████▋     | 77/165 [10:15<09:52,  6.73s/it]Running generate_until requests:  47%|████▋     | 78/165 [10:29<12:53,  8.89s/it]Running generate_until requests:  48%|████▊     | 79/165 [10:43<14:53, 10.39s/it]Running generate_until requests:  48%|████▊     | 80/165 [10:49<13:00,  9.18s/it]Running generate_until requests:  49%|████▉     | 81/165 [10:56<11:48,  8.43s/it]Running generate_until requests:  50%|████▉     | 82/165 [11:03<10:54,  7.88s/it]Running generate_until requests:  50%|█████     | 83/165 [11:09<10:05,  7.38s/it]Running generate_until requests:  51%|█████     | 84/165 [11:21<12:04,  8.95s/it]Running generate_until requests:  52%|█████▏    | 85/165 [11:26<10:08,  7.61s/it]Running generate_until requests:  52%|█████▏    | 86/165 [11:30<08:38,  6.57s/it]Running generate_until requests:  53%|█████▎    | 87/165 [11:43<11:13,  8.63s/it]Running generate_until requests:  53%|█████▎    | 88/165 [11:47<09:13,  7.18s/it]Running generate_until requests:  54%|█████▍    | 89/165 [12:01<11:36,  9.16s/it]Running generate_until requests:  55%|█████▍    | 90/165 [12:08<10:32,  8.43s/it]Running generate_until requests:  55%|█████▌    | 91/165 [12:11<08:34,  6.95s/it]Running generate_until requests:  56%|█████▌    | 92/165 [12:25<10:52,  8.93s/it]Running generate_until requests:  56%|█████▋    | 93/165 [12:30<09:32,  7.95s/it]Running generate_until requests:  57%|█████▋    | 94/165 [12:38<09:13,  7.79s/it]Running generate_until requests:  58%|█████▊    | 95/165 [12:41<07:29,  6.43s/it]Running generate_until requests:  58%|█████▊    | 96/165 [12:45<06:21,  5.53s/it]Running generate_until requests:  59%|█████▉    | 97/165 [12:48<05:33,  4.90s/it]Running generate_until requests:  59%|█████▉    | 98/165 [12:55<06:06,  5.47s/it]Running generate_until requests:  60%|██████    | 99/165 [12:59<05:32,  5.04s/it]Running generate_until requests:  61%|██████    | 100/165 [13:05<05:53,  5.44s/it]Running generate_until requests:  61%|██████    | 101/165 [13:10<05:29,  5.15s/it]Running generate_until requests:  62%|██████▏   | 102/165 [13:23<08:01,  7.64s/it]Running generate_until requests:  62%|██████▏   | 103/165 [13:37<09:49,  9.50s/it]Running generate_until requests:  63%|██████▎   | 104/165 [13:42<08:19,  8.19s/it]Running generate_until requests:  64%|██████▎   | 105/165 [13:48<07:29,  7.49s/it]Running generate_until requests:  64%|██████▍   | 106/165 [13:52<06:19,  6.44s/it]Running generate_until requests:  65%|██████▍   | 107/165 [13:57<05:52,  6.08s/it]Running generate_until requests:  65%|██████▌   | 108/165 [14:02<05:25,  5.71s/it]Running generate_until requests:  66%|██████▌   | 109/165 [14:07<04:59,  5.35s/it]Running generate_until requests:  67%|██████▋   | 110/165 [14:14<05:30,  6.02s/it]Running generate_until requests:  67%|██████▋   | 111/165 [14:21<05:46,  6.42s/it]Running generate_until requests:  68%|██████▊   | 112/165 [14:26<05:04,  5.75s/it]Running generate_until requests:  68%|██████▊   | 113/165 [14:31<04:56,  5.70s/it]Running generate_until requests:  69%|██████▉   | 114/165 [14:36<04:28,  5.27s/it]Running generate_until requests:  70%|██████▉   | 115/165 [14:44<05:10,  6.20s/it]Running generate_until requests:  70%|███████   | 116/165 [14:49<04:41,  5.74s/it]Running generate_until requests:  71%|███████   | 117/165 [14:55<04:49,  6.03s/it]Running generate_until requests:  72%|███████▏  | 118/165 [14:59<04:16,  5.45s/it]Running generate_until requests:  72%|███████▏  | 119/165 [15:05<04:10,  5.45s/it]Running generate_until requests:  73%|███████▎  | 120/165 [15:10<04:02,  5.39s/it]Running generate_until requests:  73%|███████▎  | 121/165 [15:14<03:41,  5.03s/it]Running generate_until requests:  74%|███████▍  | 122/165 [15:23<04:26,  6.20s/it]Running generate_until requests:  75%|███████▍  | 123/165 [15:32<04:53,  6.98s/it]Running generate_until requests:  75%|███████▌  | 124/165 [15:35<04:02,  5.90s/it]Running generate_until requests:  76%|███████▌  | 125/165 [15:49<05:27,  8.18s/it]Running generate_until requests:  76%|███████▋  | 126/165 [15:53<04:31,  6.97s/it]Running generate_until requests:  77%|███████▋  | 127/165 [15:57<03:50,  6.08s/it]Running generate_until requests:  78%|███████▊  | 128/165 [16:01<03:25,  5.56s/it]Running generate_until requests:  78%|███████▊  | 129/165 [16:07<03:18,  5.51s/it]Running generate_until requests:  79%|███████▉  | 130/165 [16:13<03:16,  5.61s/it]Running generate_until requests:  79%|███████▉  | 131/165 [16:26<04:35,  8.09s/it]Running generate_until requests:  80%|████████  | 132/165 [16:40<05:21,  9.75s/it]Running generate_until requests:  81%|████████  | 133/165 [16:44<04:18,  8.08s/it]Running generate_until requests:  81%|████████  | 134/165 [16:49<03:38,  7.04s/it]Running generate_until requests:  82%|████████▏ | 135/165 [16:52<02:55,  5.84s/it]Running generate_until requests:  82%|████████▏ | 136/165 [16:56<02:33,  5.30s/it]Running generate_until requests:  83%|████████▎ | 137/165 [17:00<02:17,  4.92s/it]Running generate_until requests:  84%|████████▎ | 138/165 [17:06<02:18,  5.14s/it]Running generate_until requests:  84%|████████▍ | 139/165 [17:10<02:03,  4.76s/it]Running generate_until requests:  85%|████████▍ | 140/165 [17:14<01:54,  4.60s/it]Running generate_until requests:  85%|████████▌ | 141/165 [17:19<01:56,  4.87s/it]Running generate_until requests:  86%|████████▌ | 142/165 [17:27<02:09,  5.63s/it]Running generate_until requests:  87%|████████▋ | 143/165 [17:30<01:49,  4.98s/it]Running generate_until requests:  87%|████████▋ | 144/165 [17:37<01:56,  5.57s/it]Running generate_until requests:  88%|████████▊ | 145/165 [17:43<01:51,  5.57s/it]Running generate_until requests:  88%|████████▊ | 146/165 [17:46<01:32,  4.85s/it]Running generate_until requests:  89%|████████▉ | 147/165 [17:50<01:24,  4.70s/it]Running generate_until requests:  90%|████████▉ | 148/165 [17:55<01:21,  4.80s/it]Running generate_until requests:  90%|█████████ | 149/165 [18:02<01:26,  5.43s/it]Running generate_until requests:  91%|█████████ | 150/165 [18:06<01:16,  5.12s/it]Running generate_until requests:  92%|█████████▏| 151/165 [18:12<01:11,  5.11s/it]Running generate_until requests:  92%|█████████▏| 152/165 [18:15<00:58,  4.50s/it]Running generate_until requests:  93%|█████████▎| 153/165 [18:21<01:00,  5.03s/it]Running generate_until requests:  93%|█████████▎| 154/165 [18:32<01:15,  6.84s/it]Running generate_until requests:  94%|█████████▍| 155/165 [18:34<00:54,  5.45s/it]Running generate_until requests:  95%|█████████▍| 156/165 [18:37<00:41,  4.60s/it]Running generate_until requests:  95%|█████████▌| 157/165 [18:41<00:35,  4.46s/it]Running generate_until requests:  96%|█████████▌| 158/165 [18:44<00:29,  4.15s/it]Running generate_until requests:  96%|█████████▋| 159/165 [18:55<00:37,  6.22s/it]Running generate_until requests:  97%|█████████▋| 160/165 [18:59<00:27,  5.48s/it]Running generate_until requests:  98%|█████████▊| 161/165 [19:03<00:20,  5.12s/it]Running generate_until requests:  98%|█████████▊| 162/165 [19:15<00:20,  6.91s/it]Running generate_until requests:  99%|█████████▉| 163/165 [19:18<00:11,  5.91s/it]Running generate_until requests:  99%|█████████▉| 164/165 [19:21<00:04,  4.97s/it]Running generate_until requests: 100%|██████████| 165/165 [19:24<00:00,  4.45s/it]Running generate_until requests: 100%|██████████| 165/165 [19:24<00:00,  7.06s/it]
