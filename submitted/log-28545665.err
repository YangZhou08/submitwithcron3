Already on 'yangexp2'
wandb: Currently logged in as: stevenzhou0816100. Use `wandb login --relogin` to force relogin
Traceback (most recent call last):
  File "/private/home/beidic/.conda/envs/griffin/bin/huggingface-cli", line 8, in <module>
    sys.exit(main())
             ^^^^^^
  File "/private/home/beidic/.conda/envs/griffin/lib/python3.12/site-packages/huggingface_hub/commands/huggingface_cli.py", line 51, in main
    service.run()
  File "/private/home/beidic/.conda/envs/griffin/lib/python3.12/site-packages/huggingface_hub/commands/user.py", line 98, in run
    login(token=self.args.token, add_to_git_credential=self.args.add_to_git_credential)
  File "/private/home/beidic/.conda/envs/griffin/lib/python3.12/site-packages/huggingface_hub/_login.py", line 111, in login
    _login(token, add_to_git_credential=add_to_git_credential, write_permission=write_permission)
  File "/private/home/beidic/.conda/envs/griffin/lib/python3.12/site-packages/huggingface_hub/_login.py", line 307, in _login
    raise ValueError("Invalid token passed!")
ValueError: Invalid token passed!
The following values were not passed to `accelerate launch` and had defaults used instead:
		More than one GPU was found, enabling multi-GPU training.
		If this was unintended please pass in `--num_processes=1`.
	`--mixed_precision` was set to a value of `'no'`
	`--dynamo_backend` was set to a value of `'no'`
To avoid this warning pass in values for each of the problematic parameters or run `accelerate config`.
2024-06-03:11:21:10,437 INFO     [main.py:288] Verbosity set to INFO
2024-06-03:11:21:10,437 INFO     [main.py:288] Verbosity set to INFO
2024-06-03:11:21:10,437 INFO     [main.py:288] Verbosity set to INFO
2024-06-03:11:21:10,437 INFO     [main.py:288] Verbosity set to INFO
2024-06-03:11:21:10,437 INFO     [main.py:288] Verbosity set to INFO
2024-06-03:11:21:10,437 INFO     [main.py:288] Verbosity set to INFO
2024-06-03:11:21:10,437 INFO     [main.py:288] Verbosity set to INFO
2024-06-03:11:21:10,521 INFO     [main.py:288] Verbosity set to INFO
2024-06-03:11:21:16,319 INFO     [main.py:378] Selected Tasks: ['gsm8k']
2024-06-03:11:21:16,319 INFO     [main.py:378] Selected Tasks: ['gsm8k']
2024-06-03:11:21:16,322 INFO     [main.py:378] Selected Tasks: ['gsm8k']
2024-06-03:11:21:16,322 INFO     [main.py:378] Selected Tasks: ['gsm8k']
2024-06-03:11:21:16,329 INFO     [xevaluator.py:137] Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234
2024-06-03:11:21:16,329 INFO     [xevaluator.py:184] Initializing xhf model, with arguments: {'pretrained': 'meta-llama/Meta-Llama-3-8B-Instruct', 'griffin': True, 'check': True, 'kernel_size': 16, 'spr': 0.5, 'thr': 0.1}
2024-06-03:11:21:16,329 INFO     [xevaluator.py:137] Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234
2024-06-03:11:21:16,329 INFO     [xevaluator.py:137] Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234
2024-06-03:11:21:16,329 INFO     [xevaluator.py:137] Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234
2024-06-03:11:21:16,330 INFO     [xevaluator.py:184] Initializing xhf model, with arguments: {'pretrained': 'meta-llama/Meta-Llama-3-8B-Instruct', 'griffin': True, 'check': True, 'kernel_size': 16, 'spr': 0.5, 'thr': 0.1}
2024-06-03:11:21:16,330 INFO     [xevaluator.py:184] Initializing xhf model, with arguments: {'pretrained': 'meta-llama/Meta-Llama-3-8B-Instruct', 'griffin': True, 'check': True, 'kernel_size': 16, 'spr': 0.5, 'thr': 0.1}
2024-06-03:11:21:16,330 INFO     [xevaluator.py:184] Initializing xhf model, with arguments: {'pretrained': 'meta-llama/Meta-Llama-3-8B-Instruct', 'griffin': True, 'check': True, 'kernel_size': 16, 'spr': 0.5, 'thr': 0.1}
2024-06-03:11:21:17,019 INFO     [main.py:378] Selected Tasks: ['gsm8k']
2024-06-03:11:21:17,023 INFO     [xevaluator.py:137] Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234
2024-06-03:11:21:17,023 INFO     [xevaluator.py:184] Initializing xhf model, with arguments: {'pretrained': 'meta-llama/Meta-Llama-3-8B-Instruct', 'griffin': True, 'check': True, 'kernel_size': 16, 'spr': 0.5, 'thr': 0.1}
2024-06-03:11:21:17,259 INFO     [main.py:378] Selected Tasks: ['gsm8k']
2024-06-03:11:21:17,265 INFO     [xevaluator.py:137] Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234
2024-06-03:11:21:17,265 INFO     [xevaluator.py:184] Initializing xhf model, with arguments: {'pretrained': 'meta-llama/Meta-Llama-3-8B-Instruct', 'griffin': True, 'check': True, 'kernel_size': 16, 'spr': 0.5, 'thr': 0.1}
2024-06-03:11:21:17,312 INFO     [main.py:378] Selected Tasks: ['gsm8k']
2024-06-03:11:21:17,315 INFO     [xevaluator.py:137] Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234
2024-06-03:11:21:17,315 INFO     [xevaluator.py:184] Initializing xhf model, with arguments: {'pretrained': 'meta-llama/Meta-Llama-3-8B-Instruct', 'griffin': True, 'check': True, 'kernel_size': 16, 'spr': 0.5, 'thr': 0.1}
2024-06-03:11:21:17,344 INFO     [main.py:378] Selected Tasks: ['gsm8k']
2024-06-03:11:21:17,349 INFO     [xevaluator.py:137] Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234
2024-06-03:11:21:17,349 INFO     [xevaluator.py:184] Initializing xhf model, with arguments: {'pretrained': 'meta-llama/Meta-Llama-3-8B-Instruct', 'griffin': True, 'check': True, 'kernel_size': 16, 'spr': 0.5, 'thr': 0.1}
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:  25%|██▌       | 1/4 [00:27<01:21, 27.20s/it]Loading checkpoint shards:  25%|██▌       | 1/4 [00:28<01:25, 28.34s/it]Loading checkpoint shards:  25%|██▌       | 1/4 [00:28<01:24, 28.16s/it]Loading checkpoint shards:  25%|██▌       | 1/4 [00:28<01:25, 28.42s/it]Loading checkpoint shards:  25%|██▌       | 1/4 [00:27<01:22, 27.66s/it]Loading checkpoint shards:  25%|██▌       | 1/4 [00:28<01:25, 28.55s/it]Loading checkpoint shards:  25%|██▌       | 1/4 [00:28<01:25, 28.56s/it]Loading checkpoint shards:  25%|██▌       | 1/4 [00:27<01:22, 27.60s/it]Loading checkpoint shards:  50%|█████     | 2/4 [00:55<00:55, 27.81s/it]Loading checkpoint shards:  50%|█████     | 2/4 [00:56<00:56, 28.26s/it]Loading checkpoint shards:  50%|█████     | 2/4 [00:56<00:56, 28.25s/it]Loading checkpoint shards:  50%|█████     | 2/4 [00:55<00:56, 28.07s/it]Loading checkpoint shards:  50%|█████     | 2/4 [00:55<00:55, 27.91s/it]Loading checkpoint shards:  50%|█████     | 2/4 [00:56<00:56, 28.18s/it]Loading checkpoint shards:  50%|█████     | 2/4 [00:55<00:55, 27.95s/it]Loading checkpoint shards:  50%|█████     | 2/4 [00:56<00:56, 28.32s/it]Loading checkpoint shards:  75%|███████▌  | 3/4 [01:22<00:27, 27.30s/it]Loading checkpoint shards:  75%|███████▌  | 3/4 [01:23<00:27, 27.51s/it]Loading checkpoint shards:  75%|███████▌  | 3/4 [01:23<00:27, 27.54s/it]Loading checkpoint shards:  75%|███████▌  | 3/4 [01:23<00:27, 27.53s/it]Loading checkpoint shards:  75%|███████▌  | 3/4 [01:23<00:27, 27.49s/it]Loading checkpoint shards:  75%|███████▌  | 3/4 [01:22<00:27, 27.36s/it]Loading checkpoint shards:  75%|███████▌  | 3/4 [01:22<00:27, 27.34s/it]Loading checkpoint shards:  75%|███████▌  | 3/4 [01:22<00:27, 27.44s/it]Loading checkpoint shards: 100%|██████████| 4/4 [01:27<00:00, 18.63s/it]Loading checkpoint shards: 100%|██████████| 4/4 [01:27<00:00, 21.93s/it]
Loading checkpoint shards: 100%|██████████| 4/4 [01:28<00:00, 18.80s/it]Loading checkpoint shards: 100%|██████████| 4/4 [01:28<00:00, 22.15s/it]
Loading checkpoint shards: 100%|██████████| 4/4 [01:27<00:00, 18.74s/it]Loading checkpoint shards: 100%|██████████| 4/4 [01:27<00:00, 21.99s/it]
Loading checkpoint shards: 100%|██████████| 4/4 [01:28<00:00, 18.82s/it]Loading checkpoint shards: 100%|██████████| 4/4 [01:28<00:00, 22.17s/it]
Loading checkpoint shards: 100%|██████████| 4/4 [01:27<00:00, 18.70s/it]Loading checkpoint shards: 100%|██████████| 4/4 [01:28<00:00, 18.79s/it]Loading checkpoint shards: 100%|██████████| 4/4 [01:27<00:00, 21.96s/it]
Loading checkpoint shards: 100%|██████████| 4/4 [01:28<00:00, 22.12s/it]
Loading checkpoint shards: 100%|██████████| 4/4 [01:28<00:00, 18.85s/it]Loading checkpoint shards: 100%|██████████| 4/4 [01:28<00:00, 19.01s/it]Loading checkpoint shards: 100%|██████████| 4/4 [01:28<00:00, 22.21s/it]
Loading checkpoint shards: 100%|██████████| 4/4 [01:28<00:00, 22.21s/it]
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
2024-06-03:11:23:21,714 INFO     [xhuggingface.py:314] Using 8 devices with data parallelism
Using the latest cached version of the dataset since gsm8k couldn't be found on the Hugging Face Hub
2024-06-03:11:23:21,957 WARNING  [load.py:1631] Using the latest cached version of the dataset since gsm8k couldn't be found on the Hugging Face Hub
Found the latest cached dataset configuration 'main' at /private/home/beidic/.cache/huggingface/datasets/gsm8k/main/0.0.0/e53f048856ff4f594e959d75785d2c2d37b678ee (last modified on Thu May 16 07:01:08 2024).
2024-06-03:11:23:21,960 WARNING  [cache.py:95] Found the latest cached dataset configuration 'main' at /private/home/beidic/.cache/huggingface/datasets/gsm8k/main/0.0.0/e53f048856ff4f594e959d75785d2c2d37b678ee (last modified on Thu May 16 07:01:08 2024).
2024-06-03:11:23:22,346 INFO     [task.py:395] Building contexts for gsm8k on rank 0...
  0%|          | 0/165 [00:00<?, ?it/s]  9%|▉         | 15/165 [00:00<00:01, 145.93it/s] 18%|█▊        | 30/165 [00:00<00:00, 146.39it/s] 27%|██▋       | 45/165 [00:00<00:00, 146.60it/s] 36%|███▋      | 60/165 [00:00<00:00, 146.76it/s] 45%|████▌     | 75/165 [00:00<00:00, 146.82it/s] 55%|█████▍    | 90/165 [00:00<00:00, 146.93it/s] 64%|██████▎   | 105/165 [00:00<00:00, 146.92it/s] 73%|███████▎  | 120/165 [00:00<00:00, 146.60it/s] 82%|████████▏ | 135/165 [00:00<00:00, 146.58it/s] 91%|█████████ | 150/165 [00:01<00:00, 146.54it/s]100%|██████████| 165/165 [00:01<00:00, 146.64it/s]100%|██████████| 165/165 [00:01<00:00, 146.63it/s]
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
Using the latest cached version of the dataset since gsm8k couldn't be found on the Hugging Face Hub
2024-06-03:11:23:24,816 WARNING  [load.py:1631] Using the latest cached version of the dataset since gsm8k couldn't be found on the Hugging Face Hub
Found the latest cached dataset configuration 'main' at /private/home/beidic/.cache/huggingface/datasets/gsm8k/main/0.0.0/e53f048856ff4f594e959d75785d2c2d37b678ee (last modified on Thu May 16 07:01:08 2024).
2024-06-03:11:23:24,818 WARNING  [cache.py:95] Found the latest cached dataset configuration 'main' at /private/home/beidic/.cache/huggingface/datasets/gsm8k/main/0.0.0/e53f048856ff4f594e959d75785d2c2d37b678ee (last modified on Thu May 16 07:01:08 2024).
2024-06-03:11:23:24,984 INFO     [task.py:395] Building contexts for gsm8k on rank 4...
  0%|          | 0/165 [00:00<?, ?it/s] 13%|█▎        | 21/165 [00:00<00:00, 203.42it/s] 25%|██▌       | 42/165 [00:00<00:00, 204.50it/s] 38%|███▊      | 63/165 [00:00<00:00, 205.31it/s] 51%|█████     | 84/165 [00:00<00:00, 206.36it/s] 64%|██████▎   | 105/165 [00:00<00:00, 206.61it/s] 76%|███████▋  | 126/165 [00:00<00:00, 201.49it/s] 89%|████████▉ | 147/165 [00:00<00:00, 198.66it/s]100%|██████████| 165/165 [00:00<00:00, 200.33it/s]
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
Using the latest cached version of the dataset since gsm8k couldn't be found on the Hugging Face Hub
2024-06-03:11:23:40,596 WARNING  [load.py:1631] Using the latest cached version of the dataset since gsm8k couldn't be found on the Hugging Face Hub
Found the latest cached dataset configuration 'main' at /private/home/beidic/.cache/huggingface/datasets/gsm8k/main/0.0.0/e53f048856ff4f594e959d75785d2c2d37b678ee (last modified on Thu May 16 07:01:08 2024).
2024-06-03:11:23:40,598 WARNING  [cache.py:95] Found the latest cached dataset configuration 'main' at /private/home/beidic/.cache/huggingface/datasets/gsm8k/main/0.0.0/e53f048856ff4f594e959d75785d2c2d37b678ee (last modified on Thu May 16 07:01:08 2024).
2024-06-03:11:23:40,842 INFO     [task.py:395] Building contexts for gsm8k on rank 2...
  0%|          | 0/165 [00:00<?, ?it/s]  9%|▉         | 15/165 [00:00<00:01, 142.23it/s] 18%|█▊        | 30/165 [00:00<00:00, 142.71it/s] 27%|██▋       | 45/165 [00:00<00:00, 143.05it/s] 36%|███▋      | 60/165 [00:00<00:00, 143.26it/s] 45%|████▌     | 75/165 [00:00<00:00, 143.15it/s] 55%|█████▍    | 90/165 [00:00<00:00, 143.31it/s] 64%|██████▎   | 105/165 [00:00<00:00, 141.81it/s] 73%|███████▎  | 120/165 [00:00<00:00, 142.15it/s] 82%|████████▏ | 135/165 [00:00<00:00, 142.53it/s] 91%|█████████ | 150/165 [00:01<00:00, 142.67it/s]100%|██████████| 165/165 [00:01<00:00, 142.88it/s]100%|██████████| 165/165 [00:01<00:00, 142.71it/s]
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
Using the latest cached version of the dataset since gsm8k couldn't be found on the Hugging Face Hub
2024-06-03:11:23:47,817 WARNING  [load.py:1631] Using the latest cached version of the dataset since gsm8k couldn't be found on the Hugging Face Hub
Found the latest cached dataset configuration 'main' at /private/home/beidic/.cache/huggingface/datasets/gsm8k/main/0.0.0/e53f048856ff4f594e959d75785d2c2d37b678ee (last modified on Thu May 16 07:01:08 2024).
2024-06-03:11:23:47,819 WARNING  [cache.py:95] Found the latest cached dataset configuration 'main' at /private/home/beidic/.cache/huggingface/datasets/gsm8k/main/0.0.0/e53f048856ff4f594e959d75785d2c2d37b678ee (last modified on Thu May 16 07:01:08 2024).
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
2024-06-03:11:23:48,068 INFO     [task.py:395] Building contexts for gsm8k on rank 6...
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
  0%|          | 0/165 [00:00<?, ?it/s]  9%|▉         | 15/165 [00:00<00:01, 144.00it/s]Using the latest cached version of the dataset since gsm8k couldn't be found on the Hugging Face Hub
2024-06-03:11:23:48,212 WARNING  [load.py:1631] Using the latest cached version of the dataset since gsm8k couldn't be found on the Hugging Face Hub
Found the latest cached dataset configuration 'main' at /private/home/beidic/.cache/huggingface/datasets/gsm8k/main/0.0.0/e53f048856ff4f594e959d75785d2c2d37b678ee (last modified on Thu May 16 07:01:08 2024).
2024-06-03:11:23:48,214 WARNING  [cache.py:95] Found the latest cached dataset configuration 'main' at /private/home/beidic/.cache/huggingface/datasets/gsm8k/main/0.0.0/e53f048856ff4f594e959d75785d2c2d37b678ee (last modified on Thu May 16 07:01:08 2024).
 18%|█▊        | 30/165 [00:00<00:00, 143.93it/s]Using the latest cached version of the dataset since gsm8k couldn't be found on the Hugging Face Hub
2024-06-03:11:23:48,350 WARNING  [load.py:1631] Using the latest cached version of the dataset since gsm8k couldn't be found on the Hugging Face Hub
Found the latest cached dataset configuration 'main' at /private/home/beidic/.cache/huggingface/datasets/gsm8k/main/0.0.0/e53f048856ff4f594e959d75785d2c2d37b678ee (last modified on Thu May 16 07:01:08 2024).
2024-06-03:11:23:48,352 WARNING  [cache.py:95] Found the latest cached dataset configuration 'main' at /private/home/beidic/.cache/huggingface/datasets/gsm8k/main/0.0.0/e53f048856ff4f594e959d75785d2c2d37b678ee (last modified on Thu May 16 07:01:08 2024).
2024-06-03:11:23:48,384 INFO     [task.py:395] Building contexts for gsm8k on rank 7...
 27%|██▋       | 45/165 [00:00<00:00, 144.30it/s]  0%|          | 0/164 [00:00<?, ?it/s]Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
 36%|███▋      | 60/165 [00:00<00:00, 144.48it/s]  9%|▊         | 14/164 [00:00<00:01, 136.06it/s] 45%|████▌     | 75/165 [00:00<00:00, 144.54it/s] 17%|█▋        | 28/164 [00:00<00:00, 137.85it/s]2024-06-03:11:23:48,638 INFO     [task.py:395] Building contexts for gsm8k on rank 3...
  0%|          | 0/165 [00:00<?, ?it/s]Using the latest cached version of the dataset since gsm8k couldn't be found on the Hugging Face Hub
2024-06-03:11:23:48,704 WARNING  [load.py:1631] Using the latest cached version of the dataset since gsm8k couldn't be found on the Hugging Face Hub
Found the latest cached dataset configuration 'main' at /private/home/beidic/.cache/huggingface/datasets/gsm8k/main/0.0.0/e53f048856ff4f594e959d75785d2c2d37b678ee (last modified on Thu May 16 07:01:08 2024).
2024-06-03:11:23:48,706 WARNING  [cache.py:95] Found the latest cached dataset configuration 'main' at /private/home/beidic/.cache/huggingface/datasets/gsm8k/main/0.0.0/e53f048856ff4f594e959d75785d2c2d37b678ee (last modified on Thu May 16 07:01:08 2024).
Using the latest cached version of the dataset since gsm8k couldn't be found on the Hugging Face Hub
2024-06-03:11:23:48,723 WARNING  [load.py:1631] Using the latest cached version of the dataset since gsm8k couldn't be found on the Hugging Face Hub
Found the latest cached dataset configuration 'main' at /private/home/beidic/.cache/huggingface/datasets/gsm8k/main/0.0.0/e53f048856ff4f594e959d75785d2c2d37b678ee (last modified on Thu May 16 07:01:08 2024).
2024-06-03:11:23:48,725 WARNING  [cache.py:95] Found the latest cached dataset configuration 'main' at /private/home/beidic/.cache/huggingface/datasets/gsm8k/main/0.0.0/e53f048856ff4f594e959d75785d2c2d37b678ee (last modified on Thu May 16 07:01:08 2024).
 55%|█████▍    | 90/165 [00:00<00:00, 144.82it/s] 27%|██▋       | 45/164 [00:00<00:00, 148.96it/s] 11%|█         | 18/165 [00:00<00:00, 171.63it/s] 64%|██████▎   | 105/165 [00:00<00:00, 144.83it/s] 37%|███▋      | 60/164 [00:00<00:00, 144.62it/s] 22%|██▏       | 36/165 [00:00<00:00, 150.27it/s] 73%|███████▎  | 120/165 [00:00<00:00, 144.61it/s] 46%|████▌     | 75/164 [00:00<00:00, 142.45it/s]2024-06-03:11:23:48,995 INFO     [task.py:395] Building contexts for gsm8k on rank 1...
2024-06-03:11:23:49,013 INFO     [task.py:395] Building contexts for gsm8k on rank 5...
 32%|███▏      | 52/165 [00:00<00:00, 144.55it/s] 82%|████████▏ | 135/165 [00:00<00:00, 144.89it/s]  0%|          | 0/165 [00:00<?, ?it/s]  0%|          | 0/165 [00:00<?, ?it/s] 55%|█████▍    | 90/164 [00:00<00:00, 141.16it/s] 41%|████      | 67/165 [00:00<00:00, 143.63it/s] 91%|█████████ | 150/165 [00:01<00:00, 144.70it/s]  9%|▉         | 15/165 [00:00<00:01, 141.56it/s]  9%|▉         | 15/165 [00:00<00:01, 142.81it/s] 64%|██████▍   | 105/164 [00:00<00:00, 141.29it/s] 50%|████▉     | 82/165 [00:00<00:00, 143.04it/s]100%|██████████| 165/165 [00:01<00:00, 144.19it/s]100%|██████████| 165/165 [00:01<00:00, 144.44it/s]
 18%|█▊        | 30/165 [00:00<00:00, 141.53it/s] 18%|█▊        | 30/165 [00:00<00:00, 142.51it/s] 73%|███████▎  | 120/164 [00:00<00:00, 141.42it/s] 59%|█████▉    | 97/165 [00:00<00:00, 142.61it/s] 27%|██▋       | 45/165 [00:00<00:00, 141.28it/s] 27%|██▋       | 45/165 [00:00<00:00, 142.71it/s] 82%|████████▏ | 135/164 [00:00<00:00, 141.36it/s] 68%|██████▊   | 112/165 [00:00<00:00, 142.60it/s] 36%|███▋      | 60/165 [00:00<00:00, 141.07it/s] 36%|███▋      | 60/165 [00:00<00:00, 141.94it/s] 91%|█████████▏| 150/164 [00:01<00:00, 140.86it/s] 77%|███████▋  | 127/165 [00:00<00:00, 142.07it/s] 45%|████▌     | 75/165 [00:00<00:00, 140.82it/s] 45%|████▌     | 75/165 [00:00<00:00, 141.79it/s]100%|██████████| 164/164 [00:01<00:00, 141.60it/s]
 86%|████████▌ | 142/165 [00:00<00:00, 140.84it/s] 56%|█████▋    | 93/165 [00:00<00:00, 152.91it/s] 55%|█████▍    | 90/165 [00:00<00:00, 142.16it/s] 95%|█████████▌| 157/165 [00:01<00:00, 141.15it/s] 66%|██████▌   | 109/165 [00:00<00:00, 147.16it/s] 64%|██████▎   | 105/165 [00:00<00:00, 141.60it/s]100%|██████████| 165/165 [00:01<00:00, 143.18it/s]
 74%|███████▍  | 122/165 [00:00<00:00, 150.15it/s] 75%|███████▌  | 124/165 [00:00<00:00, 144.66it/s] 86%|████████▌ | 142/165 [00:00<00:00, 163.59it/s] 85%|████████▍ | 140/165 [00:00<00:00, 147.04it/s] 94%|█████████▍| 155/165 [00:01<00:00, 147.81it/s] 96%|█████████▋| 159/165 [00:01<00:00, 160.65it/s]100%|██████████| 165/165 [00:01<00:00, 150.72it/s]
100%|██████████| 165/165 [00:01<00:00, 146.08it/s]
2024-06-03:11:23:54,772 INFO     [xevaluator.py:395] Running generate_until requests
2024-06-03:11:23:54,772 INFO     [xevaluator.py:395] Running generate_until requests
2024-06-03:11:23:54,772 INFO     [xevaluator.py:395] Running generate_until requests
2024-06-03:11:23:54,772 INFO     [xevaluator.py:395] Running generate_until requests
2024-06-03:11:23:54,772 INFO     [xevaluator.py:395] Running generate_until requests
2024-06-03:11:23:54,772 INFO     [xevaluator.py:395] Running generate_until requests
2024-06-03:11:23:54,772 INFO     [xevaluator.py:395] Running generate_until requests
Running generate_until requests:   0%|          | 0/165 [00:00<?, ?it/s]2024-06-03:11:23:54,773 INFO     [xevaluator.py:395] Running generate_until requests
Running generate_until requests:   1%|          | 1/165 [00:13<35:45, 13.08s/it]Running generate_until requests:   1%|          | 2/165 [00:21<27:44, 10.21s/it]Running generate_until requests:   2%|▏         | 3/165 [00:29<25:08,  9.31s/it]Running generate_until requests:   2%|▏         | 4/165 [00:39<25:33,  9.53s/it]Running generate_until requests:   3%|▎         | 5/165 [00:45<22:00,  8.25s/it]Running generate_until requests:   4%|▎         | 6/165 [00:57<25:14,  9.52s/it]Running generate_until requests:   4%|▍         | 7/165 [01:01<20:35,  7.82s/it]Running generate_until requests:   5%|▍         | 8/165 [01:08<19:13,  7.35s/it]Running generate_until requests:   5%|▌         | 9/165 [01:12<16:38,  6.40s/it]Running generate_until requests:   6%|▌         | 10/165 [01:18<16:44,  6.48s/it]Running generate_until requests:   7%|▋         | 11/165 [01:26<17:49,  6.94s/it]Running generate_until requests:   7%|▋         | 12/165 [01:31<16:09,  6.34s/it]Running generate_until requests:   8%|▊         | 13/165 [01:39<16:40,  6.58s/it]Running generate_until requests:   8%|▊         | 14/165 [01:44<15:47,  6.27s/it]Running generate_until requests:   9%|▉         | 15/165 [01:51<15:57,  6.39s/it]Running generate_until requests:  10%|▉         | 16/165 [01:56<14:44,  5.94s/it]Running generate_until requests:  10%|█         | 17/165 [02:04<16:02,  6.51s/it]Running generate_until requests:  11%|█         | 18/165 [02:11<16:24,  6.70s/it]Running generate_until requests:  12%|█▏        | 19/165 [02:16<15:02,  6.18s/it]Running generate_until requests:  12%|█▏        | 20/165 [02:22<14:45,  6.11s/it]Running generate_until requests:  13%|█▎        | 21/165 [02:31<17:13,  7.18s/it]Running generate_until requests:  13%|█▎        | 22/165 [02:38<17:05,  7.17s/it]Running generate_until requests:  14%|█▍        | 23/165 [02:43<14:56,  6.31s/it]Running generate_until requests:  15%|█▍        | 24/165 [02:48<14:16,  6.07s/it]Running generate_until requests:  15%|█▌        | 25/165 [02:54<14:14,  6.11s/it]Running generate_until requests:  16%|█▌        | 26/165 [03:00<13:49,  5.97s/it]Running generate_until requests:  16%|█▋        | 27/165 [03:09<15:29,  6.74s/it]Running generate_until requests:  17%|█▋        | 28/165 [03:14<14:31,  6.36s/it]Running generate_until requests:  18%|█▊        | 29/165 [03:23<15:56,  7.03s/it]Running generate_until requests:  18%|█▊        | 30/165 [03:30<15:45,  7.00s/it]Running generate_until requests:  19%|█▉        | 31/165 [03:37<15:35,  6.98s/it]Running generate_until requests:  19%|█▉        | 32/165 [03:41<13:45,  6.21s/it]Running generate_until requests:  20%|██        | 33/165 [03:45<12:22,  5.63s/it]Running generate_until requests:  21%|██        | 34/165 [03:52<13:18,  6.10s/it]Running generate_until requests:  21%|██        | 35/165 [04:02<15:13,  7.03s/it]Running generate_until requests:  22%|██▏       | 36/165 [04:14<18:27,  8.59s/it]Running generate_until requests:  22%|██▏       | 37/165 [04:20<17:03,  8.00s/it]Running generate_until requests:  23%|██▎       | 38/165 [04:28<16:26,  7.77s/it]Running generate_until requests:  24%|██▎       | 39/165 [04:39<18:21,  8.74s/it]Running generate_until requests:  24%|██▍       | 40/165 [04:44<16:19,  7.84s/it]Running generate_until requests:  25%|██▍       | 41/165 [04:50<14:50,  7.18s/it]Running generate_until requests:  25%|██▌       | 42/165 [04:57<14:18,  6.98s/it]Running generate_until requests:  26%|██▌       | 43/165 [05:05<14:48,  7.28s/it]Running generate_until requests:  27%|██▋       | 44/165 [05:14<15:56,  7.91s/it]Running generate_until requests:  27%|██▋       | 45/165 [05:20<14:26,  7.22s/it]Running generate_until requests:  28%|██▊       | 46/165 [05:24<12:27,  6.28s/it]Running generate_until requests:  28%|██▊       | 47/165 [05:29<11:31,  5.86s/it]Running generate_until requests:  29%|██▉       | 48/165 [05:36<12:23,  6.35s/it]Running generate_until requests:  30%|██▉       | 49/165 [05:44<13:09,  6.80s/it]Running generate_until requests:  30%|███       | 50/165 [05:49<12:14,  6.39s/it]Running generate_until requests:  31%|███       | 51/165 [05:58<13:17,  6.99s/it]Running generate_until requests:  32%|███▏      | 52/165 [06:02<11:26,  6.07s/it]Running generate_until requests:  32%|███▏      | 53/165 [06:09<12:13,  6.55s/it]Running generate_until requests:  33%|███▎      | 54/165 [06:15<11:29,  6.21s/it]Running generate_until requests:  33%|███▎      | 55/165 [06:19<10:30,  5.73s/it]Running generate_until requests:  34%|███▍      | 56/165 [06:25<10:19,  5.68s/it]Running generate_until requests:  35%|███▍      | 57/165 [06:30<10:04,  5.60s/it]Running generate_until requests:  35%|███▌      | 58/165 [06:35<09:27,  5.30s/it]Running generate_until requests:  36%|███▌      | 59/165 [06:41<09:45,  5.52s/it]Running generate_until requests:  36%|███▋      | 60/165 [06:46<09:21,  5.34s/it]Running generate_until requests:  37%|███▋      | 61/165 [06:52<09:41,  5.59s/it]Running generate_until requests:  38%|███▊      | 62/165 [06:56<08:53,  5.18s/it]Running generate_until requests:  38%|███▊      | 63/165 [07:02<08:51,  5.22s/it]Running generate_until requests:  39%|███▉      | 64/165 [07:08<09:09,  5.45s/it]Running generate_until requests:  39%|███▉      | 65/165 [07:11<07:53,  4.74s/it]Running generate_until requests:  40%|████      | 66/165 [07:16<08:05,  4.90s/it]Running generate_until requests:  41%|████      | 67/165 [07:22<08:23,  5.14s/it]Running generate_until requests:  41%|████      | 68/165 [07:28<08:46,  5.43s/it]Running generate_until requests:  42%|████▏     | 69/165 [07:38<10:57,  6.85s/it]Running generate_until requests:  42%|████▏     | 70/165 [07:43<10:11,  6.44s/it]Running generate_until requests:  43%|████▎     | 71/165 [07:50<09:59,  6.38s/it]Running generate_until requests:  44%|████▎     | 72/165 [08:02<12:33,  8.10s/it]Running generate_until requests:  44%|████▍     | 73/165 [08:06<10:49,  7.06s/it]Running generate_until requests:  45%|████▍     | 74/165 [08:13<10:44,  7.09s/it]Running generate_until requests:  45%|████▌     | 75/165 [08:20<10:10,  6.78s/it]Running generate_until requests:  46%|████▌     | 76/165 [08:27<10:08,  6.84s/it]Running generate_until requests:  47%|████▋     | 77/165 [08:33<09:46,  6.67s/it]Running generate_until requests:  47%|████▋     | 78/165 [08:42<10:33,  7.28s/it]Running generate_until requests:  48%|████▊     | 79/165 [08:46<09:21,  6.53s/it]Running generate_until requests:  48%|████▊     | 80/165 [08:51<08:15,  5.83s/it]Running generate_until requests:  49%|████▉     | 81/165 [08:58<08:40,  6.19s/it]Running generate_until requests:  50%|████▉     | 82/165 [09:04<08:38,  6.25s/it]Running generate_until requests:  50%|█████     | 83/165 [09:11<08:48,  6.44s/it]Running generate_until requests:  51%|█████     | 84/165 [09:18<09:08,  6.78s/it]Running generate_until requests:  52%|█████▏    | 85/165 [09:22<07:38,  5.73s/it]Running generate_until requests:  52%|█████▏    | 86/165 [09:26<07:08,  5.42s/it]Running generate_until requests:  53%|█████▎    | 87/165 [09:33<07:24,  5.70s/it]Running generate_until requests:  53%|█████▎    | 88/165 [09:37<06:54,  5.39s/it]Running generate_until requests:  54%|█████▍    | 89/165 [09:45<07:39,  6.04s/it]Running generate_until requests:  55%|█████▍    | 90/165 [09:51<07:35,  6.08s/it]Running generate_until requests:  55%|█████▌    | 91/165 [09:55<06:38,  5.38s/it]Running generate_until requests:  56%|█████▌    | 92/165 [09:59<06:04,  5.00s/it]Running generate_until requests:  56%|█████▋    | 93/165 [10:05<06:29,  5.41s/it]Running generate_until requests:  57%|█████▋    | 94/165 [10:10<06:11,  5.23s/it]Running generate_until requests:  58%|█████▊    | 95/165 [10:16<06:14,  5.35s/it]Running generate_until requests:  58%|█████▊    | 96/165 [10:21<05:56,  5.17s/it]Running generate_until requests:  59%|█████▉    | 97/165 [10:25<05:44,  5.07s/it]Running generate_until requests:  59%|█████▉    | 98/165 [10:32<06:17,  5.64s/it]Running generate_until requests:  60%|██████    | 99/165 [10:37<05:54,  5.38s/it]Running generate_until requests:  61%|██████    | 100/165 [10:43<05:51,  5.41s/it]Running generate_until requests:  61%|██████    | 101/165 [10:48<05:49,  5.47s/it]Running generate_until requests:  62%|██████▏   | 102/165 [10:53<05:32,  5.28s/it]Running generate_until requests:  62%|██████▏   | 103/165 [11:01<06:12,  6.01s/it]Running generate_until requests:  63%|██████▎   | 104/165 [11:08<06:25,  6.31s/it]Running generate_until requests:  64%|██████▎   | 105/165 [11:13<06:05,  6.10s/it]Running generate_until requests:  64%|██████▍   | 106/165 [11:17<05:19,  5.42s/it]Running generate_until requests:  65%|██████▍   | 107/165 [11:22<05:10,  5.36s/it]Running generate_until requests:  65%|██████▌   | 108/165 [11:29<05:30,  5.81s/it]Running generate_until requests:  66%|██████▌   | 109/165 [11:34<05:04,  5.44s/it]Running generate_until requests:  67%|██████▋   | 110/165 [11:43<06:02,  6.60s/it]Running generate_until requests:  67%|██████▋   | 111/165 [11:53<06:46,  7.53s/it]Running generate_until requests:  68%|██████▊   | 112/165 [11:57<05:41,  6.45s/it]Running generate_until requests:  68%|██████▊   | 113/165 [12:02<05:19,  6.15s/it]Running generate_until requests:  69%|██████▉   | 114/165 [12:06<04:42,  5.53s/it]Running generate_until requests:  70%|██████▉   | 115/165 [12:12<04:46,  5.73s/it]Running generate_until requests:  70%|███████   | 116/165 [12:17<04:24,  5.40s/it]Running generate_until requests:  71%|███████   | 117/165 [12:21<03:59,  4.98s/it]Running generate_until requests:  72%|███████▏  | 118/165 [12:28<04:16,  5.47s/it]Running generate_until requests:  72%|███████▏  | 119/165 [12:33<04:10,  5.44s/it]Running generate_until requests:  73%|███████▎  | 120/165 [12:40<04:24,  5.87s/it]Running generate_until requests:  73%|███████▎  | 121/165 [12:47<04:31,  6.18s/it]Running generate_until requests:  74%|███████▍  | 122/165 [12:58<05:25,  7.56s/it]Running generate_until requests:  75%|███████▍  | 123/165 [13:03<04:52,  6.95s/it]Running generate_until requests:  75%|███████▌  | 124/165 [13:09<04:26,  6.49s/it]Running generate_until requests:  76%|███████▌  | 125/165 [13:25<06:13,  9.33s/it]Running generate_until requests:  76%|███████▋  | 126/165 [13:29<05:02,  7.75s/it]Running generate_until requests:  77%|███████▋  | 127/165 [13:33<04:16,  6.76s/it]Running generate_until requests:  78%|███████▊  | 128/165 [13:39<04:03,  6.59s/it]Running generate_until requests:  78%|███████▊  | 129/165 [13:44<03:36,  6.03s/it]Running generate_until requests:  79%|███████▉  | 130/165 [13:48<03:14,  5.56s/it]Running generate_until requests:  79%|███████▉  | 131/165 [13:54<03:13,  5.69s/it]Running generate_until requests:  80%|████████  | 132/165 [14:10<04:41,  8.53s/it]Running generate_until requests:  81%|████████  | 133/165 [14:14<03:53,  7.29s/it]Running generate_until requests:  81%|████████  | 134/165 [14:19<03:21,  6.51s/it]Running generate_until requests:  82%|████████▏ | 135/165 [14:25<03:15,  6.51s/it]Running generate_until requests:  82%|████████▏ | 136/165 [14:29<02:47,  5.77s/it]Running generate_until requests:  83%|████████▎ | 137/165 [14:35<02:41,  5.77s/it]Running generate_until requests:  84%|████████▎ | 138/165 [14:43<02:55,  6.49s/it]Running generate_until requests:  84%|████████▍ | 139/165 [14:48<02:34,  5.96s/it]Running generate_until requests:  85%|████████▍ | 140/165 [14:55<02:35,  6.22s/it]Running generate_until requests:  85%|████████▌ | 141/165 [14:58<02:11,  5.48s/it]Running generate_until requests:  86%|████████▌ | 142/165 [15:05<02:15,  5.91s/it]Running generate_until requests:  87%|████████▋ | 143/165 [15:09<01:51,  5.08s/it]Running generate_until requests:  87%|████████▋ | 144/165 [15:14<01:49,  5.21s/it]Running generate_until requests:  88%|████████▊ | 145/165 [15:20<01:49,  5.50s/it]Running generate_until requests:  88%|████████▊ | 146/165 [15:25<01:38,  5.17s/it]Running generate_until requests:  89%|████████▉ | 147/165 [15:29<01:30,  5.03s/it]Running generate_until requests:  90%|████████▉ | 148/165 [15:34<01:23,  4.90s/it]Running generate_until requests:  90%|█████████ | 149/165 [15:38<01:13,  4.61s/it]Running generate_until requests:  91%|█████████ | 150/165 [15:42<01:07,  4.51s/it]Running generate_until requests:  92%|█████████▏| 151/165 [15:51<01:20,  5.78s/it]Running generate_until requests:  92%|█████████▏| 152/165 [15:57<01:15,  5.82s/it]Running generate_until requests:  93%|█████████▎| 153/165 [16:01<01:05,  5.47s/it]Running generate_until requests:  93%|█████████▎| 154/165 [16:06<00:57,  5.19s/it]Running generate_until requests:  94%|█████████▍| 155/165 [16:10<00:48,  4.90s/it]Running generate_until requests:  95%|█████████▍| 156/165 [16:18<00:53,  5.90s/it]Running generate_until requests:  95%|█████████▌| 157/165 [16:22<00:41,  5.23s/it]Running generate_until requests:  96%|█████████▌| 158/165 [16:28<00:38,  5.48s/it]Running generate_until requests:  96%|█████████▋| 159/165 [16:36<00:37,  6.28s/it]Running generate_until requests:  97%|█████████▋| 160/165 [16:40<00:27,  5.54s/it]Running generate_until requests:  98%|█████████▊| 161/165 [16:45<00:21,  5.40s/it]Running generate_until requests:  98%|█████████▊| 162/165 [16:49<00:14,  4.87s/it]Running generate_until requests:  99%|█████████▉| 163/165 [16:53<00:09,  4.55s/it]Running generate_until requests:  99%|█████████▉| 164/165 [16:56<00:04,  4.31s/it]Running generate_until requests: 100%|██████████| 165/165 [17:00<00:00,  4.23s/it]Running generate_until requests: 100%|██████████| 165/165 [17:00<00:00,  6.19s/it]
